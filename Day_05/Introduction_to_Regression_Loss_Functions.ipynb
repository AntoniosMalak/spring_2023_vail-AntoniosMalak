{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MySureStart/spring_2023_vail-AntoniosMalak/blob/main/Day_05/Introduction_to_Regression_Loss_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "861ncVuLPeyF"
      },
      "source": [
        "![image_2021-10-30_133041.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Day 5 Objectives: \n",
        "* To introduce you to loss functions. \n"
      ],
      "metadata": {
        "id": "5rokz_Xr0kDG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCtJpzBrYWqr"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4fAWIkUYUyR"
      },
      "source": [
        "Loss functions define what a good prediction is and isn’t. Choosing the right loss function dictates how well your estimator (machine learning model) will be. The criteria by which an estimator is scrutinized is its performance - how accurate the model's decisions are. This calls for a way to measure how far a particular iteration of the model is from the actual values. This is where loss functions come into play.\n",
        "\n",
        "Loss functions measure how far an estimated value is from its true value. A loss function maps decisions to their associated costs. Loss functions are not fixed, they change depending on the task in hand and the goal to be met.\n",
        "\n",
        "Worth to note we can speak of different kind of loss functions: **regression loss** functions and **classification loss** functions.\n",
        "\n",
        "Regression loss function describes the difference between the values that a model is predicting and the actual values of the labels. So the loss function has a meaning on a labeled data when we compare the prediction to the label at a single point of time. This loss function is often called the error function or the error formula. Typical error functions we use for regression models are L1 and L2, Huber loss, Quantile loss, log cosh loss.\n",
        "\n",
        "**Note**: L1 loss is also know as Mean Absolute Error. L2 Loss is also know as Mean Square Error or Quadratic loss.\n",
        "\n",
        "Loss functions for classification represent the price paid for inaccuracy of predictions in classification problems (problems of identifying which category a particular observation belongs to). To name a few: log loss, focal loss, exponential loss, hinge loss, relative entropy loss and other.\n",
        "\n",
        "*Note*: While more commonly used in regression, the square loss function can be re-written and utilized for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I1Y9BQxq72l"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Hpicvr6XJ0"
      },
      "source": [
        "# Regression Losses\n",
        "\n",
        "Remember, in regression, the output would be a real value. We need some loss functions which compares two real values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoFFw2VUR7j",
        "outputId": "ccdb73dd-e352-4f9e-c68c-fe7526307234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()\n",
        "\n",
        "# get per-feature statistics (mean, standard deviation) from the training set to normalize by\n",
        "train_mean = np.mean(train_features, axis=0)\n",
        "train_std = np.std(train_features, axis=0)\n",
        "train_features = (train_features - train_mean) / train_std"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAdSFpdB6aDH"
      },
      "source": [
        "## Mean Squared Error [MSE]\n",
        "\n",
        "As the name suggests, Mean square error is measured as the average of squared difference between predictions and actual observations. It’s only concerned with the average magnitude of error irrespective of their direction. \n",
        "\n",
        "However, due to squaring, predictions which are far away from actual values are penalized heavily in comparison to less deviated predictions. Plus MSE has nice mathematical properties which makes it easier to calculate gradients.\n",
        "\n",
        "Let's assume there are $n$ data samples, for $i^{th}$ sample; the actual output is $y_i$ and $\\hat{y}_i$ is the estimated output from the regression model. \n",
        "\n",
        "We first square the difference between the original and estimated output with $(y_i - \\hat{y}_i)^2$. Then we take sum of the squared difference for all the samples. And finally divide it by the total count of samples, which is $n$. \n",
        "\n",
        "$$MSE = \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5OO5ZfoYtCJ",
        "outputId": "8749b09e-db37-46af-b67a-3e09138ad241",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mse',\n",
        "              metrics=['mse'])\n",
        "\n",
        "history = model.fit(train_features, train_labels, epochs=250, validation_split = 0.1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "12/12 [==============================] - 9s 39ms/step - loss: 591.8322 - mse: 591.8322 - val_loss: 497.7946 - val_mse: 497.7946\n",
            "Epoch 2/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 581.5326 - mse: 581.5326 - val_loss: 487.6369 - val_mse: 487.6369\n",
            "Epoch 3/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 568.3712 - mse: 568.3712 - val_loss: 472.1071 - val_mse: 472.1071\n",
            "Epoch 4/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 546.5814 - mse: 546.5814 - val_loss: 447.1936 - val_mse: 447.1936\n",
            "Epoch 5/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 512.5260 - mse: 512.5260 - val_loss: 408.8595 - val_mse: 408.8595\n",
            "Epoch 6/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 457.9333 - mse: 457.9333 - val_loss: 350.6699 - val_mse: 350.6699\n",
            "Epoch 7/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 381.1250 - mse: 381.1250 - val_loss: 272.1481 - val_mse: 272.1481\n",
            "Epoch 8/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 285.0956 - mse: 285.0956 - val_loss: 183.6006 - val_mse: 183.6006\n",
            "Epoch 9/250\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 181.8386 - mse: 181.8386 - val_loss: 99.6538 - val_mse: 99.6538\n",
            "Epoch 10/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 101.5443 - mse: 101.5443 - val_loss: 49.1316 - val_mse: 49.1316\n",
            "Epoch 11/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 66.0750 - mse: 66.0750 - val_loss: 35.5099 - val_mse: 35.5099\n",
            "Epoch 12/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 55.4995 - mse: 55.4995 - val_loss: 29.1480 - val_mse: 29.1480\n",
            "Epoch 13/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 46.5865 - mse: 46.5865 - val_loss: 25.3880 - val_mse: 25.3880\n",
            "Epoch 14/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 41.5337 - mse: 41.5337 - val_loss: 23.5261 - val_mse: 23.5261\n",
            "Epoch 15/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 38.1378 - mse: 38.1378 - val_loss: 22.1840 - val_mse: 22.1840\n",
            "Epoch 16/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 35.4419 - mse: 35.4419 - val_loss: 21.2228 - val_mse: 21.2228\n",
            "Epoch 17/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 33.4280 - mse: 33.4280 - val_loss: 20.1366 - val_mse: 20.1366\n",
            "Epoch 18/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 31.8843 - mse: 31.8843 - val_loss: 19.6893 - val_mse: 19.6893\n",
            "Epoch 19/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 30.2917 - mse: 30.2917 - val_loss: 18.5795 - val_mse: 18.5795\n",
            "Epoch 20/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 29.1409 - mse: 29.1409 - val_loss: 17.5854 - val_mse: 17.5854\n",
            "Epoch 21/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 27.7976 - mse: 27.7976 - val_loss: 17.3455 - val_mse: 17.3455\n",
            "Epoch 22/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 26.8590 - mse: 26.8590 - val_loss: 17.0285 - val_mse: 17.0285\n",
            "Epoch 23/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25.9472 - mse: 25.9472 - val_loss: 16.3961 - val_mse: 16.3961\n",
            "Epoch 24/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 25.0583 - mse: 25.0583 - val_loss: 16.1912 - val_mse: 16.1912\n",
            "Epoch 25/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 24.3739 - mse: 24.3739 - val_loss: 16.1128 - val_mse: 16.1128\n",
            "Epoch 26/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 23.5995 - mse: 23.5995 - val_loss: 15.5005 - val_mse: 15.5005\n",
            "Epoch 27/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 22.9104 - mse: 22.9104 - val_loss: 15.2029 - val_mse: 15.2029\n",
            "Epoch 28/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 22.3147 - mse: 22.3147 - val_loss: 15.0709 - val_mse: 15.0709\n",
            "Epoch 29/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 21.7837 - mse: 21.7837 - val_loss: 14.9712 - val_mse: 14.9712\n",
            "Epoch 30/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 21.3526 - mse: 21.3526 - val_loss: 14.4296 - val_mse: 14.4296\n",
            "Epoch 31/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 20.8175 - mse: 20.8175 - val_loss: 14.3305 - val_mse: 14.3305\n",
            "Epoch 32/250\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 20.3854 - mse: 20.3854 - val_loss: 13.9870 - val_mse: 13.9870\n",
            "Epoch 33/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 20.0257 - mse: 20.0257 - val_loss: 14.2404 - val_mse: 14.2404\n",
            "Epoch 34/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 19.5648 - mse: 19.5648 - val_loss: 13.6483 - val_mse: 13.6483\n",
            "Epoch 35/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 19.0514 - mse: 19.0514 - val_loss: 13.5714 - val_mse: 13.5714\n",
            "Epoch 36/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 18.7939 - mse: 18.7939 - val_loss: 13.4753 - val_mse: 13.4753\n",
            "Epoch 37/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18.4257 - mse: 18.4257 - val_loss: 13.3333 - val_mse: 13.3333\n",
            "Epoch 38/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 18.3170 - mse: 18.3170 - val_loss: 13.0648 - val_mse: 13.0648\n",
            "Epoch 39/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17.8010 - mse: 17.8010 - val_loss: 14.2643 - val_mse: 14.2643\n",
            "Epoch 40/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17.7393 - mse: 17.7393 - val_loss: 13.6912 - val_mse: 13.6912\n",
            "Epoch 41/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17.2763 - mse: 17.2763 - val_loss: 13.4943 - val_mse: 13.4943\n",
            "Epoch 42/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 16.9379 - mse: 16.9379 - val_loss: 13.4775 - val_mse: 13.4775\n",
            "Epoch 43/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 16.6756 - mse: 16.6756 - val_loss: 13.0787 - val_mse: 13.0787\n",
            "Epoch 44/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16.5034 - mse: 16.5034 - val_loss: 12.7744 - val_mse: 12.7744\n",
            "Epoch 45/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16.1764 - mse: 16.1764 - val_loss: 12.7952 - val_mse: 12.7952\n",
            "Epoch 46/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 15.9905 - mse: 15.9905 - val_loss: 12.7580 - val_mse: 12.7580\n",
            "Epoch 47/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.7512 - mse: 15.7512 - val_loss: 12.6493 - val_mse: 12.6493\n",
            "Epoch 48/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.5353 - mse: 15.5353 - val_loss: 12.3999 - val_mse: 12.3999\n",
            "Epoch 49/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 15.3191 - mse: 15.3191 - val_loss: 12.3263 - val_mse: 12.3263\n",
            "Epoch 50/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.1406 - mse: 15.1406 - val_loss: 12.1074 - val_mse: 12.1074\n",
            "Epoch 51/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 14.8760 - mse: 14.8760 - val_loss: 12.3001 - val_mse: 12.3001\n",
            "Epoch 52/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 14.8526 - mse: 14.8526 - val_loss: 12.0666 - val_mse: 12.0666\n",
            "Epoch 53/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14.5966 - mse: 14.5966 - val_loss: 11.9490 - val_mse: 11.9490\n",
            "Epoch 54/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 14.3788 - mse: 14.3788 - val_loss: 11.8420 - val_mse: 11.8420\n",
            "Epoch 55/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 14.2142 - mse: 14.2142 - val_loss: 11.7434 - val_mse: 11.7434\n",
            "Epoch 56/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 14.0707 - mse: 14.0707 - val_loss: 11.6743 - val_mse: 11.6743\n",
            "Epoch 57/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 13.9272 - mse: 13.9272 - val_loss: 11.5569 - val_mse: 11.5569\n",
            "Epoch 58/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 13.8603 - mse: 13.8603 - val_loss: 11.7444 - val_mse: 11.7444\n",
            "Epoch 59/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 13.6489 - mse: 13.6489 - val_loss: 11.3144 - val_mse: 11.3144\n",
            "Epoch 60/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 13.4244 - mse: 13.4244 - val_loss: 11.3339 - val_mse: 11.3339\n",
            "Epoch 61/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 13.2900 - mse: 13.2900 - val_loss: 11.3111 - val_mse: 11.3111\n",
            "Epoch 62/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 13.1424 - mse: 13.1424 - val_loss: 11.2131 - val_mse: 11.2131\n",
            "Epoch 63/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12.9731 - mse: 12.9731 - val_loss: 11.0780 - val_mse: 11.0780\n",
            "Epoch 64/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 13.0056 - mse: 13.0056 - val_loss: 10.9022 - val_mse: 10.9022\n",
            "Epoch 65/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12.8198 - mse: 12.8198 - val_loss: 11.0895 - val_mse: 11.0895\n",
            "Epoch 66/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12.5819 - mse: 12.5819 - val_loss: 10.7289 - val_mse: 10.7289\n",
            "Epoch 67/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 12.4465 - mse: 12.4465 - val_loss: 10.7441 - val_mse: 10.7441\n",
            "Epoch 68/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12.3534 - mse: 12.3534 - val_loss: 10.7271 - val_mse: 10.7271\n",
            "Epoch 69/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 12.2799 - mse: 12.2799 - val_loss: 10.5063 - val_mse: 10.5063\n",
            "Epoch 70/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 12.0830 - mse: 12.0830 - val_loss: 10.4157 - val_mse: 10.4157\n",
            "Epoch 71/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12.0024 - mse: 12.0024 - val_loss: 10.3797 - val_mse: 10.3797\n",
            "Epoch 72/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 11.8144 - mse: 11.8144 - val_loss: 10.2426 - val_mse: 10.2426\n",
            "Epoch 73/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 11.6923 - mse: 11.6923 - val_loss: 10.1680 - val_mse: 10.1680\n",
            "Epoch 74/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.6649 - mse: 11.6649 - val_loss: 10.1025 - val_mse: 10.1025\n",
            "Epoch 75/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.4938 - mse: 11.4938 - val_loss: 9.9639 - val_mse: 9.9639\n",
            "Epoch 76/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.3562 - mse: 11.3562 - val_loss: 9.9836 - val_mse: 9.9836\n",
            "Epoch 77/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11.2480 - mse: 11.2480 - val_loss: 10.0277 - val_mse: 10.0277\n",
            "Epoch 78/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.1764 - mse: 11.1764 - val_loss: 9.8377 - val_mse: 9.8377\n",
            "Epoch 79/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 11.2679 - mse: 11.2679 - val_loss: 9.6860 - val_mse: 9.6860\n",
            "Epoch 80/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11.0677 - mse: 11.0677 - val_loss: 9.8617 - val_mse: 9.8617\n",
            "Epoch 81/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.8730 - mse: 10.8730 - val_loss: 9.6065 - val_mse: 9.6065\n",
            "Epoch 82/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.7833 - mse: 10.7833 - val_loss: 9.7018 - val_mse: 9.7018\n",
            "Epoch 83/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.6909 - mse: 10.6909 - val_loss: 9.6068 - val_mse: 9.6068\n",
            "Epoch 84/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.5943 - mse: 10.5943 - val_loss: 9.3879 - val_mse: 9.3879\n",
            "Epoch 85/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.3985 - mse: 10.3985 - val_loss: 9.2886 - val_mse: 9.2886\n",
            "Epoch 86/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.3109 - mse: 10.3109 - val_loss: 9.2967 - val_mse: 9.2967\n",
            "Epoch 87/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10.2392 - mse: 10.2392 - val_loss: 9.0566 - val_mse: 9.0566\n",
            "Epoch 88/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.1944 - mse: 10.1944 - val_loss: 9.0659 - val_mse: 9.0659\n",
            "Epoch 89/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 10.1050 - mse: 10.1050 - val_loss: 9.0534 - val_mse: 9.0534\n",
            "Epoch 90/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.0330 - mse: 10.0330 - val_loss: 8.8972 - val_mse: 8.8972\n",
            "Epoch 91/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.8720 - mse: 9.8720 - val_loss: 9.0934 - val_mse: 9.0934\n",
            "Epoch 92/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.7324 - mse: 9.7324 - val_loss: 8.8785 - val_mse: 8.8785\n",
            "Epoch 93/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.6420 - mse: 9.6420 - val_loss: 8.8565 - val_mse: 8.8565\n",
            "Epoch 94/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.5707 - mse: 9.5707 - val_loss: 8.6943 - val_mse: 8.6943\n",
            "Epoch 95/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.4839 - mse: 9.4839 - val_loss: 8.6543 - val_mse: 8.6543\n",
            "Epoch 96/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.4109 - mse: 9.4109 - val_loss: 8.5861 - val_mse: 8.5861\n",
            "Epoch 97/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.3326 - mse: 9.3326 - val_loss: 8.5501 - val_mse: 8.5501\n",
            "Epoch 98/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 9.2805 - mse: 9.2805 - val_loss: 8.6155 - val_mse: 8.6155\n",
            "Epoch 99/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.1581 - mse: 9.1581 - val_loss: 8.5816 - val_mse: 8.5816\n",
            "Epoch 100/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.0967 - mse: 9.0967 - val_loss: 8.3784 - val_mse: 8.3784\n",
            "Epoch 101/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.9915 - mse: 8.9915 - val_loss: 8.3734 - val_mse: 8.3734\n",
            "Epoch 102/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.9819 - mse: 8.9819 - val_loss: 8.2839 - val_mse: 8.2839\n",
            "Epoch 103/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.0461 - mse: 9.0461 - val_loss: 8.2406 - val_mse: 8.2406\n",
            "Epoch 104/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.7829 - mse: 8.7829 - val_loss: 8.1919 - val_mse: 8.1919\n",
            "Epoch 105/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.8077 - mse: 8.8077 - val_loss: 8.1009 - val_mse: 8.1009\n",
            "Epoch 106/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.7005 - mse: 8.7005 - val_loss: 8.0944 - val_mse: 8.0944\n",
            "Epoch 107/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.6243 - mse: 8.6243 - val_loss: 7.9903 - val_mse: 7.9903\n",
            "Epoch 108/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.5583 - mse: 8.5583 - val_loss: 7.9887 - val_mse: 7.9887\n",
            "Epoch 109/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.4762 - mse: 8.4762 - val_loss: 8.1484 - val_mse: 8.1484\n",
            "Epoch 110/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.4401 - mse: 8.4401 - val_loss: 8.1637 - val_mse: 8.1637\n",
            "Epoch 111/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.3592 - mse: 8.3592 - val_loss: 8.1003 - val_mse: 8.1003\n",
            "Epoch 112/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.3875 - mse: 8.3875 - val_loss: 8.0200 - val_mse: 8.0200\n",
            "Epoch 113/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.2987 - mse: 8.2987 - val_loss: 8.1295 - val_mse: 8.1295\n",
            "Epoch 114/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.2439 - mse: 8.2439 - val_loss: 8.0925 - val_mse: 8.0925\n",
            "Epoch 115/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.1303 - mse: 8.1303 - val_loss: 7.8730 - val_mse: 7.8730\n",
            "Epoch 116/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.5323 - mse: 8.5323 - val_loss: 7.9486 - val_mse: 7.9486\n",
            "Epoch 117/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.3112 - mse: 8.3112 - val_loss: 7.7803 - val_mse: 7.7803\n",
            "Epoch 118/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.0001 - mse: 8.0001 - val_loss: 7.7490 - val_mse: 7.7490\n",
            "Epoch 119/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.9620 - mse: 7.9620 - val_loss: 7.8864 - val_mse: 7.8864\n",
            "Epoch 120/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.0283 - mse: 8.0283 - val_loss: 7.8693 - val_mse: 7.8693\n",
            "Epoch 121/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.8963 - mse: 7.8963 - val_loss: 7.7410 - val_mse: 7.7410\n",
            "Epoch 122/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.7732 - mse: 7.7732 - val_loss: 7.7243 - val_mse: 7.7243\n",
            "Epoch 123/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.8467 - mse: 7.8467 - val_loss: 7.5984 - val_mse: 7.5984\n",
            "Epoch 124/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.8158 - mse: 7.8158 - val_loss: 7.4920 - val_mse: 7.4920\n",
            "Epoch 125/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.6844 - mse: 7.6844 - val_loss: 7.5459 - val_mse: 7.5459\n",
            "Epoch 126/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.6951 - mse: 7.6951 - val_loss: 7.4912 - val_mse: 7.4912\n",
            "Epoch 127/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.5661 - mse: 7.5661 - val_loss: 7.4571 - val_mse: 7.4571\n",
            "Epoch 128/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.5494 - mse: 7.5494 - val_loss: 7.4350 - val_mse: 7.4350\n",
            "Epoch 129/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.5192 - mse: 7.5192 - val_loss: 7.3542 - val_mse: 7.3542\n",
            "Epoch 130/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.4543 - mse: 7.4543 - val_loss: 7.3248 - val_mse: 7.3248\n",
            "Epoch 131/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.5509 - mse: 7.5509 - val_loss: 7.4194 - val_mse: 7.4194\n",
            "Epoch 132/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.4493 - mse: 7.4493 - val_loss: 7.2862 - val_mse: 7.2862\n",
            "Epoch 133/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.3288 - mse: 7.3288 - val_loss: 7.1959 - val_mse: 7.1959\n",
            "Epoch 134/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.3347 - mse: 7.3347 - val_loss: 7.3081 - val_mse: 7.3081\n",
            "Epoch 135/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.2474 - mse: 7.2474 - val_loss: 7.2658 - val_mse: 7.2658\n",
            "Epoch 136/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.2663 - mse: 7.2663 - val_loss: 7.1763 - val_mse: 7.1763\n",
            "Epoch 137/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.2680 - mse: 7.2680 - val_loss: 7.2527 - val_mse: 7.2527\n",
            "Epoch 138/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.1169 - mse: 7.1169 - val_loss: 7.3090 - val_mse: 7.3090\n",
            "Epoch 139/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.1206 - mse: 7.1206 - val_loss: 7.0901 - val_mse: 7.0901\n",
            "Epoch 140/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.1237 - mse: 7.1237 - val_loss: 7.0922 - val_mse: 7.0922\n",
            "Epoch 141/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.0518 - mse: 7.0518 - val_loss: 6.9919 - val_mse: 6.9919\n",
            "Epoch 142/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.0070 - mse: 7.0070 - val_loss: 6.9911 - val_mse: 6.9911\n",
            "Epoch 143/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.0651 - mse: 7.0651 - val_loss: 6.9041 - val_mse: 6.9041\n",
            "Epoch 144/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9841 - mse: 6.9841 - val_loss: 6.8422 - val_mse: 6.8422\n",
            "Epoch 145/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.9045 - mse: 6.9045 - val_loss: 6.7838 - val_mse: 6.7838\n",
            "Epoch 146/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.9135 - mse: 6.9135 - val_loss: 6.9766 - val_mse: 6.9766\n",
            "Epoch 147/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.9275 - mse: 6.9275 - val_loss: 6.7826 - val_mse: 6.7826\n",
            "Epoch 148/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8873 - mse: 6.8873 - val_loss: 6.8147 - val_mse: 6.8147\n",
            "Epoch 149/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8148 - mse: 6.8148 - val_loss: 6.8684 - val_mse: 6.8684\n",
            "Epoch 150/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.8053 - mse: 6.8053 - val_loss: 6.9544 - val_mse: 6.9544\n",
            "Epoch 151/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7806 - mse: 6.7806 - val_loss: 6.9362 - val_mse: 6.9362\n",
            "Epoch 152/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.7568 - mse: 6.7568 - val_loss: 6.9821 - val_mse: 6.9821\n",
            "Epoch 153/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.6602 - mse: 6.6602 - val_loss: 6.9370 - val_mse: 6.9370\n",
            "Epoch 154/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.6177 - mse: 6.6177 - val_loss: 6.8593 - val_mse: 6.8593\n",
            "Epoch 155/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.6824 - mse: 6.6824 - val_loss: 6.8608 - val_mse: 6.8608\n",
            "Epoch 156/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5617 - mse: 6.5617 - val_loss: 6.8711 - val_mse: 6.8711\n",
            "Epoch 157/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5271 - mse: 6.5271 - val_loss: 6.7649 - val_mse: 6.7649\n",
            "Epoch 158/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.5133 - mse: 6.5133 - val_loss: 6.7440 - val_mse: 6.7440\n",
            "Epoch 159/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5182 - mse: 6.5182 - val_loss: 6.8747 - val_mse: 6.8747\n",
            "Epoch 160/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.4511 - mse: 6.4511 - val_loss: 6.9212 - val_mse: 6.9212\n",
            "Epoch 161/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.4707 - mse: 6.4707 - val_loss: 6.8743 - val_mse: 6.8743\n",
            "Epoch 162/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.4663 - mse: 6.4663 - val_loss: 6.8289 - val_mse: 6.8289\n",
            "Epoch 163/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.4209 - mse: 6.4209 - val_loss: 6.8310 - val_mse: 6.8310\n",
            "Epoch 164/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.4766 - mse: 6.4766 - val_loss: 6.7822 - val_mse: 6.7822\n",
            "Epoch 165/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.4361 - mse: 6.4361 - val_loss: 6.9540 - val_mse: 6.9540\n",
            "Epoch 166/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.3783 - mse: 6.3783 - val_loss: 6.8844 - val_mse: 6.8844\n",
            "Epoch 167/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.2945 - mse: 6.2945 - val_loss: 6.7293 - val_mse: 6.7293\n",
            "Epoch 168/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.3145 - mse: 6.3145 - val_loss: 6.7119 - val_mse: 6.7119\n",
            "Epoch 169/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.3024 - mse: 6.3024 - val_loss: 6.6959 - val_mse: 6.6959\n",
            "Epoch 170/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.1538 - mse: 6.1538 - val_loss: 6.7412 - val_mse: 6.7412\n",
            "Epoch 171/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.2069 - mse: 6.2069 - val_loss: 6.5737 - val_mse: 6.5737\n",
            "Epoch 172/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.1911 - mse: 6.1911 - val_loss: 6.7102 - val_mse: 6.7102\n",
            "Epoch 173/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.1305 - mse: 6.1305 - val_loss: 6.7625 - val_mse: 6.7625\n",
            "Epoch 174/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.2002 - mse: 6.2002 - val_loss: 6.6076 - val_mse: 6.6076\n",
            "Epoch 175/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0833 - mse: 6.0833 - val_loss: 6.5245 - val_mse: 6.5245\n",
            "Epoch 176/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.0252 - mse: 6.0252 - val_loss: 6.6521 - val_mse: 6.6521\n",
            "Epoch 177/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0119 - mse: 6.0119 - val_loss: 6.7220 - val_mse: 6.7220\n",
            "Epoch 178/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.9978 - mse: 5.9978 - val_loss: 6.5850 - val_mse: 6.5850\n",
            "Epoch 179/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.0747 - mse: 6.0747 - val_loss: 6.5476 - val_mse: 6.5476\n",
            "Epoch 180/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0408 - mse: 6.0408 - val_loss: 6.7248 - val_mse: 6.7248\n",
            "Epoch 181/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5.9497 - mse: 5.9497 - val_loss: 6.6495 - val_mse: 6.6495\n",
            "Epoch 182/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8979 - mse: 5.8979 - val_loss: 6.5947 - val_mse: 6.5947\n",
            "Epoch 183/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9410 - mse: 5.9410 - val_loss: 6.6272 - val_mse: 6.6272\n",
            "Epoch 184/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.0189 - mse: 6.0189 - val_loss: 6.6830 - val_mse: 6.6830\n",
            "Epoch 185/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.7962 - mse: 5.7962 - val_loss: 6.5618 - val_mse: 6.5618\n",
            "Epoch 186/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9828 - mse: 5.9828 - val_loss: 6.7509 - val_mse: 6.7509\n",
            "Epoch 187/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9010 - mse: 5.9010 - val_loss: 7.0058 - val_mse: 7.0058\n",
            "Epoch 188/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8624 - mse: 5.8624 - val_loss: 6.6624 - val_mse: 6.6624\n",
            "Epoch 189/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.7462 - mse: 5.7462 - val_loss: 6.6091 - val_mse: 6.6091\n",
            "Epoch 190/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5.6662 - mse: 5.6662 - val_loss: 6.6153 - val_mse: 6.6153\n",
            "Epoch 191/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.6546 - mse: 5.6546 - val_loss: 6.7160 - val_mse: 6.7160\n",
            "Epoch 192/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.6839 - mse: 5.6839 - val_loss: 6.6437 - val_mse: 6.6437\n",
            "Epoch 193/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5.7590 - mse: 5.7590 - val_loss: 6.7015 - val_mse: 6.7015\n",
            "Epoch 194/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.6971 - mse: 5.6971 - val_loss: 6.6522 - val_mse: 6.6522\n",
            "Epoch 195/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.7130 - mse: 5.7130 - val_loss: 6.6806 - val_mse: 6.6806\n",
            "Epoch 196/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.5385 - mse: 5.5385 - val_loss: 6.7033 - val_mse: 6.7033\n",
            "Epoch 197/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.5539 - mse: 5.5539 - val_loss: 6.7026 - val_mse: 6.7026\n",
            "Epoch 198/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.4463 - mse: 5.4463 - val_loss: 6.5933 - val_mse: 6.5933\n",
            "Epoch 199/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.5310 - mse: 5.5310 - val_loss: 6.6769 - val_mse: 6.6769\n",
            "Epoch 200/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.4207 - mse: 5.4207 - val_loss: 6.6193 - val_mse: 6.6193\n",
            "Epoch 201/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.4648 - mse: 5.4648 - val_loss: 6.5141 - val_mse: 6.5141\n",
            "Epoch 202/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.3470 - mse: 5.3470 - val_loss: 6.6941 - val_mse: 6.6941\n",
            "Epoch 203/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.3556 - mse: 5.3556 - val_loss: 6.5871 - val_mse: 6.5871\n",
            "Epoch 204/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.4535 - mse: 5.4535 - val_loss: 6.8020 - val_mse: 6.8020\n",
            "Epoch 205/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.3869 - mse: 5.3869 - val_loss: 6.7113 - val_mse: 6.7113\n",
            "Epoch 206/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.3744 - mse: 5.3744 - val_loss: 6.7313 - val_mse: 6.7313\n",
            "Epoch 207/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.2292 - mse: 5.2292 - val_loss: 6.6299 - val_mse: 6.6299\n",
            "Epoch 208/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.2205 - mse: 5.2205 - val_loss: 6.8835 - val_mse: 6.8835\n",
            "Epoch 209/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.2472 - mse: 5.2472 - val_loss: 6.7277 - val_mse: 6.7277\n",
            "Epoch 210/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.2541 - mse: 5.2541 - val_loss: 6.8590 - val_mse: 6.8590\n",
            "Epoch 211/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.1654 - mse: 5.1654 - val_loss: 6.6227 - val_mse: 6.6227\n",
            "Epoch 212/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.1131 - mse: 5.1131 - val_loss: 6.7326 - val_mse: 6.7326\n",
            "Epoch 213/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.2510 - mse: 5.2510 - val_loss: 6.6063 - val_mse: 6.6063\n",
            "Epoch 214/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.2805 - mse: 5.2805 - val_loss: 6.5578 - val_mse: 6.5578\n",
            "Epoch 215/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.1265 - mse: 5.1265 - val_loss: 6.8240 - val_mse: 6.8240\n",
            "Epoch 216/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.2868 - mse: 5.2868 - val_loss: 6.6754 - val_mse: 6.6754\n",
            "Epoch 217/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.2710 - mse: 5.2710 - val_loss: 6.9080 - val_mse: 6.9080\n",
            "Epoch 218/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.0615 - mse: 5.0615 - val_loss: 6.6693 - val_mse: 6.6693\n",
            "Epoch 219/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.9748 - mse: 4.9748 - val_loss: 6.7587 - val_mse: 6.7587\n",
            "Epoch 220/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9323 - mse: 4.9323 - val_loss: 6.6145 - val_mse: 6.6145\n",
            "Epoch 221/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.9809 - mse: 4.9809 - val_loss: 6.7249 - val_mse: 6.7249\n",
            "Epoch 222/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.9970 - mse: 4.9970 - val_loss: 6.7620 - val_mse: 6.7620\n",
            "Epoch 223/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.9544 - mse: 4.9544 - val_loss: 6.7812 - val_mse: 6.7812\n",
            "Epoch 224/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9655 - mse: 4.9655 - val_loss: 6.7898 - val_mse: 6.7898\n",
            "Epoch 225/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.8824 - mse: 4.8824 - val_loss: 6.6726 - val_mse: 6.6726\n",
            "Epoch 226/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 5.1431 - mse: 5.1431 - val_loss: 6.9004 - val_mse: 6.9004\n",
            "Epoch 227/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.9255 - mse: 4.9255 - val_loss: 6.9965 - val_mse: 6.9965\n",
            "Epoch 228/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.8105 - mse: 4.8105 - val_loss: 7.0200 - val_mse: 7.0200\n",
            "Epoch 229/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8535 - mse: 4.8535 - val_loss: 6.8674 - val_mse: 6.8674\n",
            "Epoch 230/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.7865 - mse: 4.7865 - val_loss: 6.8028 - val_mse: 6.8028\n",
            "Epoch 231/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.7618 - mse: 4.7618 - val_loss: 6.8807 - val_mse: 6.8807\n",
            "Epoch 232/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.7238 - mse: 4.7238 - val_loss: 6.8843 - val_mse: 6.8843\n",
            "Epoch 233/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 4.8027 - mse: 4.8027 - val_loss: 7.1148 - val_mse: 7.1148\n",
            "Epoch 234/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.7138 - mse: 4.7138 - val_loss: 6.9884 - val_mse: 6.9884\n",
            "Epoch 235/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6774 - mse: 4.6774 - val_loss: 6.9945 - val_mse: 6.9945\n",
            "Epoch 236/250\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 4.6829 - mse: 4.6829 - val_loss: 6.9897 - val_mse: 6.9897\n",
            "Epoch 237/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.6075 - mse: 4.6075 - val_loss: 7.0615 - val_mse: 7.0615\n",
            "Epoch 238/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.6294 - mse: 4.6294 - val_loss: 7.1911 - val_mse: 7.1911\n",
            "Epoch 239/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.6087 - mse: 4.6087 - val_loss: 6.9919 - val_mse: 6.9919\n",
            "Epoch 240/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.6439 - mse: 4.6439 - val_loss: 7.1820 - val_mse: 7.1820\n",
            "Epoch 241/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.6255 - mse: 4.6255 - val_loss: 7.1919 - val_mse: 7.1919\n",
            "Epoch 242/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.6576 - mse: 4.6576 - val_loss: 7.1415 - val_mse: 7.1415\n",
            "Epoch 243/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.5861 - mse: 4.5861 - val_loss: 7.3405 - val_mse: 7.3405\n",
            "Epoch 244/250\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 4.6621 - mse: 4.6621 - val_loss: 7.2356 - val_mse: 7.2356\n",
            "Epoch 245/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.5877 - mse: 4.5877 - val_loss: 7.3687 - val_mse: 7.3687\n",
            "Epoch 246/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.6748 - mse: 4.6748 - val_loss: 7.1012 - val_mse: 7.1012\n",
            "Epoch 247/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.4916 - mse: 4.4916 - val_loss: 7.3567 - val_mse: 7.3567\n",
            "Epoch 248/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.4524 - mse: 4.4524 - val_loss: 7.2070 - val_mse: 7.2070\n",
            "Epoch 249/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 4.4105 - mse: 4.4105 - val_loss: 7.2838 - val_mse: 7.2838\n",
            "Epoch 250/250\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 4.3941 - mse: 4.3941 - val_loss: 7.3333 - val_mse: 7.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEFaa0VQaKef"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Now that you know how MSE works, you need to plot the behavior of MSE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc5OFsCmadXE"
      },
      "source": [
        "### Answer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8RF_LUDbdo2",
        "outputId": "866a34d6-ea8e-41d0-9135-a67c9dd54a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# errors = np.arange(-5, 6)\n",
        "# n = len(errors)\n",
        "\n",
        "mse = history.history['mse']\n",
        "val_mse = history.history['val_mse']\n",
        "\n",
        "plt.plot(mse, marker='o')\n",
        "plt.plot(val_mse, marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Difference between actual and estimated ouputs')\n",
        "plt.ylabel('Mean Squared Errors')\n",
        "plt.legend(['train', 'valid'])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU1b348c83yWQFEhYN621wqTuyRMVibSy1blVpVfSq1Vpb2lsVtdcFuyj19lqqvbV6XW5p9Ve1VqSIgCsqGi2tWqFgQFFBRSEgmxAIJCHL9/fHORMmYSaZLDMT5vm+X695zTPnWeZ7ZmC+Oed5nnNEVTHGGGMAMlIdgDHGmJ7DkoIxxphmlhSMMcY0s6RgjDGmmSUFY4wxzbJSHUBXDBgwQEtKSjq1786dOykoKOjegHq4INYZgllvq3MwdLbOixcv3qyq+0Vbt08nhZKSEhYtWtSpfcvLyykrK+vegHq4INYZgllvq3MwdLbOIvJJrHXWfWSMMaaZJQVjjDHNEpoURKRIRGaJyHsiskJEjheRfiLyoois9M99/bYiIneLyCoRqRCR0YmMzRhjzN4SfU7hLuB5VT1XRLKBfOAnwAJVnSYiU4ApwI3AacDB/nEccL9/NsaYblNfX8/atWupra1NdShdVlhYyIoVK2Kuz83NZejQoYRCobiPmbCkICKFwInAdwBUdTewW0TOBsr8Zg8B5bikcDbwsLrBmN7wrYxBqro+UTEaY4Jn7dq19O7dm5KSEkQk1eF0yY4dO+jdu3fUdarKli1bWLt2LcOHD4/7mJKoAfFEZCQwHXgXOBpYDFwNVKpqkd9GgK2qWiQiTwPTVHWhX7cAuFFVF7U67iRgEkBxcfGYGTNmdCiuf6yr54kP6tlS20T/3AzO+WKILw2OP4vuy6qrq+nVq1eqw0i6INbb6hxbYWEhBx544D6fEAAaGxvJzMyMuV5V+fDDD6mqqmpRftJJJy1W1dJo+ySy+ygLGA1cpapvishduK6iZqqqItKhrKSq03HJhtLSUu3I5VhzllTyyIJl1NQrIGypVR5Z0cjhhx3OhFFDOhLGPimIl+xBMOttdY5txYoV9OnTJ/EBJUFbLYWw3NxcRo0aFfcxE3mieS2wVlXf9K9n4ZLEBhEZBOCfN/r1lcCwiP2H+rJuc8f896mpb2xRVlPfyB3z3+/OtzHGmH1WwpKCqn4GrBGRQ3zReFxX0jzgUl92KTDXL88DLvFXIY0Fqrr7fMK6bTUdKjfGmO62bds27rvvvg7vd/rpp7Nt27YERNRSou9TuAp4VEQqgJHAbcA04GQRWQl8zb8GeBb4CFgF/AH4UXcHM7goL2p5hghzlnRro8QYkybmLKlk3LSXGT7lGcZNe7nLvxWxkkJDQ0Ob+z377LMUFRV16b3jkdBLUlV1KRDtZMb4KNsqcEUi47n+lEO4afayvbqQGlW5afYygECcWzDGxGfOksoWvxmV22q6/FsxZcoUPvzwQ0aOHEkoFCI3N5e+ffvy3nvv8cEHHzBhwgTWrFlDbW0tV199NZMmTQL2DOtTXV3NaaedxgknnMDChQsZNmwYc+fOJS8v+h+9HbVPj33UUeEv8T9nvk1jq6uuwucWLCkYExy/eOod3l23Peb6JZ9uY3djU4uymvpGbphVwWP//DTqPocP7sMtZx4R85jTpk1j+fLlLF26lPLycs444wyWL1/efNnogw8+SL9+/aipqeGYY47hnHPOoX///i2OsXLlSh577DF++9vfcvnll/PEE09w8cUXx1vtNgVumIsJo4bQFOMyXDu3YIyJ1DohtFfeGccee2yL+wjuvvtujj76aMaOHcuaNWtYuXLlXvsMHz6ckSNHAjBmzBhWr17dbfEEqqUQNrgoj8ooCaAwLxj3KxhjnLb+ogcYN+3lqL8VQ4ryePwHx3dLDJFDX5eXl/PSSy/x+uuvk5+fT1lZWdQ7r3NycpqXMzMzqanpvj9oA9dSAHduIdrtHjt3N9gJZ2NMs+tPOYS8UMtfi7xQJtefckiMPdrXu3dvduzYEXVdVVUVffv2JT8/n/fee4833nij0+/TWYFMChNGDSFao6C+Ue2eBWNMswmjhvCrbx3FkKI8BNdC+NW3jurSucf+/fszbtw4jjzySK6//voW60499VQaGho47LDDmDJlCmPHju1iDToukN1HANX10cvtvIIxJtKEUUO6/QKUv/zlL1HLc3JyeO6556KuC583GDBgAMuXL28uv+6667o1tkC2FAD650Yf9yTWvQzGGBMEgU0K53wx1O19hcYYs68LbFL40uAQv/rWUfTJdT1ogwpzu9xXaIwx+7rAJgVwfYUTS90YfJ9V1XLH/Pft6iNjTKAFOinMWVLJI298AoCy5xZ2SwzGmKAKdFK4Y/771DXsfQu7XZZqjAmqQCcFG0rbGNPThWeTW7duHeeee27UbcrKyli0aFHUdR0V6KQQ6/JTuyzVGNOsYibceSRMLXLPFTNTEsbgwYOZNWtWwt8n0EkhEbewG2PSSMVMeGoyVK0B1D0/NblLiWHKlCnce++9za+nTp3KL3/5S8aPH8/o0aM56qijmDt37l77rV69miOPPBKAmpoaLrjgAkpLS/nmN7/ZrWMfBfaOZtgzlPbNc5ezvbaBwYW53HDqoXZZqjFB8dwU+GxZ7PVr34LGupZl9TUw90pY/FD0fQYeBadNi74OOP/887nmmmu44go3fczMmTOZP38+kydPpk+fPmzevJmxY8dy1llnIRL9Jtv777+f/Px8Fi1axMcff8zo0aPbrGZHBDopgEsMDU3KdX99m0e/P5bhAwra38kYEwytE0J75XEYNWoUGzduZN26dWzatIm+ffsycOBArr32Wl577TUyMjKorKxkw4YNDBw4MOoxXnvtNSZPngzAiBEjGDFiRKfjaS3wSQHcjWvg7lWwpGBMgLTxFz3gziFUrdm7vHAYXPZMp9/2vPPOY9asWXz22Wecf/75PProo2zatInFixcTCoUoKSmJOmR2MgT6nEJYcR+XFDZsT82XYIzpocbfDKFWF56E8lx5F5x//vnMmDGDWbNmcd5551FVVcX+++9PKBTilVde4ZNPPmlz/xNPPLF5UL3ly5dTUVHRpXgiWUsBGOhbCuurLCkYYyKMmOieF9wKVWuhcKhLCOHyTjriiCPYsWMHQ4YMYdCgQVx00UWceeaZHHXUUZSWlnLooYe2uf9//Md/cNlll1FaWsoRRxzBmDFjuhRPJEsKQK+cLHrnZFlLwRiztxETu5wEolm2bM8J7gEDBvD6669H3a66uhqAkpKS5iGz8/LymDFjBjt27KB3797dGpd1H+GGu6ipb+RP/1jNuGkv2zAXxpjACnxSmLOkkptmL6OhSQEb/8gYE2yBTwp3zH+fmvrGFmU2/pEx6U1VUx1CUnSmnoFPCjb+kTHBkpuby5YtW9I+MagqW7ZsITc3t0P7JfREs4isBnYAjUCDqpaKSD/gcaAEWA1MVNWt4m7duws4HdgFfEdV/5XI+MCNc1QZJQHY+EfGpKehQ4eydu1aNm3alOpQuqy2trbNH/3c3FyGDh3aoWMm4+qjk1R1c8TrKcACVZ0mIlP86xuB04CD/eM44H7/3L0qZsKCW/lK1VpYMpTfHX4Vl7z1hRZdSDb+kTHpKxQKMXz48FSH0S3Ky8sZNWpUtx4zFd1HZwPhQUMeAiZElD+szhtAkYgM6tZ3jhjcSvzgVscsu4WHj/mEvvkhAPbvnWPTchpjAksS2a8mIh8DW3ETm/1eVaeLyDZVLfLrBdiqqkUi8jQwTVUX+nULgBtVdVGrY04CJgEUFxePmTFjRtzxjH39e+TW7d1krM3Zjz8e/Ht+s6iWm47N5ZB+mVH23vdVV1c3j80eJEGst9U5GDpb55NOOmmxqpZGW5fo7qMTVLVSRPYHXhSR9yJXqqqKSIeykqpOB6YDlJaWallZWfw7l2+OWpxbt4mzBqzhN+zHAYceSdnhxR0JaZ9RXl5Ohz6vNBHEeludgyERdU5o95GqVvrnjcCTwLHAhnC3kH/e6DevBIZF7D7Ul3WfwtgnXIYunMJZGQupqqnv1rc0xph9ScKSgogUiEjv8DLwdWA5MA+41G92KRCeTWIecIk4Y4EqVV3frUFFG9zKy2io4YasmZYUjDGBlsjuo2LgST9JRBbwF1V9XkTeAmaKyOXAJ0B4UJFncZejrsJdknpZt0cUHr9k9vejrh4sWywpGGMCLWFJQVU/Ao6OUr4FGB+lXIErEhVPsxET/YiHe4+R/pn0Z7slBWNMgAXzjubxN9OYkdOyLJTH9NDF1lIwxgRaMJPCiIm8f8gVkBlxJ2BWHvnZmZYUjDGBFsyk0Cziatiaz7l61z0c9fn81IVjjDEpFtikcMBHj+w1+XaO1nHhjj+lJiBjjOkBApsUcuqi38i2n0YvN8aYIAhsUqjLGRC1fF1Tf5t9zRgTWIFNCh8d8O29bmTbpdnc3jDRZl8zxgRWYJPCxuKvwJl3Q24RAOua+jGl/nvMazoBsNnXjDHBlIz5FHquERMhpzc8dgFX1k/mX/rFFqtt9jVjTNAEtqXQbPNKAJ7InsrC7MmclbGweZXNvmaMCZpgtxQqZkL5bQCIwFDZzLTQH6EeXsz8is2+ZowJnGC3FBbcCvUtu4jyZTdTsmfa7GvGmEBqNymIyO0i0kdEQiKyQEQ2icjFyQgu4arWRi0exBZLCMaYQIqnpfB1Vd0OfANYDRwEXJ/IoJImxqQ7u3IHJjkQY4zpGeJJCiH/fAbwV1WtSmA8yRVl0p1dms2bB1yZooCMMSa14kkK8/zcymOABSKyH1Cb2LCSZMREf69CIQDaZwhT6r/Hsn6npDgwY4xJjTaTgohkAE8BXwJKVbUeNyva2UmILTlGTITTbgdALpnHC5knsmt3Q4qDMsaY1GgzKahqE3Cvqn6uqo2+bKeqfpaU6JKlV7F7rt5AQXYWOy0pGGMCKp7uowUico74yZbTUkRSyM/JZGddY2rjMcaYFIknKfwA+CuwW0S2i8gOEdme4LiSqzkpbHQthTprKRhjgqndO5pVtXcyAkmpvL6QkQXVn1GQM4Jdu62lYIwJpriGuRCRs4AT/ctyVX06cSGlQEaGay1UbyQ/O5NqaykYYwIqnjuapwFXA+/6x9Ui8qtEB5ZUFTNh50ZY+ii/W38xx+1YkOqIjDEmJeJpKZwOjPRXIiEiDwFLgJsSGVjSVMyEpyZDYz0A/Rs2cnXDPVBxqLtc1RhjAiTeAfGKIpYLExFIykQZFC+POldujDEBE09SuA1YIiJ/8q2ExcB/x/sGIpIpIktE5Gn/eriIvCkiq0TkcRHJ9uU5/vUqv76k49XphBiD4sUsN8aYNBbPHc1NwFhgNvAEcLyqPt6B97gaWBHx+tfAnap6ELAVuNyXXw5s9eV3+u0SL8ageFpoo6QaY4Innjuab1DV9ao6zz/ivptZRIbiBtL7o38twFeBWX6Th4AJfvls/xq/fnxSbpiLMShezYk/S/hbG2NMTyOq2vYG7uqjzcDjwM5wuap+3u7BRWYBvwJ6A9cB3wHe8K0BRGQY8JyqHikiy4FTVXWtX/chcJyqbm51zEnAJIDi4uIxM2bMiK+mrVRXV9OrVy8A9t/wKget/CPZDdvZntmXn9X8O2Unnky/3PSagyiyzkESxHpbnYOhs3U+6aSTFqtqabR18Vx9dL5/viKiTIED2tpJRL4BbFTVxSJSFk+g8VDV6cB0gNLSUi0r69yhy8vL2bNvGawaB38+h7fH3cu8F2Dy6GM5aP/0+gfWss7BEcR6W52DIRF1bjMp+HMKUzp4DiFsHHCWiJwO5AJ9gLuAIhHJUtUGYChQ6bevBIYBa0UkC3eV05ZOvG/n5LoLrHqzEyiwkVKNMYEUzzmFTs2ypqo3qepQVS0BLgBeVtWLgFeAc/1mlwJz/fI8/xq//mVtr2+rO/k5FdasXw/AWff8nXHTXmbOksq29jLGmLQST6f5SyJynYgME5F+4UcX3vNG4McisgroDzzgyx8A+vvyHwNTuvAeHeeTwuL3VjcXVW6r4abZyywxGGMCI2HnFCKpajlQ7pc/Ao6Nsk0tcF68x+x2OX0AyG/a2aK4pr6RO+a/z4RRdomqMSb9xTNK6vBkBJJyoVxqNUQf2bXXqnXbaqLsYIwx6Sdm95GI3BCxfF6rdbclMqhUqZZe9GHnXuWDi/KibG2MMemnrXMKF0Qstx787tQExJJyOb36UpTRsqWQF8rk+lMOSVFExhiTXG11H0mM5Wiv00Lvov6MycuANe71kKI8rj/lEDufYIwJjLaSgsZYjvY6PeQWUqxbyc/O5OKxX+Anpx+W6oiMMSap2koKR/u5mAXIi5iXWXA3o6Wf3ELYupq8UCY1NiWnMSaAYiYFVc1MZiA9Qm4h1FaRG8qkpt6SgjEmeNJrxLeuqJgJy/4KOzcxu24SR2yZn+qIjDEm6SwpwJ4pOet2AFCsm7hww29cuTHGBIglBYg6JWeO2pScxpjgsaQANiWnMcZ4MU80i8gO2rj0VFX7JCSiVCgcClVropcbY0yAxGwpqGpv/8N/F27E0iG4+Q9uBH6XnPCSJMqUnLXkuHJjjAmQeLqPzlLV+1R1h6puV9X7cfMpp48RE+HMu6FXMQDVmUX8d+YPXbkxxgRIPElhp4hcJCKZIpIhIhdBlFHj9nUjJsKlTwPw/LBrmds4LsUBGWNM8sWTFC4EJgIb/OM8X5Z+svMBKMioo7a+KcXBGGNM8sUzn8Jq0q27KJbsAgDyqWN3YxMNjU1kZdoFWsaY4Gj3F09EvigiC0RkuX89QkR+lvjQUiAUTgq1ANQ2WGvBGBMs8fwZ/AfcfAr1AKpaQcu5FtJHVjZkZpOnLinYoHjGmKCJJynkq+o/W5U1JCKYHiG7gFx1dzfX2qB4xpiAiScpbBaRA/E3sonIucD6hEaVStm9yGlyScFGSjXGBE27J5qBK4DpwKEiUgl8DFyU0KhSKbuAHN9SsO4jY0zQtJkURCQT+JGqfk1ECoAMVd2RnNBSJJRPqNFaCsaYYGozKahqo4ic4JfT74a1aLILCNVYUjDGBFM83UdLRGQe8Fci7mRW1dlt7SQiucBrQI5/n1mqeouIDAdmAP2BxcC3VXW3iOQADwNjgC3A+f4eieTK7kVW9VYAaq37yBgTMPGcaM7F/Uh/FTjTP74Rx351wFdV9WhgJHCqiIwFfg3cqaoHAVuBy/32lwNbffmdfrvkyy4gs2EXYC0FY0zwxHNH82WdObCqKlDtX4b8Q3HJJTxMxkPAVCA8yN5UXz4LuEdExB8nebILyKh3DSJLCsaYoGk3KfhuoMuBI3CtBgBU9btx7JuJ6yI6CLgX+BDYpqrh+xzW4obkxj+v8cduEJEqXBfT5lbHnARMAiguLqa8vLy9MKKqrq6Ouu+BG7cysHY7AMtXfEB5zcedOn5PFKvO6S6I9bY6B0Mi6hzPOYVHgPeAU4BbcZejrojn4KraCIwUkSLgSeDQTsYZeczpuEtkKS0t1bKysk4dp7y8nKj7Ni1EK58GlCH/VkJZ2cGdjrWniVnnNBfEeludgyERdY7nnMJBqvpzYKeqPgScARzXkTdR1W3AK8DxQJGIhJPRUKDSL1cCwwD8+kLcuYzkyi5AtIkc6vnNCx8wbtrLzFlS2f5+xhiTBuJJCvX+eZuIHIn7sd6/vZ1EZD/fQkBE8oCTcS2MV4Bz/WaXAnP98jz/Gr/+5aSfTwDe3uB6tgr8oHiV22q4afYySwzGmECIJylMF5G+wM9xP9zvArfHsd8g4BURqQDeAl5U1adx03n+WERW4c4ZPOC3fwDo78t/jJsCNOmeeq8KgHypbS6rqW/kjvnvpyIcY4xJqniuPvqjX3wVOCDeA/vRVEdFKf8IODZKeS1uAp+UqtyZCdl7Wgph67bVpCgiY4xJnniuPoo6e72q3tr94aRebkEfqN87KQwuyktRRMYYkzxxzdEc8WgETgNKEhhTSk0avgmAJ7KnsjB7MmdlLCQvlMn1pxyS4siMMSbx4uk++p/I1yLyG2B+wiJKpYqZHPbRgwCIwFDZzK+zH+Dbo0s4ZtSpKQ7OGGMSrzMTEOfjLiVNPwtuhYa6FkV51HHMh/+booCMMSa54jmnsAw/wQ6QCeyHu4kt/VSt7Vi5McakmXjuaI4c/K4B2BAxTEV6KRwKVWuilxtjTADE0320I+JRA/QRkX7hR0KjS7bxN0Oo1VVGoTxXbowxARBPS+FfuOEntgICFAGf+nVKB+5d6PFGTHTPs7+PAut0AEPO/NWecmOMSXPxtBReBM5U1QGq2h/XnfSCqg5X1fRJCGEjJkJuEUsHnseXd9+NHpXy++mMMSZp4kkKY1X12fALVX0O+FLiQuoBsgvIpY4mhd2NTamOxhhjkiaepLBORH4mIiX+8VNgXaIDS6lQPjnqLk2t3W1JwRgTHPEkhX/HXYb6pH/s78vSV3Y+OeqGubDZ14wxQRLPHc2fA1cD+NFSt6ViSOukCuWTXW9JwRgTPDFbCiJys4gc6pdzRORlYBWwQUS+lqwAUyKUT6jRjYpas9uSgjEmONrqPjofCE8icKnfdn/gK8BtCY4rtbLzyWqyloIxJnjaSgq7I7qJTgEeU9VGVV1BfPc37LtCBWT5lkKtJQVjTIC0lRTqRORIEdkPOAl4IWJdfmLDSrHsfDIbrPvIGBM8bf3FfzUwC3fl0Z2q+jGAiJwOLElCbKkTyiezYRdg3UfGmGCJmRRU9U3g0CjlzwLP7r1HGgnlIw01gFpSMMYESmfmU0h/2fkISg711FlSMMYEiCWFaEIFAORTay0FY0ygWFKIxg+fnU8dNTbMhTEmQOK6tFREvgSURG6vqg8nKKbUy3YXVxVm1VtLwRgTKPFMx/kIcCCwFAj/QiqQvknBdx/1DdXbfQrGmECJp6VQChye9uMdRfIthT6ZDXafgjEmUOI5p7AcGNjRA4vIMBF5RUTeFZF3RCQ8qF4/EXlRRFb6576+XETkbhFZJSIVIjK6o+/ZbXxLoTBrt3UfGWMCJZ6kMAB4V0Tmi8i88COO/RqA/1TVw4GxwBUicjgwBVigqgcDC/xrgNOAg/1jEnB/B+vSffyJ5t6Zdk7BGBMs8XQfTe3MgVV1PbDeL+8QkRXAEOBsoMxv9hBQDtzoyx/23VRviEiRiAzyx0mucPdRRp2dUzDGBEo88ym82tU3EZESYBTwJlAc8UP/GVDsl4cAayJ2W+vLWiQFEZmEa0lQXFxMeXl5p2Kqrq6OuW9o9zbGARl1VXy26fNOv0dP01ad01kQ6211DoZE1Dmeq4/GAv8LHAZkA5nATlXtE88biEgv4AngGlXdLiLN61RVRaRDJ7BVdTowHaC0tFTLyso6snuz8vJyYu67eyf8A/YvyCRbelFW9uVOvUdP02ad01gQ6211DoZE1Dmecwr34KbfXAnkAd8D7o3n4CISwiWER1V1ti/eICKD/PpBwEZfXgkMi9h9qC9Lvix3TqFA7ESzMSZY4rqjWVVXAZl+PoX/B5za3j7imgQPACtU9bcRq+bhJu3BP8+NKL/EX4U0FqhKyfkEgOWzUOC0LQ/xcNXlTP3lLcxZkpr8ZIwxyRTPieZdIpINLBWR23F9/PEkk3HAt4FlIrLUl/0EmAbMFJHLgU+AiX7ds8DpuCk/dwGXxV2L7lQxk4a5V7kPRmCobOaG+vu4+ckG4EdMGDUkJWEZY0wyxJMUvo1LAlcC1+K6eM5pbydVXQhIjNXjo2yvwBVxxJNYC24lq7G2RVG+7OYancH588dbUjDGpLV4rj76RETygEGq+oskxJRaVWujFg+WLazbVpPkYIwxJrna7QYSkTNx4x4971+PjPPmtX1T4dCoxeu0P4OL8pIcjDHGJFc85wamAscC2wBUdSkwPIExpdb4m2nIzG1RtEuz+R0XcP0ph6QoKGOMSY54zinUq2pV5P0FuFFS09OIiWQBDXOuJLOpjsqmAfw+dBEnfOMHdj7BGJP24kkK74jIhUCmiBwMTAb+kdiwUmzERLLee4Yda5Zxwqb/4qUrv8JB+/dKdVTGGJNw8XQfXQUcAdQBjwHbgWsSGVSPkF1AVqM7sWzjHxljgiKeq492AT/1j+AI5TUnBbur2RgTFDGTQntXGKnqWd0fTg8SyiezYReATbRjjAmMtloKx+NGLX0MN7pprBvR0lN2ARmNdQhN1lIwxgRGW0lhIHAybjC8C4FngMdU9Z1kBJZyITenQh677ZyCMSYwYp5o9oPfPa+ql+JmTlsFlIvIlUmLLpX87Gv51Fn3kTEmMNo80SwiOcAZuNZCCXA38GTiw+oBst08zXlSa91HxpjAaOtE88PAkbjRS3+hqsuTFlVP4LuP8qmzpGCMCYy2WgoXAzuBq4HJEXc0C25Q07hmXttn+ZZCvuym1rqPjDEBETMpqGpcE/CkLd9SKMqqt5aCMSYwgv3D3xZ/ornQkoIxJkAsKcTiu4/6ZO6mZndTioMxxpjksKQQi+8+6pNp9ykYY4LDkkIsvqXQO8O6j4wxwWFJIRbfUuiVsdtuXjPGBIYlhViycgBxScFaCsaYgLCkEIsIZBdQILV2TsEYExiWFNoSyidfrKVgjAkOSwptyc4nzwbEM8YEiCWFNlQ1hNi8dSsbd9QxbtrLzFlSmeqQjDEmoRKWFETkQRHZKCLLI8r6iciLIrLSP/f15SIid4vIKhGpEJHRiYorXm/N+z152z/ma7zFwuzJjNn+IjfNXmaJwRiT1hLZUvgTcGqrsinAAlU9GFjgXwOcBhzsH5OA+xMYV/sqZnLkv35OtjQgAkMzNjMt9EdObnyVO+a/n9LQjDEmkRKWFFT1NeDzVsVnAw/55YeACRHlD6vzBlAkIoMSFVu7FtxKHnUtivJlNzdkzWTdtpoUBWWMMYnX5iQ7CVCsquv98mdAsV8egpsPOmytL1tPKyIyCdeaoLi4mPLy8k4FUl1dHXPfr1StjToh9WDZQr9c6fR7plpbdU5nQay31TkYElHnZCeFZqqqIqKd2G86MB2gtLRUy8rKOvX+5eXlxNx3yVCoWrNX8Xr68/Ozj6Zs1JBOvbe7OEQAABEuSURBVGeqtVnnNBbEeludgyERdU721Ucbwt1C/nmjL68EhkVsN9SXpcb4m5uHzg6rIZt1Y25gwj6aEIwxJh7JTgrzgEv98qXA3IjyS/xVSGOBqohupuQbMRHOvBtyiwBY19SPVw/5Ocec9YOUhWSMMcmQsO4jEXkMKAMGiMha4BZgGjBTRC4HPgEm+s2fBU4HVgG7gMsSFVfcRkwEyYAnLueKzJs5Iq90r0upjDEm3SQsKajqv8dYNT7KtgpckahYOi3PtRRKCnazYXtdOxsbY8y+z+5obktePwCG5dayYXttioMxxpjEs6TQlry+AAzJqbGkYIwJBEsKbfFJQWq2smF7HcOnPGNjIBlj0polhbbkFtIkmWze9BkAClRuq7ExkIwxacuSQltEqNIC+uiOFsU19Y02BpIxJi1ZUmjH500FFMnOvcptDCRjTDqypNCOXZl9KGLHXuWFeaEURGOMMYllSaEd++0/kL5RWgo7dzfYeQVjTNqxpNCWipkM/PwtDs9YzcLsyZyVsbB5VX2j2nkFY0zasaQQS8VMeGoy1O9C2DPRTmRiqLTzCsaYNGNJIZYFt0J9yx/98EQ7kX42Z1kyozLGmISypBBL1dqoxYNlS4vXj77xqZ1bMMakDUsKsRQOjVrchLToQlLgmseX2p3Oxpi0YEkhligT7QBkSdNe5xbAnV+49vGl1p1kjNmnWVKIJTzRjmTutSrauQVwrYY/v/EpR9z8vLUajDH7JEsKbRkxEbQp6qrBsjnmbjt3N3LN40spmfIMJVOeYdStL1iSMMbsExI2yU7aKBwKVWv2KhZgec53+Un9d5nXdEKbh9i6q55rHl/KNY8vbS7rmx/iljOPsDmfjTE9iiWF9oy/GWZPwnUO7SECvajlrtB93MV9VOoAbm+Y2G6CCIuWKMCShTEmtSwptGfERJj9/ZirRdzzUNncnCCaEDLQDicKiJ0sorEEYozpbpYU4lE4LGoXUmvhBJHpWxWRiQJcW0Na7ZOsBNLs+WeaFy2pGGNas6QQjxhdSPGQiCzQOiFAxxJItLIubdsIzIHGOS4xNZJBJk2dSlDRZAg0KQwpyuP6Uw6x5GPMPsCSQjxGTIRP34BFDyT0bdpLINHKumPbcGLKwl1pFU5Qv+O+7klMNcAc0DlxbNuR40bYSi+eahzL+IylDJbNrGud2CJaSK1Zi8mYPUS143/99hSlpaW6aNGiTu1bXl5OWVlZx3aqmAlPXQP1ew+lbVJPtWViVU1A68q2Te224srjPU7akgzQJmpz9iP3jNvcH64d2V1ksaqWRltnLYWOGDHRPSpmugHz4jjPYJJHZO/XiWpd2bY9Z9t41qUdf/9Ubt0mGuZe5X7IO5gYYulRN6+JyKki8r6IrBKRKamOJ6YRE+Ha5TC1Cr71B8jrl+qIjDEBldVYy67nbu6+43XbkbpIRDKBe4GTgbXAWyIyT1XfTW1k7Qi3HiJVzITnboSaz1MTkzEmUHJrPuu2Y/WYpAAcC6xS1Y8ARGQGcDbQs5NCNNESRSxJTCDhPleNLPBad70YY/Yd65r6E31c547rSUlhCBDZSb8WOK71RiIyCZgEUFxcTHl5eaferLq6utP7dq/94bj/l5R3qq6uplevXntHsOFVDvjoEXLqNnXryToFJMp1DN19EtISmgmyXZrN/Rnnc3I3/Z71pKQQF1WdDkwHd/VRh68g8jp19dE+Lnady4BbgO49WZeUk5CRJ/0lE7SRVu2hNhNO5EKPvurGtrVtI0Te9Po7LuCECT+irJsuqe5JSaESGBbxeqgvMya2OLrqXo2RDFv/Z+sJV9J017at/wDo6fHGUzZnSSVT573Dtpr6GEcKjvCNof1zhZ+ffXS33mPTk5LCW8DBIjIclwwuAC5MbUjGmJ5iwqghbf74Bbb13803XfaYpKCqDSJyJTAfyAQeVNV3UhyWMcYESo9JCgCq+izwbKrjMMaYoOpRN68ZY4xJLUsKxhhjmllSMMYY02yfHiVVRDYBn3Ry9wHA5m4MZ18QxDpDMOttdQ6Gztb5C6q6X7QV+3RS6AoRWRRr6Nh0FcQ6QzDrbXUOhkTU2bqPjDHGNLOkYIwxplmQk8L0VAeQAkGsMwSz3lbnYOj2Ogf2nIIxxpi9BbmlYIwxphVLCsYYY5oFMinsM3NBd5GIrBaRZSKyVEQW+bJ+IvKiiKz0z31THWdXiMiDIrJRRJZHlEWtozh3+++9QkRGpy7yzotR56kiUum/66UicnrEupt8nd8XkVNSE3XXiMgwEXlFRN4VkXdE5GpfnrbfdRt1Tux3raqBeuBGYP0QOADIBt4GDk91XAmq62pgQKuy24EpfnkK8OtUx9nFOp4IjAaWt1dH4HTgOdxw/WOBN1MdfzfWeSpwXZRtD/f/xnOA4f7ffmaq69CJOg8CRvvl3sAHvm5p+123UeeEftdBbCk0zwWtqruB8FzQQXE28JBffgiYkMJYukxVXwNaT3Adq45nAw+r8wZQJCKDkhNp94lR51jOBmaoap2qfgyswv0f2Keo6npV/Zdf3gGswE3hm7bfdRt1jqVbvusgJoVoc0F37ywVPYcCL4jIYj+3NUCxqq73y58BxakJLaFi1THdv/srfVfJgxHdgmlXZxEpAUYBbxKQ77pVnSGB33UQk0KQnKCqo4HTgCtE5MTIleranGl9TXIQ6ujdDxwIjATWA/+T2nASQ0R6AU8A16jq9sh16fpdR6lzQr/rICaFwMwFraqV/nkj8CSuKbkh3Iz2zxtTF2HCxKpj2n73qrpBVRtVtQn4A3u6DdKmziISwv04Pqqqs31xWn/X0eqc6O86iEmheS5oEcnGzQU9L8UxdTsRKRCR3uFl4OvAclxdL/WbXQrMTU2ECRWrjvOAS/yVKWOBqoiuh31aq/7yb+K+a3B1vkBEcvz85wcD/0x2fF0lIgI8AKxQ1d9GrErb7zpWnRP+Xaf6DHuKzuqfjjuT/yHw01THk6A6HoC7EuFt4J1wPYH+wAJgJfAS0C/VsXaxno/hmtD1uD7Uy2PVEXclyr3+e18GlKY6/m6s8yO+ThX+x2FQxPY/9XV+Hzgt1fF3ss4n4LqGKoCl/nF6On/XbdQ5od+1DXNhjDGmWRC7j4wxxsRgScEYY0wzSwrGGGOaWVIwxhjTzJKCMcaYZpYUUkBEGv3ohu+IyNsi8p8ikuHXlYrI3X45R0Re8tueLyJf9vssFZG81NYiOhGp7uD2E0Tk8ETFkwgiUiIiF3bxGOUi0u2TzHfHcUWkTES+FPH6hyJySdejAxH5SSf2+Y6I3NMd79+J927xWQSBJYXUqFHVkap6BHAybhiKWwBUdZGqTvbbjfJlI1X1ceAi4Ff+dU17b+Jv3Onp3/EE3OiO+5ISoEtJoYcrA5p/CFX1/1T14W46doeTQoqVEfFZBEKqb9AI4gOobvX6AGAL7oabMuBpYH/cKIdVuJtWfoAbGfNj3C3vANfj7tCuAH7hy0pwN648jLtp7QttbLcCd5v8O8ALQJ5fdxDuRqC3gX8BB8Z6v2h1A+70x1wA7OfLDwSeBxYDfwMOxf1nC9dpKXAcsNhvfzTuxp1/868/BPKB/XC3/b/lH+P8+gLgQdwdnEuAs335d4DZ/r1XArfHiPtmf7zluHlvJdZnAbwR8b1c69/jnohjPQ2U+eX7gUX+8/hFxDblRLmhqo04yoFf+/p9AHzZl+fhRvpdgRvK5M0Yxx0DvOo///n4G56AycC7/jud4f9dfIYbHmEp8GUihmr2cdzp67QCOMZ/viuBX0a83xz/Xu8Ak3zZNKDRHzf8b/hiX6elwO/xQz0Dl/l6/hP3b/SeKHXq59+nwn8nI3x5c7z+9XJfrxLgPeBRH/ssIN9vsxo/zDxQ6usZ7bM4zx/vbeC1VP+WJOT3KdUBBPFBq6Tgy7bhRngsA572Zc3L/vWfgHP98tfDPxq4Ft/TuHH2S4AmYGwc2zUAI/12M4GL/fKbwDf9ci7uxzjqcaLUQ4GL/PLN4f/MuARxsF8+Dni5dZ3863eAPsCVuB/Hi3CJ7XW//i+4gf4A/g03BADAbRHxF+F+UApwP9gfAYW+Lp8Aw6LE3S9i+RHgzDY+i9bfy3eInRTCd9hm4n5owj9c5UT/8Y4VRznwP375dOAlv/xj4EG/PMJ/p6WtjhkC/sGeBH1+xD7rgJzw5+afp9LyR7X5tY8jPGfB1X7/Qbgx/NcC/VvVOw/3Ixour4447mHAU0DIv74PuMQf71PcHwDZwN+JnhT+F7jFL38VWBoj/sikoOz5Q+LBiHqtplVSiHGsZcCQyM8r3R5ZmH3V1/1jiX/dCzfWyafAJ+rGkG9vu49VdakvXwyU+PGShqjqkwCqWgsgIrGO81qruJqAx/3yn4HZfpTHLwF/dcO5AO5HJJp/AONwies24FRcIvqbX/814PCI4/Txx/86cJaIXOfLc3FJA2CBqlb5eryLSzKRQwwDnCQiN+B+9PsB74hIeYzPIkboUU30w5Zn4X7sDsf9ZRvLXnHgfjjB/UUO/rvyyycCd/v4KkQk2rEPAY4EXvSxZ+KGycDH8qiIzMH91R2P8Fhhy4B31I8pJCIf4QZk2wJMFpFv+u2G4f6tbGl1nPG4FsxbPq483IB2x+F+lDf54z4OfDFKHCcA5/i6vywi/UWkTzuxr1HVv/vlP+NaSr9pt8Z7/B34k4jMZM/3kVYsKfQAInIArlm9EffXU1y74c4v/L7VsUqAnXFuVxdR1Ij7T9mh94uD4loW21R1ZBzbv4Zrpn8BN7jZjf4Yz/j1GbhWUG2L4Nyvyjmq+n6r8uPYu55ZrbbJxf2VWqqqa0RkKi6pxKuBlufncv1xhwPXAceo6lYR+VNbx40jjnA99qpDOwT34318lHVn4BLLmcBPReSoOI4XjqOJlp9tE5AlImW45H28qu7yyTVavQV4SFVvalEo0tWJn6J+H17rcX3CryP3ifkdqeoP/b+pM4DFIjJGVVsnu31aTz8JmfZEZD/g/3DN444MRDUf+K7/KxkRGSIi+3dhO6B5hqe14f+Y/gqo/A4cJwM41y9fCCxUNwb8xyJynt9XRORov80O3FSDYX/D9TOvVDc08Oe47pKFfv0LwFXhjUUknGjmA1f55ICIjIpVxyjCPwKbff3ObeezaB3zamCkiGSIyDD2DGXcB5egq0SkGHdBQYfjaMdr+JPeInIkrguptfeB/UTkeL9dSESO8BchDFPVV3DJtxDXAmxdv44qBLb6hHAobjrMsHpxw0GD61I8N/zvSNx8y1/Addl9xf/lH8L140fzN1z3Ij4Rbfb/1lbjpitF3NzMwyP2+bfw54D/9+mXV+NaLeBbH16Lz0JEDlTVN1X1ZmATLYeqTguWFFIjL3xJKu4k5gvALzpyAFV9Ade//rqILMOdNNvrP3K827XybVzzvwLXnTOwA8fZCRwrblL5rwK3+vKLgMtFJDxqa3gK1BnA9SKyxP+HW437CzLcLbUQ18rY6l9PBkrFzTr1LvBDX/5fuL7zCv+5/lc7dWymqttwJzOX45LLW219Frgul0ZxlxNfi+tS+Bh3wvZu3AlpVPVtXHfbe/6z+zttaCeOWO4HeonICtxnvTjKcXfjEsyv/ee/FNedlwn82X+fS4C7fQxPAd/0/0a/HEcMrT2PazGswJ1cfiNi3XTcd/Soqr4L/Aw3O2AF8CLuBPh6XF/+67jPbEWM95kKjPH7TmPPENpPAP38v4MrceeXwt7HTTi1AuiL+/zA/f+7S0QW4VpiYa0/iztEZJn/9/0P3AnntGKjpBpjAsF3mT6tqkemOJQezVoKxhhjmllLwRhjTDNrKRhjjGlmScEYY0wzSwrGGGOaWVIwxhjTzJKCMcaYZv8fGE8qIczThkMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aShHwxvw6hml"
      },
      "source": [
        "## Mean Absolute Error [MAE]\n",
        "\n",
        "Mean absolute error, on the other hand, is measured as the average of sum of absolute differences between predictions and actual observations. \n",
        "\n",
        "Like MSE, this as well measures the magnitude of error without considering their direction. \n",
        "\n",
        "Unlike MSE, MAE needs more complicated tools such as linear programming to compute the gradients. Plus MAE is more robust to outliers since it does not make use of square.\n",
        "\n",
        "Let's assume there are $n$ data samples, for $i^{th}$ sample; the actual output is $y_i$ and $\\hat{y}_i$ is the estimated output from the regression model. \n",
        "\n",
        "We first take the absolute difference between the original and estimated output with $|y_i - \\hat{y}_i|2$. Then we take sum of the absolute differences for all the samples. And finally divide it by the total count of samples, which is $n$. \n",
        "\n",
        "$$MSE = \\frac{\\sum_{i=1}^{n}|y_i - \\hat{y}_i|}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI9_GEL86hmn",
        "outputId": "02d118e8-96ff-4225-a3e0-09d6541a41e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae'])\n",
        "\n",
        "history = model.fit(train_features, train_labels, epochs=250, validation_split = 0.1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "12/12 [==============================] - 2s 17ms/step - loss: 22.1402 - mae: 22.1402 - val_loss: 20.5132 - val_mae: 20.5132\n",
            "Epoch 2/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 20.9483 - mae: 20.9483 - val_loss: 19.0928 - val_mae: 19.0928\n",
            "Epoch 3/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19.0298 - mae: 19.0298 - val_loss: 16.5866 - val_mae: 16.5866\n",
            "Epoch 4/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.8946 - mae: 15.8946 - val_loss: 12.9357 - val_mae: 12.9357\n",
            "Epoch 5/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.7303 - mae: 11.7303 - val_loss: 7.5935 - val_mae: 7.5935\n",
            "Epoch 6/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8005 - mae: 6.8005 - val_loss: 5.3087 - val_mae: 5.3087\n",
            "Epoch 7/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.0526 - mae: 5.0526 - val_loss: 4.0397 - val_mae: 4.0397\n",
            "Epoch 8/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.9138 - mae: 3.9138 - val_loss: 3.3954 - val_mae: 3.3954\n",
            "Epoch 9/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.4624 - mae: 3.4624 - val_loss: 3.2312 - val_mae: 3.2312\n",
            "Epoch 10/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.3120 - mae: 3.3120 - val_loss: 3.1278 - val_mae: 3.1278\n",
            "Epoch 11/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.1273 - mae: 3.1273 - val_loss: 2.9489 - val_mae: 2.9489\n",
            "Epoch 12/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9676 - mae: 2.9676 - val_loss: 2.7342 - val_mae: 2.7342\n",
            "Epoch 13/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.8276 - mae: 2.8276 - val_loss: 2.6249 - val_mae: 2.6249\n",
            "Epoch 14/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.7294 - mae: 2.7294 - val_loss: 2.4751 - val_mae: 2.4751\n",
            "Epoch 15/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.6302 - mae: 2.6302 - val_loss: 2.5167 - val_mae: 2.5167\n",
            "Epoch 16/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.5835 - mae: 2.5835 - val_loss: 2.5833 - val_mae: 2.5833\n",
            "Epoch 17/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.4814 - mae: 2.4814 - val_loss: 2.3641 - val_mae: 2.3641\n",
            "Epoch 18/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.4488 - mae: 2.4488 - val_loss: 2.4302 - val_mae: 2.4302\n",
            "Epoch 19/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.3711 - mae: 2.3711 - val_loss: 2.3817 - val_mae: 2.3817\n",
            "Epoch 20/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.3482 - mae: 2.3482 - val_loss: 2.2939 - val_mae: 2.2939\n",
            "Epoch 21/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.3089 - mae: 2.3089 - val_loss: 2.3233 - val_mae: 2.3233\n",
            "Epoch 22/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.2835 - mae: 2.2835 - val_loss: 2.2015 - val_mae: 2.2015\n",
            "Epoch 23/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.2188 - mae: 2.2188 - val_loss: 2.2089 - val_mae: 2.2089\n",
            "Epoch 24/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.2239 - mae: 2.2239 - val_loss: 2.2679 - val_mae: 2.2679\n",
            "Epoch 25/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1973 - mae: 2.1973 - val_loss: 2.1653 - val_mae: 2.1653\n",
            "Epoch 26/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.1369 - mae: 2.1369 - val_loss: 2.1481 - val_mae: 2.1481\n",
            "Epoch 27/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.1126 - mae: 2.1126 - val_loss: 2.2126 - val_mae: 2.2126\n",
            "Epoch 28/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0968 - mae: 2.0968 - val_loss: 2.1405 - val_mae: 2.1405\n",
            "Epoch 29/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.0672 - mae: 2.0672 - val_loss: 2.1979 - val_mae: 2.1979\n",
            "Epoch 30/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0549 - mae: 2.0549 - val_loss: 2.1210 - val_mae: 2.1210\n",
            "Epoch 31/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.0853 - mae: 2.0853 - val_loss: 2.2270 - val_mae: 2.2270\n",
            "Epoch 32/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.0599 - mae: 2.0599 - val_loss: 2.0519 - val_mae: 2.0519\n",
            "Epoch 33/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.0462 - mae: 2.0462 - val_loss: 2.0742 - val_mae: 2.0742\n",
            "Epoch 34/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9932 - mae: 1.9932 - val_loss: 2.1277 - val_mae: 2.1277\n",
            "Epoch 35/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9992 - mae: 1.9992 - val_loss: 2.0889 - val_mae: 2.0889\n",
            "Epoch 36/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9392 - mae: 1.9392 - val_loss: 2.1440 - val_mae: 2.1440\n",
            "Epoch 37/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9824 - mae: 1.9824 - val_loss: 2.1501 - val_mae: 2.1501\n",
            "Epoch 38/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.9509 - mae: 1.9509 - val_loss: 2.0286 - val_mae: 2.0286\n",
            "Epoch 39/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9379 - mae: 1.9379 - val_loss: 2.1185 - val_mae: 2.1185\n",
            "Epoch 40/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9447 - mae: 1.9447 - val_loss: 2.0181 - val_mae: 2.0181\n",
            "Epoch 41/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8908 - mae: 1.8908 - val_loss: 2.0690 - val_mae: 2.0690\n",
            "Epoch 42/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9173 - mae: 1.9173 - val_loss: 2.0861 - val_mae: 2.0861\n",
            "Epoch 43/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8756 - mae: 1.8756 - val_loss: 2.0280 - val_mae: 2.0280\n",
            "Epoch 44/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8578 - mae: 1.8578 - val_loss: 2.0666 - val_mae: 2.0666\n",
            "Epoch 45/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8552 - mae: 1.8552 - val_loss: 1.9612 - val_mae: 1.9612\n",
            "Epoch 46/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8337 - mae: 1.8337 - val_loss: 2.1531 - val_mae: 2.1531\n",
            "Epoch 47/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8565 - mae: 1.8565 - val_loss: 2.1580 - val_mae: 2.1580\n",
            "Epoch 48/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8637 - mae: 1.8637 - val_loss: 2.0139 - val_mae: 2.0139\n",
            "Epoch 49/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8423 - mae: 1.8423 - val_loss: 2.1301 - val_mae: 2.1301\n",
            "Epoch 50/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8328 - mae: 1.8328 - val_loss: 2.0126 - val_mae: 2.0126\n",
            "Epoch 51/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7983 - mae: 1.7983 - val_loss: 2.2515 - val_mae: 2.2515\n",
            "Epoch 52/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8211 - mae: 1.8211 - val_loss: 2.0414 - val_mae: 2.0414\n",
            "Epoch 53/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8000 - mae: 1.8000 - val_loss: 2.1260 - val_mae: 2.1260\n",
            "Epoch 54/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8761 - mae: 1.8761 - val_loss: 2.2187 - val_mae: 2.2187\n",
            "Epoch 55/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7530 - mae: 1.7530 - val_loss: 1.9966 - val_mae: 1.9966\n",
            "Epoch 56/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7644 - mae: 1.7644 - val_loss: 2.0748 - val_mae: 2.0748\n",
            "Epoch 57/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7136 - mae: 1.7136 - val_loss: 2.0306 - val_mae: 2.0306\n",
            "Epoch 58/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7469 - mae: 1.7469 - val_loss: 2.1476 - val_mae: 2.1476\n",
            "Epoch 59/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7103 - mae: 1.7103 - val_loss: 1.9727 - val_mae: 1.9727\n",
            "Epoch 60/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7185 - mae: 1.7185 - val_loss: 2.0604 - val_mae: 2.0604\n",
            "Epoch 61/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6847 - mae: 1.6847 - val_loss: 2.0438 - val_mae: 2.0438\n",
            "Epoch 62/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6581 - mae: 1.6581 - val_loss: 2.1230 - val_mae: 2.1230\n",
            "Epoch 63/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6587 - mae: 1.6587 - val_loss: 1.9551 - val_mae: 1.9551\n",
            "Epoch 64/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6897 - mae: 1.6897 - val_loss: 2.1214 - val_mae: 2.1214\n",
            "Epoch 65/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6377 - mae: 1.6377 - val_loss: 2.1030 - val_mae: 2.1030\n",
            "Epoch 66/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6570 - mae: 1.6570 - val_loss: 1.9871 - val_mae: 1.9871\n",
            "Epoch 67/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7479 - mae: 1.7479 - val_loss: 2.2584 - val_mae: 2.2584\n",
            "Epoch 68/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7316 - mae: 1.7316 - val_loss: 1.9492 - val_mae: 1.9492\n",
            "Epoch 69/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6168 - mae: 1.6168 - val_loss: 2.0534 - val_mae: 2.0534\n",
            "Epoch 70/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6157 - mae: 1.6157 - val_loss: 1.9775 - val_mae: 1.9775\n",
            "Epoch 71/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.6080 - mae: 1.6080 - val_loss: 2.0004 - val_mae: 2.0004\n",
            "Epoch 72/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5970 - mae: 1.5970 - val_loss: 2.0725 - val_mae: 2.0725\n",
            "Epoch 73/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5961 - mae: 1.5961 - val_loss: 2.0708 - val_mae: 2.0708\n",
            "Epoch 74/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5989 - mae: 1.5989 - val_loss: 1.9966 - val_mae: 1.9966\n",
            "Epoch 75/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5385 - mae: 1.5385 - val_loss: 2.0628 - val_mae: 2.0628\n",
            "Epoch 76/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5724 - mae: 1.5724 - val_loss: 2.0172 - val_mae: 2.0172\n",
            "Epoch 77/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5832 - mae: 1.5832 - val_loss: 2.0516 - val_mae: 2.0516\n",
            "Epoch 78/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5630 - mae: 1.5630 - val_loss: 2.0849 - val_mae: 2.0849\n",
            "Epoch 79/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5637 - mae: 1.5637 - val_loss: 1.9252 - val_mae: 1.9252\n",
            "Epoch 80/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5825 - mae: 1.5825 - val_loss: 2.0210 - val_mae: 2.0210\n",
            "Epoch 81/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5687 - mae: 1.5687 - val_loss: 2.0399 - val_mae: 2.0399\n",
            "Epoch 82/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5140 - mae: 1.5140 - val_loss: 1.9452 - val_mae: 1.9452\n",
            "Epoch 83/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5189 - mae: 1.5189 - val_loss: 2.0239 - val_mae: 2.0239\n",
            "Epoch 84/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4969 - mae: 1.4969 - val_loss: 1.9021 - val_mae: 1.9021\n",
            "Epoch 85/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4994 - mae: 1.4994 - val_loss: 2.0180 - val_mae: 2.0180\n",
            "Epoch 86/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5134 - mae: 1.5134 - val_loss: 2.0242 - val_mae: 2.0242\n",
            "Epoch 87/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5102 - mae: 1.5102 - val_loss: 2.0466 - val_mae: 2.0466\n",
            "Epoch 88/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4735 - mae: 1.4735 - val_loss: 1.9586 - val_mae: 1.9586\n",
            "Epoch 89/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4574 - mae: 1.4574 - val_loss: 1.9381 - val_mae: 1.9381\n",
            "Epoch 90/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.5095 - mae: 1.5095 - val_loss: 2.1040 - val_mae: 2.1040\n",
            "Epoch 91/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5552 - mae: 1.5552 - val_loss: 2.0840 - val_mae: 2.0840\n",
            "Epoch 92/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5748 - mae: 1.5748 - val_loss: 1.9426 - val_mae: 1.9426\n",
            "Epoch 93/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.5190 - mae: 1.5190 - val_loss: 2.1559 - val_mae: 2.1559\n",
            "Epoch 94/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5260 - mae: 1.5260 - val_loss: 2.0200 - val_mae: 2.0200\n",
            "Epoch 95/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4530 - mae: 1.4530 - val_loss: 2.0225 - val_mae: 2.0225\n",
            "Epoch 96/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4955 - mae: 1.4955 - val_loss: 2.0231 - val_mae: 2.0231\n",
            "Epoch 97/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.5806 - mae: 1.5806 - val_loss: 2.0003 - val_mae: 2.0003\n",
            "Epoch 98/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4800 - mae: 1.4800 - val_loss: 1.8931 - val_mae: 1.8931\n",
            "Epoch 99/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4601 - mae: 1.4601 - val_loss: 1.9569 - val_mae: 1.9569\n",
            "Epoch 100/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4541 - mae: 1.4541 - val_loss: 1.9893 - val_mae: 1.9893\n",
            "Epoch 101/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4342 - mae: 1.4342 - val_loss: 1.9293 - val_mae: 1.9293\n",
            "Epoch 102/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.4361 - mae: 1.4361 - val_loss: 1.9513 - val_mae: 1.9513\n",
            "Epoch 103/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.4759 - mae: 1.4759 - val_loss: 2.0833 - val_mae: 2.0833\n",
            "Epoch 104/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5066 - mae: 1.5066 - val_loss: 2.0467 - val_mae: 2.0467\n",
            "Epoch 105/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4225 - mae: 1.4225 - val_loss: 1.9414 - val_mae: 1.9414\n",
            "Epoch 106/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4057 - mae: 1.4057 - val_loss: 1.9273 - val_mae: 1.9273\n",
            "Epoch 107/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4238 - mae: 1.4238 - val_loss: 1.9965 - val_mae: 1.9965\n",
            "Epoch 108/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4598 - mae: 1.4598 - val_loss: 1.8893 - val_mae: 1.8893\n",
            "Epoch 109/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4265 - mae: 1.4265 - val_loss: 2.0106 - val_mae: 2.0106\n",
            "Epoch 110/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4485 - mae: 1.4485 - val_loss: 1.9254 - val_mae: 1.9254\n",
            "Epoch 111/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3898 - mae: 1.3898 - val_loss: 1.9710 - val_mae: 1.9710\n",
            "Epoch 112/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3616 - mae: 1.3616 - val_loss: 1.9027 - val_mae: 1.9027\n",
            "Epoch 113/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3596 - mae: 1.3596 - val_loss: 2.0183 - val_mae: 2.0183\n",
            "Epoch 114/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4138 - mae: 1.4138 - val_loss: 1.9198 - val_mae: 1.9198\n",
            "Epoch 115/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4381 - mae: 1.4381 - val_loss: 1.9662 - val_mae: 1.9662\n",
            "Epoch 116/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5047 - mae: 1.5047 - val_loss: 2.0861 - val_mae: 2.0861\n",
            "Epoch 117/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4255 - mae: 1.4255 - val_loss: 1.9546 - val_mae: 1.9546\n",
            "Epoch 118/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3513 - mae: 1.3513 - val_loss: 1.9421 - val_mae: 1.9421\n",
            "Epoch 119/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3277 - mae: 1.3277 - val_loss: 1.9509 - val_mae: 1.9509\n",
            "Epoch 120/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3897 - mae: 1.3897 - val_loss: 2.0068 - val_mae: 2.0068\n",
            "Epoch 121/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4493 - mae: 1.4493 - val_loss: 1.9120 - val_mae: 1.9120\n",
            "Epoch 122/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4377 - mae: 1.4377 - val_loss: 1.9522 - val_mae: 1.9522\n",
            "Epoch 123/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3949 - mae: 1.3949 - val_loss: 1.9082 - val_mae: 1.9082\n",
            "Epoch 124/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3674 - mae: 1.3674 - val_loss: 1.9118 - val_mae: 1.9118\n",
            "Epoch 125/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3424 - mae: 1.3424 - val_loss: 1.8936 - val_mae: 1.8936\n",
            "Epoch 126/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3568 - mae: 1.3568 - val_loss: 1.9241 - val_mae: 1.9241\n",
            "Epoch 127/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3741 - mae: 1.3741 - val_loss: 1.8547 - val_mae: 1.8547\n",
            "Epoch 128/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3221 - mae: 1.3221 - val_loss: 1.9116 - val_mae: 1.9116\n",
            "Epoch 129/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4266 - mae: 1.4266 - val_loss: 1.9245 - val_mae: 1.9245\n",
            "Epoch 130/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3820 - mae: 1.3820 - val_loss: 1.9489 - val_mae: 1.9489\n",
            "Epoch 131/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4388 - mae: 1.4388 - val_loss: 1.8937 - val_mae: 1.8937\n",
            "Epoch 132/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4945 - mae: 1.4945 - val_loss: 1.9068 - val_mae: 1.9068\n",
            "Epoch 133/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3413 - mae: 1.3413 - val_loss: 1.9294 - val_mae: 1.9294\n",
            "Epoch 134/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3139 - mae: 1.3139 - val_loss: 1.9572 - val_mae: 1.9572\n",
            "Epoch 135/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3149 - mae: 1.3149 - val_loss: 1.9140 - val_mae: 1.9140\n",
            "Epoch 136/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3422 - mae: 1.3422 - val_loss: 1.9122 - val_mae: 1.9122\n",
            "Epoch 137/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3155 - mae: 1.3155 - val_loss: 1.8486 - val_mae: 1.8486\n",
            "Epoch 138/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3127 - mae: 1.3127 - val_loss: 1.9133 - val_mae: 1.9133\n",
            "Epoch 139/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2995 - mae: 1.2995 - val_loss: 1.8913 - val_mae: 1.8913\n",
            "Epoch 140/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3163 - mae: 1.3163 - val_loss: 1.9003 - val_mae: 1.9003\n",
            "Epoch 141/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3607 - mae: 1.3607 - val_loss: 1.8701 - val_mae: 1.8701\n",
            "Epoch 142/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3224 - mae: 1.3224 - val_loss: 2.0012 - val_mae: 2.0012\n",
            "Epoch 143/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3932 - mae: 1.3932 - val_loss: 1.9166 - val_mae: 1.9166\n",
            "Epoch 144/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3442 - mae: 1.3442 - val_loss: 1.8988 - val_mae: 1.8988\n",
            "Epoch 145/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2926 - mae: 1.2926 - val_loss: 1.8709 - val_mae: 1.8709\n",
            "Epoch 146/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2691 - mae: 1.2691 - val_loss: 1.8632 - val_mae: 1.8632\n",
            "Epoch 147/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2995 - mae: 1.2995 - val_loss: 1.9864 - val_mae: 1.9864\n",
            "Epoch 148/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3132 - mae: 1.3132 - val_loss: 1.9884 - val_mae: 1.9884\n",
            "Epoch 149/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3079 - mae: 1.3079 - val_loss: 1.9900 - val_mae: 1.9900\n",
            "Epoch 150/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3408 - mae: 1.3408 - val_loss: 1.9215 - val_mae: 1.9215\n",
            "Epoch 151/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3296 - mae: 1.3296 - val_loss: 1.8883 - val_mae: 1.8883\n",
            "Epoch 152/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3181 - mae: 1.3181 - val_loss: 1.9779 - val_mae: 1.9779\n",
            "Epoch 153/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2768 - mae: 1.2768 - val_loss: 1.8622 - val_mae: 1.8622\n",
            "Epoch 154/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2530 - mae: 1.2530 - val_loss: 1.8348 - val_mae: 1.8348\n",
            "Epoch 155/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2360 - mae: 1.2360 - val_loss: 1.8475 - val_mae: 1.8475\n",
            "Epoch 156/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2821 - mae: 1.2821 - val_loss: 1.9483 - val_mae: 1.9483\n",
            "Epoch 157/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2773 - mae: 1.2773 - val_loss: 1.9729 - val_mae: 1.9729\n",
            "Epoch 158/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2479 - mae: 1.2479 - val_loss: 1.8472 - val_mae: 1.8472\n",
            "Epoch 159/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2756 - mae: 1.2756 - val_loss: 1.8916 - val_mae: 1.8916\n",
            "Epoch 160/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2304 - mae: 1.2304 - val_loss: 1.8442 - val_mae: 1.8442\n",
            "Epoch 161/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2382 - mae: 1.2382 - val_loss: 1.8216 - val_mae: 1.8216\n",
            "Epoch 162/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2656 - mae: 1.2656 - val_loss: 1.8327 - val_mae: 1.8327\n",
            "Epoch 163/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2331 - mae: 1.2331 - val_loss: 1.8644 - val_mae: 1.8644\n",
            "Epoch 164/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2523 - mae: 1.2523 - val_loss: 1.8219 - val_mae: 1.8219\n",
            "Epoch 165/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2511 - mae: 1.2511 - val_loss: 1.8577 - val_mae: 1.8577\n",
            "Epoch 166/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2212 - mae: 1.2212 - val_loss: 1.8597 - val_mae: 1.8597\n",
            "Epoch 167/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2233 - mae: 1.2233 - val_loss: 1.8579 - val_mae: 1.8579\n",
            "Epoch 168/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2053 - mae: 1.2053 - val_loss: 1.8211 - val_mae: 1.8211\n",
            "Epoch 169/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2240 - mae: 1.2240 - val_loss: 1.9053 - val_mae: 1.9053\n",
            "Epoch 170/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3178 - mae: 1.3178 - val_loss: 1.8339 - val_mae: 1.8339\n",
            "Epoch 171/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2674 - mae: 1.2674 - val_loss: 1.7829 - val_mae: 1.7829\n",
            "Epoch 172/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2312 - mae: 1.2312 - val_loss: 1.8600 - val_mae: 1.8600\n",
            "Epoch 173/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2382 - mae: 1.2382 - val_loss: 1.8092 - val_mae: 1.8092\n",
            "Epoch 174/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1815 - mae: 1.1815 - val_loss: 1.8191 - val_mae: 1.8191\n",
            "Epoch 175/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1926 - mae: 1.1926 - val_loss: 1.8124 - val_mae: 1.8124\n",
            "Epoch 176/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2062 - mae: 1.2062 - val_loss: 1.7875 - val_mae: 1.7875\n",
            "Epoch 177/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2709 - mae: 1.2709 - val_loss: 1.9606 - val_mae: 1.9606\n",
            "Epoch 178/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2260 - mae: 1.2260 - val_loss: 1.7671 - val_mae: 1.7671\n",
            "Epoch 179/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1908 - mae: 1.1908 - val_loss: 1.7907 - val_mae: 1.7907\n",
            "Epoch 180/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2310 - mae: 1.2310 - val_loss: 1.8108 - val_mae: 1.8108\n",
            "Epoch 181/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1621 - mae: 1.1621 - val_loss: 1.8364 - val_mae: 1.8364\n",
            "Epoch 182/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1454 - mae: 1.1454 - val_loss: 1.8329 - val_mae: 1.8329\n",
            "Epoch 183/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1712 - mae: 1.1712 - val_loss: 1.8574 - val_mae: 1.8574\n",
            "Epoch 184/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1622 - mae: 1.1622 - val_loss: 1.8250 - val_mae: 1.8250\n",
            "Epoch 185/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1773 - mae: 1.1773 - val_loss: 1.8649 - val_mae: 1.8649\n",
            "Epoch 186/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1993 - mae: 1.1993 - val_loss: 1.8312 - val_mae: 1.8312\n",
            "Epoch 187/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1550 - mae: 1.1550 - val_loss: 1.8196 - val_mae: 1.8196\n",
            "Epoch 188/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1590 - mae: 1.1590 - val_loss: 1.8533 - val_mae: 1.8533\n",
            "Epoch 189/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1314 - mae: 1.1314 - val_loss: 1.8285 - val_mae: 1.8285\n",
            "Epoch 190/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1668 - mae: 1.1668 - val_loss: 1.8792 - val_mae: 1.8792\n",
            "Epoch 191/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1336 - mae: 1.1336 - val_loss: 1.8463 - val_mae: 1.8463\n",
            "Epoch 192/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1650 - mae: 1.1650 - val_loss: 1.8868 - val_mae: 1.8868\n",
            "Epoch 193/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1856 - mae: 1.1856 - val_loss: 1.8119 - val_mae: 1.8119\n",
            "Epoch 194/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1678 - mae: 1.1678 - val_loss: 1.7929 - val_mae: 1.7929\n",
            "Epoch 195/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1570 - mae: 1.1570 - val_loss: 1.8040 - val_mae: 1.8040\n",
            "Epoch 196/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1396 - mae: 1.1396 - val_loss: 1.7794 - val_mae: 1.7794\n",
            "Epoch 197/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1159 - mae: 1.1159 - val_loss: 1.7904 - val_mae: 1.7904\n",
            "Epoch 198/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1181 - mae: 1.1181 - val_loss: 1.7998 - val_mae: 1.7998\n",
            "Epoch 199/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1555 - mae: 1.1555 - val_loss: 1.7594 - val_mae: 1.7594\n",
            "Epoch 200/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1809 - mae: 1.1809 - val_loss: 1.8773 - val_mae: 1.8773\n",
            "Epoch 201/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1637 - mae: 1.1637 - val_loss: 1.8164 - val_mae: 1.8164\n",
            "Epoch 202/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1387 - mae: 1.1387 - val_loss: 1.7797 - val_mae: 1.7797\n",
            "Epoch 203/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1379 - mae: 1.1379 - val_loss: 1.8467 - val_mae: 1.8467\n",
            "Epoch 204/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0927 - mae: 1.0927 - val_loss: 1.7954 - val_mae: 1.7954\n",
            "Epoch 205/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0891 - mae: 1.0891 - val_loss: 1.8210 - val_mae: 1.8210\n",
            "Epoch 206/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1372 - mae: 1.1372 - val_loss: 1.7812 - val_mae: 1.7812\n",
            "Epoch 207/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2236 - mae: 1.2236 - val_loss: 1.7760 - val_mae: 1.7760\n",
            "Epoch 208/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2135 - mae: 1.2135 - val_loss: 1.7592 - val_mae: 1.7592\n",
            "Epoch 209/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1599 - mae: 1.1599 - val_loss: 1.8231 - val_mae: 1.8231\n",
            "Epoch 210/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1199 - mae: 1.1199 - val_loss: 1.8052 - val_mae: 1.8052\n",
            "Epoch 211/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1884 - mae: 1.1884 - val_loss: 1.7867 - val_mae: 1.7867\n",
            "Epoch 212/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1206 - mae: 1.1206 - val_loss: 1.8379 - val_mae: 1.8379\n",
            "Epoch 213/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2680 - mae: 1.2680 - val_loss: 1.8176 - val_mae: 1.8176\n",
            "Epoch 214/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2328 - mae: 1.2328 - val_loss: 1.8578 - val_mae: 1.8578\n",
            "Epoch 215/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2712 - mae: 1.2712 - val_loss: 1.7843 - val_mae: 1.7843\n",
            "Epoch 216/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1509 - mae: 1.1509 - val_loss: 1.8947 - val_mae: 1.8947\n",
            "Epoch 217/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2181 - mae: 1.2181 - val_loss: 1.8642 - val_mae: 1.8642\n",
            "Epoch 218/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1738 - mae: 1.1738 - val_loss: 1.7725 - val_mae: 1.7725\n",
            "Epoch 219/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1101 - mae: 1.1101 - val_loss: 1.7137 - val_mae: 1.7137\n",
            "Epoch 220/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1082 - mae: 1.1082 - val_loss: 1.7865 - val_mae: 1.7865\n",
            "Epoch 221/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1678 - mae: 1.1678 - val_loss: 1.7689 - val_mae: 1.7689\n",
            "Epoch 222/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1710 - mae: 1.1710 - val_loss: 1.7527 - val_mae: 1.7527\n",
            "Epoch 223/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0718 - mae: 1.0718 - val_loss: 1.7933 - val_mae: 1.7933\n",
            "Epoch 224/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0512 - mae: 1.0512 - val_loss: 1.7645 - val_mae: 1.7645\n",
            "Epoch 225/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1219 - mae: 1.1219 - val_loss: 1.7989 - val_mae: 1.7989\n",
            "Epoch 226/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0944 - mae: 1.0944 - val_loss: 1.7726 - val_mae: 1.7726\n",
            "Epoch 227/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0553 - mae: 1.0553 - val_loss: 1.7226 - val_mae: 1.7226\n",
            "Epoch 228/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0942 - mae: 1.0942 - val_loss: 1.7579 - val_mae: 1.7579\n",
            "Epoch 229/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0413 - mae: 1.0413 - val_loss: 1.7157 - val_mae: 1.7157\n",
            "Epoch 230/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0732 - mae: 1.0732 - val_loss: 1.7561 - val_mae: 1.7561\n",
            "Epoch 231/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0762 - mae: 1.0762 - val_loss: 1.7152 - val_mae: 1.7152\n",
            "Epoch 232/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0474 - mae: 1.0474 - val_loss: 1.7352 - val_mae: 1.7352\n",
            "Epoch 233/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0313 - mae: 1.0313 - val_loss: 1.7041 - val_mae: 1.7041\n",
            "Epoch 234/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0584 - mae: 1.0584 - val_loss: 1.7416 - val_mae: 1.7416\n",
            "Epoch 235/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1341 - mae: 1.1341 - val_loss: 1.7449 - val_mae: 1.7449\n",
            "Epoch 236/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.1108 - mae: 1.1108 - val_loss: 1.7316 - val_mae: 1.7316\n",
            "Epoch 237/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1350 - mae: 1.1350 - val_loss: 1.7390 - val_mae: 1.7390\n",
            "Epoch 238/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.2205 - mae: 1.2205 - val_loss: 1.7054 - val_mae: 1.7054\n",
            "Epoch 239/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1737 - mae: 1.1737 - val_loss: 1.7083 - val_mae: 1.7083\n",
            "Epoch 240/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1122 - mae: 1.1122 - val_loss: 1.8303 - val_mae: 1.8303\n",
            "Epoch 241/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1037 - mae: 1.1037 - val_loss: 1.7270 - val_mae: 1.7270\n",
            "Epoch 242/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1150 - mae: 1.1150 - val_loss: 1.6398 - val_mae: 1.6398\n",
            "Epoch 243/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0458 - mae: 1.0458 - val_loss: 1.7259 - val_mae: 1.7259\n",
            "Epoch 244/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0065 - mae: 1.0065 - val_loss: 1.6779 - val_mae: 1.6779\n",
            "Epoch 245/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9968 - mae: 0.9968 - val_loss: 1.7135 - val_mae: 1.7135\n",
            "Epoch 246/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0338 - mae: 1.0338 - val_loss: 1.6635 - val_mae: 1.6635\n",
            "Epoch 247/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0738 - mae: 1.0738 - val_loss: 1.7195 - val_mae: 1.7195\n",
            "Epoch 248/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0414 - mae: 1.0414 - val_loss: 1.7592 - val_mae: 1.7592\n",
            "Epoch 249/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0515 - mae: 1.0515 - val_loss: 1.7394 - val_mae: 1.7394\n",
            "Epoch 250/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9991 - mae: 0.9991 - val_loss: 1.6986 - val_mae: 1.6986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IEl3-k3bn7N"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Now that you know how MAE works, you need to plot the behavior of MAE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYyGYH4zbn7N"
      },
      "source": [
        "### Answer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK1qdGtBbn7N",
        "outputId": "de001a91-9700-4064-807f-947a733bd72b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# errors = np.arange(-5, 6)\n",
        "# n = len(errors)\n",
        "\n",
        "mae =  history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "plt.plot(mae, marker='o')\n",
        "plt.plot(val_mae, marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Difference between actual and estimated ouputs')\n",
        "plt.ylabel('Mean Absolute Errors')\n",
        "plt.legend(['train', 'valid'])\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xU1bnw8d+TZHIhCZeAIhdPwb6WCohcotLiJUgVqxWx9dCbl/ZYbW0tbU/FYu1RtL6Vamt7PN5qq2+1VimnIhWr4jVardqCYAAppSoKAcEgiQSGZDJ53j/2mjAZZiaTZC5k9vP9fPLJnjX78qyZ5Fl7r7332qKqGGOM8Y+CXAdgjDEmuyzxG2OMz1jiN8YYn7HEb4wxPmOJ3xhjfKYo1wGkYsiQITpq1KgeLbtnzx7Ky8vTG9BBzursH36st9U5dStXrmxQ1UNiy/tE4h81ahQrVqzo0bK1tbXU1NSkN6CDnNXZP/xYb6tz6kTknXjl1tVjjDE+Y4nfGGN8xhK/Mcb4TJ/o4zfGmO4KhUJs2bKFffv25TqUXhswYADr169P+H5paSkjR44kEAiktD5L/MaYvLRlyxYqKysZNWoUIpLrcHpl9+7dVFZWxn1PVdm5cydbtmxh9OjRKa0vb7t6lq6qZ9rCZ/nKE3uYtvBZlq6qz3VIxpgs2rdvH4MHD+7zSb8rIsLgwYO7dWSTl3v8S1fVc+WSNQRDYQDqG4NcuWQNALMnjchlaMaYLMr3pB/R3Xrm5R7/Tcs3dCT9iGAozE3LN+QoImOMOXjkZeLf2hjsVrkxxqRbY2Mjt99+e7eXO+OMM2hsbMxARPvlZeIfPrCsW+XGGBM5Lzh6/p/Tcl4wUeJva2tLutxjjz3GwIEDe7XtruRl4p83cwxlgcJOZWWBQubNHJOjiIwxB7PIecH6xiDK/vOCvUn+8+fP580332TixIkce+yxnHjiicyaNYuxY8cCMHv2bKZMmcK4ceO46667OpYbNWoUDQ0NbNq0iaOOOoqLL76Y4447jtNOO41gMD29Fnl5cjdyAvf6P79BQ3Mrg8uL+a/PjLUTu8b41LXL1vHG1g8Tvr/q3UZaw+2dyoKhMFf8sY4H//Zu3GXGDu/PNWeNS7jOhQsXsnbtWlavXk1tbS1nnnkma9eu7bjk8p577qGqqopgMMixxx7L5z73OQYPHtxpHRs3buTBBx/k5ptv5qKLLuKhhx7ivPPOS7XaCeXlHj94yX/pt6YBcMXpYyzpG2MSik36XZX3xHHHHdfpOvtbbrmFY445hqlTp7J582Y2btx4wDKjR49m4sSJAEyZMoVNmzalJZa83OOPOLSyFAG2NfX9O/eMMT2XbM8cYNrCZ6mPc/HHiIFl/OHrn0hLDNHDKtfW1vL000/z8ssv069fP2pqauJeh19SUtIxXVhYmLaunrzd4wcoLiqgf4nwniV+Y0wSmTgvWFlZye7du+O+19TUxKBBg+jXrx//+Mc/eOWVV3q8nZ7I6z1+gKoSsT1+Y0xSka7gm5ZvYGtjkOEDy5g3s3ddxIMHD2batGmMHz+esrIyhg4d2vHe6aefzp133slRRx3FmDFjmDp1aq/r0B15nfiXrqpnS3M7b//zfaYtfLbXX6QxJn/NnjQi7fnhgQceiFteUlLC448/Hve9SD/+kCFDWLt2bUf55Zdfnra48rarJ3J5Vsidm0nH5VnGGJMP8jbx27ANxhgTX94mfhu2wRhj4svbxH9hxd94sXgub5V8iReL5zKr4EXAhm0wxpj8PLlbt5gf6Z0UFXhX84yUBhYGfkOxFnDCzG/mODhjjMmt/Nzjf+Y6isKdL+HsJ61cV/6QXdVjjPG9/Ez8TVviFvcLvpflQIwxJjUVFRUAbN26lXPPPTfuPDU1NaxYsaLX28rPxD9gZPfKjTGmbjH8YjwsGOj9rluckzCGDx/OH//4x4xuI2OJX0QOF5HnROQNEVknIt9x5VUi8pSIbHS/B6V94zOuhkDnk7itUuqVG2NMrLrFsGwuNG0G1Pu9bG6vkv/8+fO57bbbOl4vWLCA66+/nhkzZjB58mSOPvpo/vSnPx2w3KZNmxg/fjwAwWCQL3zhC1RXV3POOef0iWGZ24Dvq+prIlIJrBSRp4CvAM+o6kIRmQ/MB36Q1i1PmOP9fuJK2NtAAwN5Yti3OS9Sbozxl8fnw3trEr+/5e8QbulcFgrCny6DlffGX+awo+HTCxOu8vOf/zzf/e53+da3vgXA4sWLWb58OXPnzqV///40NDQwdepUZs2alfCZuXfccQf9+vVjxYoVvP3220yePDlpNVOVsT1+Vd2mqq+56d3AemAEcDYQ+STvBWZnJIAJc+BLfwDglorvUFtyckY2Y4zJA7FJv6vyFEyaNIkdO3awdetWXn/9dQYNGsRhhx3GD3/4QyZMmMCnPvUp6uvr2b59e8J1vPDCCx3j70+YMIEJEyb0OJ5oWbmcU0RGAZOAV4GhqrrNvfUeMDTBMpcAlwAMHTqU2trabm+3NLidqcCg1m288l5Dj9bRFzU3N/umrhF+rDP4s96p1nnAgAH7R8c84aqk85bfdTwFuw8czqW9cgR7zl2UeMEEo29GzJo1i/vvv58dO3Zw9tlnc/fdd7Nt2zZqa2sJBAKMHz+ehoaGjiGbd+/eTXNzM+3t7ezevZu2tjb27t1LOBxm9+7dtLe3s2fPnrijfu7bty/lv4WMJ34RqQAeAr6rqh9GH9KoqoqIxltOVe8C7gKorq7Wmpqa7m88FIRXL2F0RRht60dNjT/2+mtra+nR59WH+bHO4M96p1rn9evXU1lZmdpKT13g9emHovrQA2UUnLog9XXEccEFF3DxxRfT0NDA888/z+LFixk+fDhVVVU899xzvPvuu1RUVHRso7KykoqKCgoKCqisrOSUU05h6dKlnHzyybzzzjusXbuW8vLyuDGVlpYyadKklOLKaOIXkQBe0v+9qi5xxdtFZJiqbhORYcCOjAUQKKOtsB+HSCNNwVDGNmOM6eMi5/+euc67HHzASO9ikF6eFxw3bhy7d+9mxIgRDBs2jC9/+cucddZZHH300VRXV/Pxj3886fKXXnopX/3qV6murmbcuHFMmTKlV/FEZCzxi7drfzewXlVvjnrrEeBCYKH7feBp7TRqLR5IlTbSaInfGJPMhDm9TvTxrFmz/6TykCFDePnll+PO19zcDHgPW48Mx1xWVsaiRYvYvXt3r448YmVyj38acD6wRkRWu7If4iX8xSJyEfAOkNFLbVqLB9I/vIvWtnb2hcKUxjxlxxhj/CZjiV9VXwTiX6MEMzK13VitxYOo3Ovdydu4N8RhAyzxG2P8LT/v3I2oW0zVB69RuecdXiyeyw0/vZZpC5+1h7EY4xOqca8dyTvdrWf+Jn53J15ROIgAIwsauCHwG6Z8+JQ9icsYHygtLWXnzp15n/xVlZ07d1JaWpryMvk5LDN4Z+dDnW9v7ietXFG0mEdaT+Cm5RtspE5j8tjIkSPZsmUL77//fq5D6bV9+/YlTeylpaWMHJn6WGT5m/gTjNA5XHYC9iQuY/JdIBBg9OjRuQ4jLWpra1O+Rj8V+dvVk2Akzq06GLAncRlj/Ct/E3+cETr3ajE3ts2hLFDIvJljchSYMcbkVv529bgbMVoevYKS1l3s1EquDZ3Pyv6ncsPMMda/b4zxrfxN/AAT5vDaVuETr3yNm9u/yLATLuClM47KdVTGGJNT+dvV44QLve6eQUX72NsaznE0xhiTe75J/AMLWgiGLPEbY0x+d/UAWlAIRWX0lxaCtsdvjDH5v8cPQEkl/QuC7G1ty3UkxhiTcz5J/BVUyj7r6jHGGPyS+IsrKGefdfUYYwx+Sfwl/Slnr13VY4wx+CbxV1CmQevqMcYYfJP4K73Eb3v8xhjjk8RfXEFpu3X1GGMM+CXxl1RQ0r6XYCic9w9lMMaYrvgk8fenqL2FItrYF2rPdTTGGJNT/kj8xRUAlLPPbuIyxvhetxK/iBSISP9MBZMxJV7ir8Cu7DHGmC4Tv4g8ICL9RaQcWAu8ISLzMh9aGpVUAlAudhOXMcakssc/VlU/BGYDjwOjgfMzGlW61a8C4IniH/CR+46HusU5DsgYY3InlcQfEJEAXuJ/RFVDQJ+5NObQ7c/Dq3cCUCBQvKcels215G+M8a1UEv+dwCagHHhBRD4CfJjJoNLpiLd+B+GWzoWhIDxzXW4CMsaYHEs6Hr+IFADbVXVEVNm7wPRMB5YuJS0N8d9o2pLdQIwx5iCRdI9fVduBK2LKVFX7zDWRLSVD4r8xYGR2AzHGmINEKl09T4vI5SJyuIhURX4yHlmavHXE+VBU1rkwUAYzrs5NQMYYk2OpPHrx8+73t6LKFDgi/eGk346hJzN2zJGw9FJUobl0GJVnXgcT5uQ6NGOMyYku9/hVdXScnz6R9Dsc80XapZDbwmdzdNPPmfbYEJauqs91VMYYkxNd7vG7SzkvBU5yRbXAr9xlnX3C0tVbObU9QCmtANQ3BrlyyRoAZk8akWxRY4zJO6n08d8BTAFudz9TXFmfcdPyDQQp7kj8AMFQmJuWb8hhVMYYkxup9PEfq6rHRL1+VkRez1RAmbC1Mci+kmJKJXRAuTHG+E0qe/xhEflo5IWIHAH0qQFvhg8so0UDlNJyQLkxxvhNKnv8lwPPichbgAAfAb6a0ajSbN7MMbQsLaFU93f1lAUKmTdzTA6jMsaY3Ojqzt1C4BjgSCCSJTeoakvipQ4+syeNYOdfBrGrwevqGTGwjHkzx9iJXWOMLyVN/KoaFpEvquovgLosxZQRgwf0Z/Du9/nk4YN54OKpuQ7HGGNyJpU+/pdE5FYROVFEJkd+ulpIRO4RkR0isjaqbIGI1IvIavdzRq+i745AGSW00tJmj140xvhbKn38E93v6OEsFTili+V+C9wK3BdT/gtV/VlK0aVTUalL/H3qvLQxxqRdKn38j7iunm5R1RdEZFQP40q/QBkluo8We9i6McbnRDX5M1VE5G+qelyPVu4l/kdVdbx7vQD4Ct54/iuA76vqrgTLXgJcAjB06NApixYt6kkINDc3U1FRwcc23E75ey/zKX7FTSf369G6+opInf3Ej3UGf9bb6py66dOnr1TV6tjyVLp6XhKRW4E/AHsihar6Wrej8O74/TFeV9GPgZ8D/xFvRlW9C7gLoLq6WmtqanqwOaitraWmpgb2PUnL9hcoKCqmp+vqKzrq7CN+rDP4s95W597LZB//AVR1e2RaRH4NPNrddfRYoJSidju5a4wxXSZ+VU3b07ZEZJiqbnMvzwHWJps/rYrKKCRMONTa9bzGGJPHEl7OKSK/jJr+Tsx7v+1qxSLyIPAyMEZEtojIRcCNIrJGROrwHt/4vZ4G3m2BUi+utiBdndcwxph8lmyP/6So6QuB/456PaGrFavqF+MU351iXOlX5CX+Em2lrV0JFErOQjHGmFxKdgOXJJjumwLegGwlYv38xhh/S7bHXyAig/Aah8h0pAEozHhk6eYSfymttITCVJSkcl7bGGPyT7LsNwBYyf5kH335Zt/rJC+KSvy2x2+M8bGEiV9VR2UxjsxzJ3ct8Rtj/C6VQdryQ2SPX0I2Xo8xxtf8k/jdHn8ZLTZejzHG13yU+L3xeayrxxjjdyklfhE5QUS+6qYPEZHRmQ0rA9x1/KXSyr6QdfUYY/yry8QvItcAPwCudEUB4P5MBpURkev4CdkevzHG11LZ4z8HmIUbmVNVtwKVmQwqI4qir+qxPX5jjH+lkvhb1RvcRgFEpDyzIWXIP/4MwFVFv2f646dA3eIcB2SMMbmRSuJfLCK/AgaKyMXA08BvMhtWmtUthj9748GJQHlwGyyba8nfGONLXSZ+93zcPwIPAWOAq1X1lkwHllbPXAehYOeyUNArN8YYn+lywBoR+amq/gB4Kk5Z39C0pXvlxhiTx1Lp6jk1Ttmn0x1IRg0Y2b1yY4zJY8kexHKpiKzBe5BKXdTP20Bd9kJMgxlXd1zO2SFQ5pUbY4zPJOvqeQB4HLgBmB9VvltVP8hoVOk2YY73e+mlaLiNppLDGPiZH+8vN8YYH0m4x6+qTaq6Ce/mLY36qRCRf8tOeGk0YQ4cchS1ciw/G/tHS/rGGN9K5Wkkf8ZL+AKUAqOBDcC4DMaVGYUBSgrCNkibMcbXukz8qnp09GsRmQx8M2MRZVJhMaWy14ZsMMb4WrdH51TV14DjMxBL5hUGKKbNhmwwxvhaKtfx/2fUywJgMrA1YxFlUlEJxdJme/zGGF9LZY+/MuqnBK/P/+xMBpUp25rDtIVaqd3wPtMWPsvSVfW5DskYY7IulT7+a7MRSKYtXVVP6ba9fFRDANQ3BrlyyRoAZk8akcvQjDEmqxImfhFZhhuRMx5VnZWRiDLkpuUbmNdeSEDaOsqCoTA3Ld9gid8Y4yvJ9vh/lrUosmBrY5DWogCBgrYDyo0xxk8SJn5VfT4yLSLFwMfcyw2qrr+kDxk+sIxQcxHFhA4oN8YYP0nl0Ys1wEbgNuB24J8iclKG40q7eTPH0F7gXc4ZURYoZN7MMTmMyhhjsi+VO3d/DpymqhsARORjwIPAlEwGlm6zJ41g49rDCPzLu4Z/xMAy5s0cY/37xhjfSSXxByJJH0BV/ykigQzGlDFHDh9M+M02KkuLeGn+KbkOxxhjciKVxL9CRH4D3O9enwesyFxIGVRYTCFhQm1tXc9rjDF5KpXEfynwLWCue/0XvL7+vqfQO1DRcCuqiojkOCBjjMm+VG7gagFuBm4WkSpgpCvrewpLAAhoG23tSqDQEr8xxn9SuaqnVkT6u6S/Evi1iPwi86FlQGExAAHaaLXxeowxPpXKWD0DVPVD4LPAfap6PDAjs2FliOvqKaaNUNgSvzHGn1JJ/EUiMgyYAzya4XgyK7LHL7bHb4zxr1QS/3XAcuBNVf27iByBd0NX31Pk9fF7Y/Jb4jfG+FMqJ3f/F/jfqNdvAZ/LZFAZ47p6ArTRal09xhifSuXk7hEiskxE3heRHSLyJ7fX39Vy97j510aVVYnIUyKy0f0e1NsKdIvr6rE+fmOMn6XS1fMAsBgYBgzH2/t/MIXlfgucHlM2H3hGVY8EnnGvsyd6j9+6eowxPpVK4u+nqr9T1Tb3cz9Q2tVCqvoC8EFM8dnAvW76XmB2t6LtLXcdf7Gd3DXG+FiyB7FUucnHRWQ+sAjvwSyfBx7r4faGquo2N/0eMDTJ9i8BLgEYOnQotbW1Pdpgc3Nzx7L9m9YzGSgmxN9WrqJ5U2GP1nmwi66zX/ixzuDPeludey/Zyd2VeIk+cnvr16PeU+DK3mxYVVVEkj3h6y7gLoDq6mqtqanp0XZqa2vpWLa+P6zyunrGjj+amjGH9midB7tOdfYJP9YZ/Flvq3PvJXsQy+hE7/VidM7tIjJMVbe5ewN29HA9PdNx527YunqMMb6VSh8/AOKZISJ3A1t6uL1HgAvd9IXAn3q4np6Juo7fLuc0xvhVKpdzThWRW4B38BL1C8DHU1juQeBlYIyIbBGRi4CFwKkishH4lHudPZEhGyRke/zGGN9KdnL3J8C/A+/iXb55LbBCVe9NtEw0Vf1igrdyN86PDdJmjDFJT+5+DfgncAewTFVbkp2M7RMiwzLbDVzGGB9L1tUzDLgeOAt4U0R+B5SJSCoPbzk4Rd3AZWP1GGP8KtlVPWHgCeAJESkBPgOUAfUi8oyqfilLMaaP6+opsZO7xhgfS2nv3T1x6yHgIRHpT7bvuE0X6+M3xpjUL+eMUNUPVfW+TASTcQUFUFBESUHY+viNMb7V7cTf5xUWU1pgN3AZY/zLh4k/QKkN0maM8bGU+vhF5JPAqOj5+2x3T2ExJQVhO7lrjPGtLhO/u4zzo8BqIOyKFeijib+EErHLOY0x/pXKHn81MFZV+/bNWxGuqycUzo/qGGNMd6XSx78WOCzTgWRNYTElEqa1Ldz1vMYYk4dS2eMfArwhIn8DWiKFqjorY1FlUmGxXcdvjPG1VBL/gkwHkVVFxRSLndw1xvhXl4lfVZ/PRiBZUbcY3lvDpHArv9x6PtT9X5gwJ9dRGWNMVqU6Hv/fRaRZRFpFJCwiH2YjuLSqWwzL5kK4FQEOad/hva5bnOvIjDEmq1I5uXsr8EVgI94gbV8DbstkUBnxzHUQCnYuCwW9cmOM8ZGU7txV1X8BhaoaVtX/B5ye2bAyoCnB0yITlRtjTJ5K5eTuXhEpBlaLyI3ANvriUA8DRkLT5vjlxhjjI6kk8PPdfJcBe4DDgc9lMqiMmHE1BMo6lwXKvHJjjPGRVK7qeUdEyoBhqnptFmLKjMjVO3/+PtryIdsYwvCzbrCreowxvpPKVT1n4Y3T84R7PVFEHsl0YBkxYQ6cNA8BztGfWdI3xvhSKl09C4DjgEYAVV0NjM5gTBm1aod345a07GbawmdZuqo+xxEZY0x2pZL4Q6raFFPWJ0c4W7qqnt+t+gCASglS3xjkyiVrLPkbY3wllcS/TkS+BBSKyJEi8j/AXzMcV0bctHwDO9tKAahkLwDBUJiblm/IZVjGGJNVqST+bwPj8AZoexD4EPhuJoPKlK2NQXard2VPpQQ7lRtjjF+kclXPXuAq99OnDR9Yxu6mfsD+Pf5IuTHG+EXCxN/VlTt9cVjmeTPH8Msl2wCocHv8ZYFC5s0ck8uwjDEmq5Lt8X8C2IzXvfMqIFmJKINmTxpBUagaHvP2+KvKi7n6M2OZPWlErkMzxpisSdbHfxjwQ2A88N/AqUCDqj7fl4dq/kz1kShCpexl3swxlvSNMb6TMPG7AdmeUNULganAv4BaEbksa9FlQkEBlFRSSZBde1tzHY0xxmRd0pO7IlICnIk3LPMo4Bbg4cyHlVlS0p8BwSDb9oZyHYoxxmRdspO79+F18zwGXKuqa7MWVaaV9qeqsIVde2yP3xjjP8n2+M/DG43zO8BckY5zuwKoqvbPcGyZU9KfAYV72WV7/MYYH0qY+FW17425n6qSSgbITuvjN8b4Uv4m92RK+1NuJ3eNMT7lv8Rftxj++QSHhrZw/+6L7GHrxhjfSeXRi/mjbjEsmwuhIAIMpwFdNte7M83G5jfG+ERO9vhFZJOIrBGR1SKyImsbfuY6CHUekE1CQd5b8kMbmtkY4xu53OOfrqoNWd1i05a4xYdqA1cuWQNgd/IaY/Kev/r4B4yMW7xVB9u4/MYY3xDV7D9MS0TeBnbhPcnrV6p6V5x5LgEuARg6dOiURYsW9Whbzc3NVFRUAHDo9ucZs+E2CttbOt7fq8XMD32NR9pPAOC3p5f3aDsHk+g6+4Uf6wz+rLfVOXXTp09fqarVseW5SvwjVLVeRA4FngK+raovJJq/urpaV6zo2amA2tpaampq9hfULWb7kvkMZSeNWs7VoQs7kv6IgWW8NP+UHm3nYHJAnX3Aj3UGf9bb6pw6EYmb+HPS1aOq9e73Dryxf47L2sYnzOHlWS/QogEWhad3JH0bl98Y4xdZT/wiUi4ilZFp4DQgq+MAzZ48krbyoRwmuwBvT/+Gzx5tJ3aNMb6Qi6t6hgIPu7F/ioAHVPWJbAdRPngkR7Y1M3nYQJZ8c1q2N2+MMTmT9cSvqm8Bx2R7uweoPIxDtq9kW9O+XEdijDFZ5a/LOaO1NHNI6xZe2vdZ9BfjbOgGY4xv+GvIhoi6xfD28wiKCN6NXcvmeu/Z0A3GmDznzz3+Z66D9pix+ENB9j5+dW7iMcaYLPJn4k8wdEPp3vdszB5jTN7zZ+JPMnSDDdtgjMl3/kz8M65mrxZ3KtqrxdzYNoetjcEECxljTH7wZ+KfMIcbA9+kRQtRBVXYh9cQDCgL5Dg4Y4zJLH8mfuDMCcMRQMT7qZJmFgZ+w0ktz/GjpWtyHZ4xxmSMbxP/sW/+D8US7lTWT1q5pug+fv/Ku3aS1xiTt3yb+BNd2VMlzSwouocFj6zLckDGGJMd/k38Ca7sEYHzC5/mpJbnmHTdk7bnb4zJO/5N/DOuJtGTCAoErim6j117Q1y5ZI0lf2NMXvFv4p8wBymrSvh2lTQzq+BFgqGwdfsYY/KKfxM/wKd/Ckjct0Tg5sCdzCp4kcZgyK70McbkDX8O0hYxYQ68+wq64u646b9I2vll4HbObX+eI17bTvuqBnbIIWyePI9jZ3096+EaY0w6+HuPH+AzNyft8ikQOLFgHSMLGigQOIz3GbfyR8y7+irr+zfG9EmW+MHr8gmUJXxbYg4H+kkrN8qtnLT0OGsAjDF9jr+7eiIiY/A//A3QcPJ5HRGoopkbuRWW3srOhysQgYE0854MoX7yFQd2B9Ut9oaEbtriXU464+r0jv/v1n9y0xZYNRKOPA02Ptnz7WU6XmNMTljij4gktCWXQMILPQ8UORoYLM0dZcNpYNjKK9CVV7iZOv3yNG2Gpd+Ex38AwQ/cu267gXIoKoHgrvgJt25x1HJufoDQnv3badoMK+7uvL1lc+HdVw5sDMAl+M0ghV7jV1YFrc0Qbu28fPRnlWnW8BiTEZb4o7mTvZ0SZg/Fdg/F1R7an7yjG5vQno4kTtNmWHKx95NIZN6uhIIHNgax640c8XTEFbP8w9/wPqN1DydseDrElksBaLvXqLS1dJ6/rArGndN5vdGiP4eyKq97LrYRiG0Qo+eL14hA57J4R0ix81jjY/KAqKa+d5sr1dXVumLFih4tW1tbS01NTfcWevQ/05L8TfYoiS7MzZBIIxY5Qor8jj5yi8wTXRbRcVT3QeejrO40iIFyWrWA4rbmzg1VosYvFakcZeX4SKxH/9N9XE/rLCIrVbX6gHJL/AnE7D1mPbEY42eJjhalENUwEq+BHXB41FHb5tQb43iNY0fjFrWeAYf3vJHrZWNpib+b0rZ34BoCdQ2BNQLGmF6JPWqMd8Tn5tlXcgilZ/6k241OosRvffypmjDHG+YBOlpvbdoMWCNgjOkBbXe/k5xXc/OUtryf1osr7Dr+npgwB763FlnQhHz2115L7YQKymimpOPJXtE/7e63McZ0WyjodRelge3x95Y7EogIuB+ApavqWfDIOhqDoY73ZxW8yDVF91HlLv/cQwmtBBjIHnZpubsXwJ3HbdUAAA8oSURBVJsukRDltHQsGznPEH3FUIsWsocyBtJMOwUU0s4Huv+eAvDuPu5YR6SrM4WylK5MihLbqKWyfLxtx2rXzkdV3Y3LmLyR4Dki3WWJP4NmTxrB7EkjYkrPBG4A4jcMXZlV8CJXFC1muOxkqw7mxrY5PNJ+QrfmB7ose6Z9IjMKVjNcGjo1KNGNUXSjFRtL9HZjG7TIdPS2EzWGseu9tugezi98Om5j1o5QgB7Q8MU2lqqdT9ZHlgu7erbT+VB4DyUAnRphiN8AJWtYky3X1Tq6u56eNNymD0jwHJHuspO7B7Glq+q5afkGtjYGGVAWoLUtzN5Qe67Dyrl0NH7J5u9eDPsbxnodkrBhTd4gNsddR3RjuIsKFoQuiLOeBpTODdUuKlgWnspnCl7pWD7RVWnxylsopIRwwsYyUYMSnUrirTduDOIaqdjiJNtItUGLnTeVo8uDWqAMzrqlW338dlWPj0TXuSdHFcYkaiwTHcmlq0GN3XbsNvYfie5MeMQI+xu/ePPGa3hjG0+IPvLs/H7KjVqc8niNajwdR7HiHY22pPmqHkv8eai7dY5tHArE61cvFCGsysCyACKwa28o3q1IxphuiHe0uL97Mn4jWhGA6z87MU7XcXJ2OadJKP65iNR11XBYY2HMfo+0n8Ajrd07MmoOwZVLvIdB9eZ/NcISv+m13jYc0Pl8xvCBZcybOaZjnfHeAw7owoo0OHaEYvJRMBTmpuUbLPGb/JGs8Uj0XnRZb7u3BvULcM1Z45g9aUTS9xItH2l0RsRptLpzjiWyHmuwTDxbG4NpWY8lfuNLPWloujtPd+brqdraWhoHHHlAQ3XmhGE894/3e3RFWPSRU7Ll+gW805196UqzSIPaVxvW4QMTPzCqOyzxG9PHZbpxSVWy7rrYeeobgx3ngFI5SoocdQFc9dBq9rTFjyF6vq62Ex1TvIbz0de39fpquHR2P5YFCju6OXvLEr8xJi3SdaTU1TwDmzam1K2XamOYaHvXzz467vyJzjl11ejFW0+y7sLodVaVCv919tFpa+At8RtjTDekcs6pN+uJt87a2lpq0nhUZ4O0GWOMz+Qk8YvI6SKyQUT+JSLzcxGDMcb4VdYTv4gUArcBnwbGAl8UkbHZjsMYY/wqF3v8xwH/UtW3VLUVWAScnYM4jDHGl7I+Vo+InAucrqpfc6/PB45X1cti5rsEuARg6NChUxYtWtSj7TU3N1NRUdG7oPsYq7N/+LHeVufUTZ8+vW+N1aOqdwF3AYjI+9OnT3+nh6saAjSkLbC+wersH36st9U5dR+JV5iLxF8PHB71eqQrS0hVD+npxkRkRbwWL59Znf3Dj/W2OvdeLvr4/w4cKSKjRaQY+ALwSA7iMMYYX8r6Hr+qtonIZcByoBC4R1XXZTsOY4zxq5z08avqY8BjWdrcXVnazsHE6uwffqy31bmX+sQTuIwxxqSPDdlgjDE+Y4nfGGN8Jq8Tv1/GBBKRTSKyRkRWi8gKV1YlIk+JyEb3e1Cu4+wNEblHRHaIyNqosrh1FM8t7nuvE5HJuYu85xLUeYGI1LvverWInBH13pWuzhtEZGZuou4dETlcRJ4TkTdEZJ2IfMeV5+13naTOmfuuVTUvf/CuGHoTOAIoBl4HxuY6rgzVdRMwJKbsRmC+m54P/DTXcfayjicBk4G1XdUROAN4HO9BS1OBV3MdfxrrvAC4PM68Y93feAkw2v3tF+a6Dj2o8zBgspuuBP7p6pa333WSOmfsu87nPX6/jwl0NnCvm74XmJ3DWHpNVV8APogpTlTHs4H71PMKMFBEhmUn0vRJUOdEzgYWqWqLqr4N/Avvf6BPUdVtqvqam94NrAdGkMffdZI6J9Lr7zqfE/8IYHPU6y0k/zD7MgWeFJGVbowjgKGqus1NvwcMzU1oGZWojvn+3V/mujXuierCy7s6i8goYBLwKj75rmPqDBn6rvM58fvJCao6GW+o62+JyEnRb6p3fJjX1+36oY7OHcBHgYnANuDnuQ0nM0SkAngI+K6qfhj9Xr5+13HqnLHvOp8Tf7fHBOqrVLXe/d4BPIx32Lc9csjrfu/IXYQZk6iOefvdq+p2VQ2rajvwa/Yf4udNnUUkgJcAf6+qS1xxXn/X8eqcye86nxO/L8YEEpFyEamMTAOnAWvx6nqhm+1C4E+5iTCjEtXxEeACd8XHVKApqpugT4vpvz4H77sGr85fEJESERkNHAn8Ldvx9ZaICHA3sF5Vb456K2+/60R1zuh3nesz2hk+W34G3hnyN4Grch1Phup4BN4Z/teBdZF6AoOBZ4CNwNNAVa5j7WU9H8Q73A3h9WlelKiOeFd43Oa+9zVAda7jT2Odf+fqVOcSwLCo+a9ydd4AfDrX8fewzifgdePUAavdzxn5/F0nqXPGvmsbssEYY3wmn7t6jDHGxGGJ3xhjfMYSvzHG+IwlfmOM8RlL/MYY4zOW+DNIRMJuVL11IvK6iHxfRArce9UicoubLhGRp928nxeRE90yq0WkLLe1iE9Emrs5/2wRGZupeDJBREaJyJd6uY5aEUn7g8HTsV4RqRGRT0a9/oaIXND76EBEftiDZb4iIremY/s92HanzyLfWeLPrKCqTlTVccCpeEMqXAOgqitUda6bb5Irm6iqfwC+DNzgXge72oi7eeVg/y5n440q2JeMAnqV+A9yNUBHslPVO1X1vjStu9uJP8dqiPos8l6ub17I5x+gOeb1EcBOvJtOaoBHgUPxRtdrwrtx4+t4IzK+jXf7NsA8vDuR64BrXdkovJs37sO7cesjSeZbj3fL9zrgSaDMvfd/8G6GeR14Dfhoou3FqxvwC7fOZ4BDXPlHgSeAlcBfgI/j/UNF6rQaOB5Y6eY/Bu/mlX9zr98E+gGH4N3C/nf3M829Xw7cg3en4irgbFf+FWCJ2/ZG4MYEcV/t1rcW7zmmkuizAF6J+l6+57Zxa9S6HgVq3PQdwAr3eVwbNU8tcW4qShJHLfBTV79/Aie68jK8EWbX4w3L8WqC9U4Bnnef/3LcTT/AXOAN950ucn8X7+Hd6r8aOJGoYYBdHL9wdVoPHOs+343A9VHbW+q2tQ64xJUtBMJuvZG/4fNcnVYDv8INIwx81dXzb3h/o7fGqVOV206d+04muPKOeN3rta5eo4B/AL93sf8R6Ofm2YQbwhyodvWM91n8u1vf68ALuc4lac9NuQ4gn3+ISfyurBFvZMEa4FFX1jHtXv8WONdNnxZJDHhHaI/ijdM+CmgHpqYwXxsw0c23GDjPTb8KnOOmS/ESbtz1xKmHAl9201dH/mHxGoEj3fTxwLOxdXKv1wH9gcvwEuCX8Rqvl937D+ANPgfwb3i3swP8JCr+gXhJoxwvKb8FDHB1eQc4PE7cVVHTvwPOSvJZxH4vXyFx4o/cSVqIl0wiyamW+Ak6URy1wM/d9BnA0276P4F73PQE951Wx6wzAPyV/Y3w56OW2QqURD4393sBnRNnx2sXR2TM+++45YfhjQG/BRgcU+8yvEQZKW+OWu9RwDIg4F7fDlzg1vcuXiNfDLxE/MT/P8A1bvoUYHWC+KMTv7J/Z+GeqHptIibxJ1jXGmBE9OeVTz9FmIPdae5nlXtdgTc2x7vAO+qNQd7VfG+r6mpXvhIY5cb3GaGqDwOo6j4AEUm0nhdi4moH/uCm7weWuNEFPwn8rzf8COAlinj+CkzDa5x+ApyO19j8xb3/KWBs1Hr6u/WfBswSkctdeSlewwDwjKo2uXq8gdeQRA9fCzBdRK7AS+xVwDoRqU3wWSQIPa45bkjsIryENhZvDzWRA+LAS47g7VmD+67c9EnALS6+OhGJt+4xwHjgKRd7Id6QD7hYfi8iS/H2nlMRGdtqDbBO3Rg4IvIW3iBhO4G5InKOm+9wvL+VnTHrmYF3JPJ3F1cZ3iBrx+Ml3vfdev8AfCxOHCcAn3N1f1ZEBotI/y5i36yqL7np+/GOeH7WZY33ewn4rYgsZv/3kTcs8WeRiByBdwi8A28vKKXF8Pr7fxWzrlHAnhTna4kqCuP943VreylQvCOERlWdmML8L+AdUn8Eb8CtH7h1/Nm9X4B3NLOvU3Be5vicqm6IKT+eA+tZFDNPKd7eZrWqbhaRBXgNR6ra6HxerNStdzRwOXCsqu4Skd8mW28KcUTqcUAduiB4CfoTcd47E6/xOAu4SkSOTmF9kTja6fzZtgNFIlKD10B/QlX3ugY0Xr0FuFdVr+xUKNLbhwPF/T6c2LFoIq+jl0n4HanqN9zf1JnAShGZoqqxDVqfdbCfEMwbInIIcCfeoWx3BkhaDvyH29tFREaIyKG9mA/oeNLPlsg/n7uyqF831lMAnOumvwS8qN4Y4m+LyL+7ZUVEjnHz7MZ7rFzEX/D6fTeqN+zsB3hdGy+6958Evh2ZWUQijcly4NuuAUBEJiWqYxyRf/QGV79zu/gsYmPeBEwUkQIROZz9w+T2x2uEm0RkKN5J/G7H0YUXcCeaRWQ8XndPrA3AISLyCTdfQETGuRP/h6vqc3gN7AC8I7nY+nXXAGCXS/ofx3v0YURIvKGGwev+OzfydyTe83M/gte9drLbgw/g9avH8xe8rkBcY9Pg/tY24T2aEvGetTs6apl/i3wOuL9PN70J7+gD3FGE0+mzEJGPquqrqno18D6dh0Hu8yzxZ1ZZ5HJOvBOHTwLXdmcFqvokXn/3yyKyBu9E1QH/rKnOF+N8vEP1Oryul8O6sZ49wHHiPQj8FOA6V/5l4CIRiYwWGnnc5SJgnoiscv9Um/D2BCNdSC/iHS3scq/nAtXiPX3oDeAbrvzHeH3Zde5z/XEXdeygqo14JxDX4jUgf0/2WeB1j4TFuxT3e3iH/2/jnSS9Be8kMKr6Ol7X2D/cZ/cSSXQRRyJ3ABUish7vs14ZZ72teI3IT93nvxqv660QuN99n6uAW1wMy4Bz3N/oiSnEEOsJvD3/9XgndF+Jeu8uvO/o96r6BvAjvKfE1QFP4Z103obXt/4y3me2PsF2FgBT3LIL2T8880NAlfs7uAzvfE/EBryHEq0HBuF9fuD9//23iKzAO6KKiP0sbhKRNe7v+694J3nzho3OaYzJK65781FVHZ/jUA5atsdvjDE+Y3v8xhjjM7bHb4wxPmOJ3xhjfMYSvzHG+IwlfmOM8RlL/MYY4zP/H/9ljIji6zviAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFJ88ER6s7w"
      },
      "source": [
        "## Mean Squared Logarithmic Error [MSLE]\n",
        "\n",
        "MSLE is just like MSE, but we have to take $log$ of the actual and estimated outputs because squaring and averaging. \n",
        "\n",
        "The introduction of the logarithm makes MSLE only care about the relative difference between the true and the predicted value, or in other words, it only cares about the percentual difference between them.\n",
        "\n",
        "This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values.\n",
        "\n",
        "We can use MSLE when we don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large.\n",
        "\n",
        "*Example*: You want to predict future house prices, and your dataset includes homes that are orders of magnitude different in price. The price is a continuous value, and therefore, we want to do regression. MSLE can here be used as the loss function.\n",
        "\n",
        "$$MSLE = \\frac{\\sum_{i=1}^{n}(\\log(y_i+1) - \\log(\\hat{y}_i+1))^2}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBkzaP9R7KnB",
        "outputId": "327438d2-4410-446d-cf4b-e0e84a36c2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
        "              metrics=['mean_squared_logarithmic_error'])\n",
        "\n",
        "history = model.fit(train_features, train_labels, epochs=150, validation_split = 0.1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 8.6406 - mean_squared_logarithmic_error: 8.6406 - val_loss: 6.4534 - val_mean_squared_logarithmic_error: 6.4534\n",
            "Epoch 2/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.4252 - mean_squared_logarithmic_error: 5.4252 - val_loss: 4.0608 - val_mean_squared_logarithmic_error: 4.0608\n",
            "Epoch 3/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.4239 - mean_squared_logarithmic_error: 3.4239 - val_loss: 2.4711 - val_mean_squared_logarithmic_error: 2.4711\n",
            "Epoch 4/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0915 - mean_squared_logarithmic_error: 2.0915 - val_loss: 1.4546 - val_mean_squared_logarithmic_error: 1.4546\n",
            "Epoch 5/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2406 - mean_squared_logarithmic_error: 1.2406 - val_loss: 0.8213 - val_mean_squared_logarithmic_error: 0.8213\n",
            "Epoch 6/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7213 - mean_squared_logarithmic_error: 0.7213 - val_loss: 0.4632 - val_mean_squared_logarithmic_error: 0.4632\n",
            "Epoch 7/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4283 - mean_squared_logarithmic_error: 0.4283 - val_loss: 0.2753 - val_mean_squared_logarithmic_error: 0.2753\n",
            "Epoch 8/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2736 - mean_squared_logarithmic_error: 0.2736 - val_loss: 0.1777 - val_mean_squared_logarithmic_error: 0.1777\n",
            "Epoch 9/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1921 - mean_squared_logarithmic_error: 0.1921 - val_loss: 0.1302 - val_mean_squared_logarithmic_error: 0.1302\n",
            "Epoch 10/150\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1495 - mean_squared_logarithmic_error: 0.1495 - val_loss: 0.1057 - val_mean_squared_logarithmic_error: 0.1057\n",
            "Epoch 11/150\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1263 - mean_squared_logarithmic_error: 0.1263 - val_loss: 0.0907 - val_mean_squared_logarithmic_error: 0.0907\n",
            "Epoch 12/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1103 - mean_squared_logarithmic_error: 0.1103 - val_loss: 0.0809 - val_mean_squared_logarithmic_error: 0.0809\n",
            "Epoch 13/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0993 - mean_squared_logarithmic_error: 0.0993 - val_loss: 0.0738 - val_mean_squared_logarithmic_error: 0.0738\n",
            "Epoch 14/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0911 - mean_squared_logarithmic_error: 0.0911 - val_loss: 0.0670 - val_mean_squared_logarithmic_error: 0.0670\n",
            "Epoch 15/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0837 - mean_squared_logarithmic_error: 0.0837 - val_loss: 0.0619 - val_mean_squared_logarithmic_error: 0.0619\n",
            "Epoch 16/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0780 - mean_squared_logarithmic_error: 0.0780 - val_loss: 0.0573 - val_mean_squared_logarithmic_error: 0.0573\n",
            "Epoch 17/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0730 - mean_squared_logarithmic_error: 0.0730 - val_loss: 0.0529 - val_mean_squared_logarithmic_error: 0.0529\n",
            "Epoch 18/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0680 - mean_squared_logarithmic_error: 0.0680 - val_loss: 0.0492 - val_mean_squared_logarithmic_error: 0.0492\n",
            "Epoch 19/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0638 - mean_squared_logarithmic_error: 0.0638 - val_loss: 0.0459 - val_mean_squared_logarithmic_error: 0.0459\n",
            "Epoch 20/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0600 - mean_squared_logarithmic_error: 0.0600 - val_loss: 0.0429 - val_mean_squared_logarithmic_error: 0.0429\n",
            "Epoch 21/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0566 - mean_squared_logarithmic_error: 0.0566 - val_loss: 0.0402 - val_mean_squared_logarithmic_error: 0.0402\n",
            "Epoch 22/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0536 - mean_squared_logarithmic_error: 0.0536 - val_loss: 0.0380 - val_mean_squared_logarithmic_error: 0.0380\n",
            "Epoch 23/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0509 - mean_squared_logarithmic_error: 0.0509 - val_loss: 0.0361 - val_mean_squared_logarithmic_error: 0.0361\n",
            "Epoch 24/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0481 - mean_squared_logarithmic_error: 0.0481 - val_loss: 0.0345 - val_mean_squared_logarithmic_error: 0.0345\n",
            "Epoch 25/150\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0457 - mean_squared_logarithmic_error: 0.0457 - val_loss: 0.0332 - val_mean_squared_logarithmic_error: 0.0332\n",
            "Epoch 26/150\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0440 - mean_squared_logarithmic_error: 0.0440 - val_loss: 0.0321 - val_mean_squared_logarithmic_error: 0.0321\n",
            "Epoch 27/150\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0420 - mean_squared_logarithmic_error: 0.0420 - val_loss: 0.0310 - val_mean_squared_logarithmic_error: 0.0310\n",
            "Epoch 28/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0404 - mean_squared_logarithmic_error: 0.0404 - val_loss: 0.0302 - val_mean_squared_logarithmic_error: 0.0302\n",
            "Epoch 29/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0389 - mean_squared_logarithmic_error: 0.0389 - val_loss: 0.0295 - val_mean_squared_logarithmic_error: 0.0295\n",
            "Epoch 30/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0375 - mean_squared_logarithmic_error: 0.0375 - val_loss: 0.0289 - val_mean_squared_logarithmic_error: 0.0289\n",
            "Epoch 31/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0364 - mean_squared_logarithmic_error: 0.0364 - val_loss: 0.0285 - val_mean_squared_logarithmic_error: 0.0285\n",
            "Epoch 32/150\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0354 - mean_squared_logarithmic_error: 0.0354 - val_loss: 0.0283 - val_mean_squared_logarithmic_error: 0.0283\n",
            "Epoch 33/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0342 - mean_squared_logarithmic_error: 0.0342 - val_loss: 0.0280 - val_mean_squared_logarithmic_error: 0.0280\n",
            "Epoch 34/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0333 - mean_squared_logarithmic_error: 0.0333 - val_loss: 0.0276 - val_mean_squared_logarithmic_error: 0.0276\n",
            "Epoch 35/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0325 - mean_squared_logarithmic_error: 0.0325 - val_loss: 0.0276 - val_mean_squared_logarithmic_error: 0.0276\n",
            "Epoch 36/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0318 - mean_squared_logarithmic_error: 0.0318 - val_loss: 0.0268 - val_mean_squared_logarithmic_error: 0.0268\n",
            "Epoch 37/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0312 - mean_squared_logarithmic_error: 0.0312 - val_loss: 0.0266 - val_mean_squared_logarithmic_error: 0.0266\n",
            "Epoch 38/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0306 - mean_squared_logarithmic_error: 0.0306 - val_loss: 0.0267 - val_mean_squared_logarithmic_error: 0.0267\n",
            "Epoch 39/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0299 - mean_squared_logarithmic_error: 0.0299 - val_loss: 0.0264 - val_mean_squared_logarithmic_error: 0.0264\n",
            "Epoch 40/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0293 - mean_squared_logarithmic_error: 0.0293 - val_loss: 0.0262 - val_mean_squared_logarithmic_error: 0.0262\n",
            "Epoch 41/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0289 - mean_squared_logarithmic_error: 0.0289 - val_loss: 0.0261 - val_mean_squared_logarithmic_error: 0.0261\n",
            "Epoch 42/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0283 - mean_squared_logarithmic_error: 0.0283 - val_loss: 0.0263 - val_mean_squared_logarithmic_error: 0.0263\n",
            "Epoch 43/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0281 - mean_squared_logarithmic_error: 0.0281 - val_loss: 0.0265 - val_mean_squared_logarithmic_error: 0.0265\n",
            "Epoch 44/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0276 - mean_squared_logarithmic_error: 0.0276 - val_loss: 0.0257 - val_mean_squared_logarithmic_error: 0.0257\n",
            "Epoch 45/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0271 - mean_squared_logarithmic_error: 0.0271 - val_loss: 0.0251 - val_mean_squared_logarithmic_error: 0.0251\n",
            "Epoch 46/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0269 - mean_squared_logarithmic_error: 0.0269 - val_loss: 0.0249 - val_mean_squared_logarithmic_error: 0.0249\n",
            "Epoch 47/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0265 - mean_squared_logarithmic_error: 0.0265 - val_loss: 0.0250 - val_mean_squared_logarithmic_error: 0.0250\n",
            "Epoch 48/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0262 - mean_squared_logarithmic_error: 0.0262 - val_loss: 0.0248 - val_mean_squared_logarithmic_error: 0.0248\n",
            "Epoch 49/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0259 - mean_squared_logarithmic_error: 0.0259 - val_loss: 0.0243 - val_mean_squared_logarithmic_error: 0.0243\n",
            "Epoch 50/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0256 - mean_squared_logarithmic_error: 0.0256 - val_loss: 0.0242 - val_mean_squared_logarithmic_error: 0.0242\n",
            "Epoch 51/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0252 - mean_squared_logarithmic_error: 0.0252 - val_loss: 0.0245 - val_mean_squared_logarithmic_error: 0.0245\n",
            "Epoch 52/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0250 - mean_squared_logarithmic_error: 0.0250 - val_loss: 0.0240 - val_mean_squared_logarithmic_error: 0.0240\n",
            "Epoch 53/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0247 - mean_squared_logarithmic_error: 0.0247 - val_loss: 0.0240 - val_mean_squared_logarithmic_error: 0.0240\n",
            "Epoch 54/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0247 - mean_squared_logarithmic_error: 0.0247 - val_loss: 0.0247 - val_mean_squared_logarithmic_error: 0.0247\n",
            "Epoch 55/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0243 - mean_squared_logarithmic_error: 0.0243 - val_loss: 0.0239 - val_mean_squared_logarithmic_error: 0.0239\n",
            "Epoch 56/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0240 - mean_squared_logarithmic_error: 0.0240 - val_loss: 0.0233 - val_mean_squared_logarithmic_error: 0.0233\n",
            "Epoch 57/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0237 - mean_squared_logarithmic_error: 0.0237 - val_loss: 0.0233 - val_mean_squared_logarithmic_error: 0.0233\n",
            "Epoch 58/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0235 - mean_squared_logarithmic_error: 0.0235 - val_loss: 0.0229 - val_mean_squared_logarithmic_error: 0.0229\n",
            "Epoch 59/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0233 - mean_squared_logarithmic_error: 0.0233 - val_loss: 0.0231 - val_mean_squared_logarithmic_error: 0.0231\n",
            "Epoch 60/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0231 - mean_squared_logarithmic_error: 0.0231 - val_loss: 0.0234 - val_mean_squared_logarithmic_error: 0.0234\n",
            "Epoch 61/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0228 - mean_squared_logarithmic_error: 0.0228 - val_loss: 0.0227 - val_mean_squared_logarithmic_error: 0.0227\n",
            "Epoch 62/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0227 - mean_squared_logarithmic_error: 0.0227 - val_loss: 0.0224 - val_mean_squared_logarithmic_error: 0.0224\n",
            "Epoch 63/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0225 - mean_squared_logarithmic_error: 0.0225 - val_loss: 0.0222 - val_mean_squared_logarithmic_error: 0.0222\n",
            "Epoch 64/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0223 - mean_squared_logarithmic_error: 0.0223 - val_loss: 0.0230 - val_mean_squared_logarithmic_error: 0.0230\n",
            "Epoch 65/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0221 - mean_squared_logarithmic_error: 0.0221 - val_loss: 0.0225 - val_mean_squared_logarithmic_error: 0.0225\n",
            "Epoch 66/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0219 - mean_squared_logarithmic_error: 0.0219 - val_loss: 0.0225 - val_mean_squared_logarithmic_error: 0.0225\n",
            "Epoch 67/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0220 - mean_squared_logarithmic_error: 0.0220 - val_loss: 0.0217 - val_mean_squared_logarithmic_error: 0.0217\n",
            "Epoch 68/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0215 - mean_squared_logarithmic_error: 0.0215 - val_loss: 0.0223 - val_mean_squared_logarithmic_error: 0.0223\n",
            "Epoch 69/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0216 - mean_squared_logarithmic_error: 0.0216 - val_loss: 0.0225 - val_mean_squared_logarithmic_error: 0.0225\n",
            "Epoch 70/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0213 - mean_squared_logarithmic_error: 0.0213 - val_loss: 0.0218 - val_mean_squared_logarithmic_error: 0.0218\n",
            "Epoch 71/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0213 - mean_squared_logarithmic_error: 0.0213 - val_loss: 0.0215 - val_mean_squared_logarithmic_error: 0.0215\n",
            "Epoch 72/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0211 - mean_squared_logarithmic_error: 0.0211 - val_loss: 0.0225 - val_mean_squared_logarithmic_error: 0.0225\n",
            "Epoch 73/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0209 - mean_squared_logarithmic_error: 0.0209 - val_loss: 0.0218 - val_mean_squared_logarithmic_error: 0.0218\n",
            "Epoch 74/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0207 - mean_squared_logarithmic_error: 0.0207 - val_loss: 0.0219 - val_mean_squared_logarithmic_error: 0.0219\n",
            "Epoch 75/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0205 - mean_squared_logarithmic_error: 0.0205 - val_loss: 0.0213 - val_mean_squared_logarithmic_error: 0.0213\n",
            "Epoch 76/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0205 - mean_squared_logarithmic_error: 0.0205 - val_loss: 0.0210 - val_mean_squared_logarithmic_error: 0.0210\n",
            "Epoch 77/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0203 - mean_squared_logarithmic_error: 0.0203 - val_loss: 0.0211 - val_mean_squared_logarithmic_error: 0.0211\n",
            "Epoch 78/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0203 - mean_squared_logarithmic_error: 0.0203 - val_loss: 0.0215 - val_mean_squared_logarithmic_error: 0.0215\n",
            "Epoch 79/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0201 - mean_squared_logarithmic_error: 0.0201 - val_loss: 0.0211 - val_mean_squared_logarithmic_error: 0.0211\n",
            "Epoch 80/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0200 - mean_squared_logarithmic_error: 0.0200 - val_loss: 0.0201 - val_mean_squared_logarithmic_error: 0.0201\n",
            "Epoch 81/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0199 - mean_squared_logarithmic_error: 0.0199 - val_loss: 0.0204 - val_mean_squared_logarithmic_error: 0.0204\n",
            "Epoch 82/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0197 - mean_squared_logarithmic_error: 0.0197 - val_loss: 0.0207 - val_mean_squared_logarithmic_error: 0.0207\n",
            "Epoch 83/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0196 - mean_squared_logarithmic_error: 0.0196 - val_loss: 0.0204 - val_mean_squared_logarithmic_error: 0.0204\n",
            "Epoch 84/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0195 - mean_squared_logarithmic_error: 0.0195 - val_loss: 0.0205 - val_mean_squared_logarithmic_error: 0.0205\n",
            "Epoch 85/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0194 - mean_squared_logarithmic_error: 0.0194 - val_loss: 0.0209 - val_mean_squared_logarithmic_error: 0.0209\n",
            "Epoch 86/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0193 - mean_squared_logarithmic_error: 0.0193 - val_loss: 0.0203 - val_mean_squared_logarithmic_error: 0.0203\n",
            "Epoch 87/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0192 - mean_squared_logarithmic_error: 0.0192 - val_loss: 0.0204 - val_mean_squared_logarithmic_error: 0.0204\n",
            "Epoch 88/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0192 - mean_squared_logarithmic_error: 0.0192 - val_loss: 0.0205 - val_mean_squared_logarithmic_error: 0.0205\n",
            "Epoch 89/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0190 - mean_squared_logarithmic_error: 0.0190 - val_loss: 0.0201 - val_mean_squared_logarithmic_error: 0.0201\n",
            "Epoch 90/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0189 - mean_squared_logarithmic_error: 0.0189 - val_loss: 0.0201 - val_mean_squared_logarithmic_error: 0.0201\n",
            "Epoch 91/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0189 - mean_squared_logarithmic_error: 0.0189 - val_loss: 0.0204 - val_mean_squared_logarithmic_error: 0.0204\n",
            "Epoch 92/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0187 - mean_squared_logarithmic_error: 0.0187 - val_loss: 0.0203 - val_mean_squared_logarithmic_error: 0.0203\n",
            "Epoch 93/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0187 - mean_squared_logarithmic_error: 0.0187 - val_loss: 0.0204 - val_mean_squared_logarithmic_error: 0.0204\n",
            "Epoch 94/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0185 - mean_squared_logarithmic_error: 0.0185 - val_loss: 0.0195 - val_mean_squared_logarithmic_error: 0.0195\n",
            "Epoch 95/150\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0186 - mean_squared_logarithmic_error: 0.0186 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 96/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0184 - mean_squared_logarithmic_error: 0.0184 - val_loss: 0.0205 - val_mean_squared_logarithmic_error: 0.0205\n",
            "Epoch 97/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0183 - mean_squared_logarithmic_error: 0.0183 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 98/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0181 - mean_squared_logarithmic_error: 0.0181 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 99/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0182 - mean_squared_logarithmic_error: 0.0182 - val_loss: 0.0199 - val_mean_squared_logarithmic_error: 0.0199\n",
            "Epoch 100/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0180 - mean_squared_logarithmic_error: 0.0180 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 101/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0179 - mean_squared_logarithmic_error: 0.0179 - val_loss: 0.0192 - val_mean_squared_logarithmic_error: 0.0192\n",
            "Epoch 102/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0181 - mean_squared_logarithmic_error: 0.0181 - val_loss: 0.0196 - val_mean_squared_logarithmic_error: 0.0196\n",
            "Epoch 103/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0179 - mean_squared_logarithmic_error: 0.0179 - val_loss: 0.0196 - val_mean_squared_logarithmic_error: 0.0196\n",
            "Epoch 104/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0179 - mean_squared_logarithmic_error: 0.0179 - val_loss: 0.0203 - val_mean_squared_logarithmic_error: 0.0203\n",
            "Epoch 105/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 106/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0175 - mean_squared_logarithmic_error: 0.0175 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 107/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0196 - val_mean_squared_logarithmic_error: 0.0196\n",
            "Epoch 108/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0196 - val_mean_squared_logarithmic_error: 0.0196\n",
            "Epoch 109/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0203 - val_mean_squared_logarithmic_error: 0.0203\n",
            "Epoch 110/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0175 - mean_squared_logarithmic_error: 0.0175 - val_loss: 0.0192 - val_mean_squared_logarithmic_error: 0.0192\n",
            "Epoch 111/150\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0173 - mean_squared_logarithmic_error: 0.0173 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 112/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0171 - mean_squared_logarithmic_error: 0.0171 - val_loss: 0.0206 - val_mean_squared_logarithmic_error: 0.0206\n",
            "Epoch 113/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0171 - mean_squared_logarithmic_error: 0.0171 - val_loss: 0.0200 - val_mean_squared_logarithmic_error: 0.0200\n",
            "Epoch 114/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0170 - mean_squared_logarithmic_error: 0.0170 - val_loss: 0.0201 - val_mean_squared_logarithmic_error: 0.0201\n",
            "Epoch 115/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0169 - mean_squared_logarithmic_error: 0.0169 - val_loss: 0.0200 - val_mean_squared_logarithmic_error: 0.0200\n",
            "Epoch 116/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0170 - mean_squared_logarithmic_error: 0.0170 - val_loss: 0.0195 - val_mean_squared_logarithmic_error: 0.0195\n",
            "Epoch 117/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0168 - mean_squared_logarithmic_error: 0.0168 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 118/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0169 - mean_squared_logarithmic_error: 0.0169 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 119/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0168 - mean_squared_logarithmic_error: 0.0168 - val_loss: 0.0200 - val_mean_squared_logarithmic_error: 0.0200\n",
            "Epoch 120/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0167 - mean_squared_logarithmic_error: 0.0167 - val_loss: 0.0192 - val_mean_squared_logarithmic_error: 0.0192\n",
            "Epoch 121/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0166 - mean_squared_logarithmic_error: 0.0166 - val_loss: 0.0196 - val_mean_squared_logarithmic_error: 0.0196\n",
            "Epoch 122/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0165 - mean_squared_logarithmic_error: 0.0165 - val_loss: 0.0196 - val_mean_squared_logarithmic_error: 0.0196\n",
            "Epoch 123/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0167 - mean_squared_logarithmic_error: 0.0167 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 124/150\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0164 - mean_squared_logarithmic_error: 0.0164 - val_loss: 0.0197 - val_mean_squared_logarithmic_error: 0.0197\n",
            "Epoch 125/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0164 - mean_squared_logarithmic_error: 0.0164 - val_loss: 0.0192 - val_mean_squared_logarithmic_error: 0.0192\n",
            "Epoch 126/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0166 - mean_squared_logarithmic_error: 0.0166 - val_loss: 0.0190 - val_mean_squared_logarithmic_error: 0.0190\n",
            "Epoch 127/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0162 - mean_squared_logarithmic_error: 0.0162 - val_loss: 0.0202 - val_mean_squared_logarithmic_error: 0.0202\n",
            "Epoch 128/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0162 - mean_squared_logarithmic_error: 0.0162 - val_loss: 0.0195 - val_mean_squared_logarithmic_error: 0.0195\n",
            "Epoch 129/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0161 - mean_squared_logarithmic_error: 0.0161 - val_loss: 0.0188 - val_mean_squared_logarithmic_error: 0.0188\n",
            "Epoch 130/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0162 - mean_squared_logarithmic_error: 0.0162 - val_loss: 0.0190 - val_mean_squared_logarithmic_error: 0.0190\n",
            "Epoch 131/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0160 - mean_squared_logarithmic_error: 0.0160 - val_loss: 0.0194 - val_mean_squared_logarithmic_error: 0.0194\n",
            "Epoch 132/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0159 - mean_squared_logarithmic_error: 0.0159 - val_loss: 0.0192 - val_mean_squared_logarithmic_error: 0.0192\n",
            "Epoch 133/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0158 - mean_squared_logarithmic_error: 0.0158 - val_loss: 0.0191 - val_mean_squared_logarithmic_error: 0.0191\n",
            "Epoch 134/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0158 - mean_squared_logarithmic_error: 0.0158 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 135/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0158 - mean_squared_logarithmic_error: 0.0158 - val_loss: 0.0191 - val_mean_squared_logarithmic_error: 0.0191\n",
            "Epoch 136/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0158 - mean_squared_logarithmic_error: 0.0158 - val_loss: 0.0191 - val_mean_squared_logarithmic_error: 0.0191\n",
            "Epoch 137/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0157 - mean_squared_logarithmic_error: 0.0157 - val_loss: 0.0186 - val_mean_squared_logarithmic_error: 0.0186\n",
            "Epoch 138/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0156 - mean_squared_logarithmic_error: 0.0156 - val_loss: 0.0190 - val_mean_squared_logarithmic_error: 0.0190\n",
            "Epoch 139/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_squared_logarithmic_error: 0.0156 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 140/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0158 - mean_squared_logarithmic_error: 0.0158 - val_loss: 0.0184 - val_mean_squared_logarithmic_error: 0.0184\n",
            "Epoch 141/150\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0154 - mean_squared_logarithmic_error: 0.0154 - val_loss: 0.0189 - val_mean_squared_logarithmic_error: 0.0189\n",
            "Epoch 142/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0154 - mean_squared_logarithmic_error: 0.0154 - val_loss: 0.0189 - val_mean_squared_logarithmic_error: 0.0189\n",
            "Epoch 143/150\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0188 - val_mean_squared_logarithmic_error: 0.0188\n",
            "Epoch 144/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0189 - val_mean_squared_logarithmic_error: 0.0189\n",
            "Epoch 145/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0152 - mean_squared_logarithmic_error: 0.0152 - val_loss: 0.0188 - val_mean_squared_logarithmic_error: 0.0188\n",
            "Epoch 146/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0195 - val_mean_squared_logarithmic_error: 0.0195\n",
            "Epoch 147/150\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0191 - val_mean_squared_logarithmic_error: 0.0191\n",
            "Epoch 148/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0185 - val_mean_squared_logarithmic_error: 0.0185\n",
            "Epoch 149/150\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0151 - mean_squared_logarithmic_error: 0.0151 - val_loss: 0.0194 - val_mean_squared_logarithmic_error: 0.0194\n",
            "Epoch 150/150\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0150 - mean_squared_logarithmic_error: 0.0150 - val_loss: 0.0187 - val_mean_squared_logarithmic_error: 0.0187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc_jN5XwcBu9"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Now that you know how MSLE works, you need to plot the behavior of MSLE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_USeo3P7cBu-"
      },
      "source": [
        "### Answer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHr_XxgUcBu-",
        "outputId": "4d15253e-6d10-44bf-e0a6-b75bee00ae1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# actual_outputs = np.arange(0, 51)\n",
        "# n = len(actual_outputs)\n",
        "# estimated_outputs = np.zeros(n)\n",
        "\n",
        "msle = history.history['mean_squared_logarithmic_error']\n",
        "val_msle = history.history['val_mean_squared_logarithmic_error']\n",
        "\n",
        "plt.plot(msle, marker='o')\n",
        "plt.plot(val_msle, marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Actual ouputs')\n",
        "plt.ylabel('Mean Squared Logarithmic Errors')\n",
        "plt.legend(['train', 'valid'])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BylzTZ1W9Ma"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Why do we add $1$ to the outputs before passing it through $\\log()$? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX5w42vRXMWj"
      },
      "source": [
        "### Answer \n",
        "\n",
        "In mean squared logarithmic error (MSLE), adding 1 to the outputs is a common practice in many regression problems, particularly when the predicted values can be very small. By adding 1 to the predicted values, the logarithmic error is penalized less when the predictions are close to 0 and more when the predictions are far from 0. This helps to address the issue of penalizing large errors more than small errors, which is a common issue with mean squared error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQiO_XeYTjE"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "Write your observations about MSE, MAE, and MSLE; and compare the results achieved with all 3 loss functions. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOUf7iOkYxcM"
      },
      "source": [
        "### Answer 5\n",
        "\n",
        "\n",
        "MSE, MAE, and MSLE are all commonly used loss functions in regression problems. Each of these loss functions have different characteristics that make them appropriate for different use cases.\n",
        "\n",
        "Mean Squared Error (MSE) is a widely used loss function that measures the average squared difference between the predicted and actual values. MSE penalizes large errors more than small errors, which makes it sensitive to outliers. MSE is widely used in regression problems where it is important to penalize large errors.\n",
        "\n",
        "Mean Absolute Error (MAE) is another commonly used loss function that measures the average absolute difference between the predicted and actual values. Unlike MSE, MAE does not penalize large errors more than small errors. This makes MAE less sensitive to outliers compared to MSE. MAE is often used in regression problems where it is important to give equal weight to both large and small errors.\n",
        "\n",
        "Mean Squared Logarithmic Error (MSLE) is a loss function that measures the average squared difference between the logarithms of the predicted and actual values. MSLE is similar to MSE in that it penalizes large errors more than small errors, but the difference is that MSLE penalizes the logarithmic difference between the predicted and actual values instead of the absolute difference. MSLE is often used in regression problems where the target values can be very small, as it is more appropriate in such cases compared to MSE or MAE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efp4KP5GfDL7"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "Plug-in any of the loss functions from [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/losses) docs to the `model.compile` method and see if the difference in model performance as compared to MSE, MAE, and MSLE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_9nfLOffJ_P"
      },
      "source": [
        "### Answer 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDWlkms1flkZ",
        "outputId": "c71415d2-1d04-4fd5-b52b-d4f6bfb3ca46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss= 'mean_absolute_percentage_error',\n",
        "              metrics=['mean_absolute_percentage_error'])\n",
        "\n",
        "model.fit(train_features, train_labels, epochs=250, validation_split = 0.1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 97.1176 - mean_absolute_percentage_error: 97.1176 - val_loss: 93.9386 - val_mean_absolute_percentage_error: 93.9386\n",
            "Epoch 2/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 90.5680 - mean_absolute_percentage_error: 90.5680 - val_loss: 85.2246 - val_mean_absolute_percentage_error: 85.2246\n",
            "Epoch 3/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 79.6061 - mean_absolute_percentage_error: 79.6061 - val_loss: 72.1590 - val_mean_absolute_percentage_error: 72.1590\n",
            "Epoch 4/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 63.5903 - mean_absolute_percentage_error: 63.5903 - val_loss: 55.6233 - val_mean_absolute_percentage_error: 55.6233\n",
            "Epoch 5/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 47.1480 - mean_absolute_percentage_error: 47.1480 - val_loss: 36.0752 - val_mean_absolute_percentage_error: 36.0752\n",
            "Epoch 6/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 32.1688 - mean_absolute_percentage_error: 32.1688 - val_loss: 25.9294 - val_mean_absolute_percentage_error: 25.9294\n",
            "Epoch 7/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26.3531 - mean_absolute_percentage_error: 26.3531 - val_loss: 21.2228 - val_mean_absolute_percentage_error: 21.2228\n",
            "Epoch 8/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21.1796 - mean_absolute_percentage_error: 21.1796 - val_loss: 16.0081 - val_mean_absolute_percentage_error: 16.0081\n",
            "Epoch 9/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17.5971 - mean_absolute_percentage_error: 17.5971 - val_loss: 15.0329 - val_mean_absolute_percentage_error: 15.0329\n",
            "Epoch 10/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 15.3323 - mean_absolute_percentage_error: 15.3323 - val_loss: 15.1700 - val_mean_absolute_percentage_error: 15.1700\n",
            "Epoch 11/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 14.1193 - mean_absolute_percentage_error: 14.1193 - val_loss: 14.5017 - val_mean_absolute_percentage_error: 14.5017\n",
            "Epoch 12/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 13.6199 - mean_absolute_percentage_error: 13.6199 - val_loss: 14.0912 - val_mean_absolute_percentage_error: 14.0912\n",
            "Epoch 13/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13.1089 - mean_absolute_percentage_error: 13.1089 - val_loss: 14.5580 - val_mean_absolute_percentage_error: 14.5580\n",
            "Epoch 14/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.7141 - mean_absolute_percentage_error: 12.7141 - val_loss: 13.5769 - val_mean_absolute_percentage_error: 13.5769\n",
            "Epoch 15/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.4172 - mean_absolute_percentage_error: 12.4172 - val_loss: 13.8104 - val_mean_absolute_percentage_error: 13.8104\n",
            "Epoch 16/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12.1314 - mean_absolute_percentage_error: 12.1314 - val_loss: 12.8422 - val_mean_absolute_percentage_error: 12.8422\n",
            "Epoch 17/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.6927 - mean_absolute_percentage_error: 11.6927 - val_loss: 13.0092 - val_mean_absolute_percentage_error: 13.0092\n",
            "Epoch 18/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11.3125 - mean_absolute_percentage_error: 11.3125 - val_loss: 12.8049 - val_mean_absolute_percentage_error: 12.8049\n",
            "Epoch 19/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11.1172 - mean_absolute_percentage_error: 11.1172 - val_loss: 12.3955 - val_mean_absolute_percentage_error: 12.3955\n",
            "Epoch 20/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.8076 - mean_absolute_percentage_error: 10.8076 - val_loss: 12.6592 - val_mean_absolute_percentage_error: 12.6592\n",
            "Epoch 21/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.5686 - mean_absolute_percentage_error: 10.5686 - val_loss: 12.6738 - val_mean_absolute_percentage_error: 12.6738\n",
            "Epoch 22/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.3415 - mean_absolute_percentage_error: 10.3415 - val_loss: 12.5602 - val_mean_absolute_percentage_error: 12.5602\n",
            "Epoch 23/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.0846 - mean_absolute_percentage_error: 10.0846 - val_loss: 12.0156 - val_mean_absolute_percentage_error: 12.0156\n",
            "Epoch 24/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.1315 - mean_absolute_percentage_error: 10.1315 - val_loss: 12.6325 - val_mean_absolute_percentage_error: 12.6325\n",
            "Epoch 25/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.8683 - mean_absolute_percentage_error: 9.8683 - val_loss: 11.8384 - val_mean_absolute_percentage_error: 11.8384\n",
            "Epoch 26/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.9208 - mean_absolute_percentage_error: 9.9208 - val_loss: 11.9614 - val_mean_absolute_percentage_error: 11.9614\n",
            "Epoch 27/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.6967 - mean_absolute_percentage_error: 9.6967 - val_loss: 12.7737 - val_mean_absolute_percentage_error: 12.7737\n",
            "Epoch 28/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.6760 - mean_absolute_percentage_error: 9.6760 - val_loss: 11.8810 - val_mean_absolute_percentage_error: 11.8810\n",
            "Epoch 29/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.8077 - mean_absolute_percentage_error: 9.8077 - val_loss: 12.1063 - val_mean_absolute_percentage_error: 12.1063\n",
            "Epoch 30/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.6698 - mean_absolute_percentage_error: 9.6698 - val_loss: 11.8680 - val_mean_absolute_percentage_error: 11.8680\n",
            "Epoch 31/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.4940 - mean_absolute_percentage_error: 9.4940 - val_loss: 12.4233 - val_mean_absolute_percentage_error: 12.4233\n",
            "Epoch 32/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.4748 - mean_absolute_percentage_error: 9.4748 - val_loss: 11.4418 - val_mean_absolute_percentage_error: 11.4418\n",
            "Epoch 33/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.4508 - mean_absolute_percentage_error: 9.4508 - val_loss: 12.5288 - val_mean_absolute_percentage_error: 12.5288\n",
            "Epoch 34/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.4544 - mean_absolute_percentage_error: 9.4544 - val_loss: 12.1591 - val_mean_absolute_percentage_error: 12.1591\n",
            "Epoch 35/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.1818 - mean_absolute_percentage_error: 9.1818 - val_loss: 11.9934 - val_mean_absolute_percentage_error: 11.9934\n",
            "Epoch 36/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.2288 - mean_absolute_percentage_error: 9.2288 - val_loss: 11.1786 - val_mean_absolute_percentage_error: 11.1786\n",
            "Epoch 37/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.3353 - mean_absolute_percentage_error: 9.3353 - val_loss: 12.6361 - val_mean_absolute_percentage_error: 12.6361\n",
            "Epoch 38/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9.2276 - mean_absolute_percentage_error: 9.2276 - val_loss: 11.6323 - val_mean_absolute_percentage_error: 11.6323\n",
            "Epoch 39/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.9784 - mean_absolute_percentage_error: 8.9784 - val_loss: 12.1277 - val_mean_absolute_percentage_error: 12.1277\n",
            "Epoch 40/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.0693 - mean_absolute_percentage_error: 9.0693 - val_loss: 10.8596 - val_mean_absolute_percentage_error: 10.8596\n",
            "Epoch 41/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.0167 - mean_absolute_percentage_error: 9.0167 - val_loss: 11.8393 - val_mean_absolute_percentage_error: 11.8393\n",
            "Epoch 42/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.9477 - mean_absolute_percentage_error: 8.9477 - val_loss: 11.8364 - val_mean_absolute_percentage_error: 11.8364\n",
            "Epoch 43/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.7207 - mean_absolute_percentage_error: 8.7207 - val_loss: 11.5191 - val_mean_absolute_percentage_error: 11.5191\n",
            "Epoch 44/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.6890 - mean_absolute_percentage_error: 8.6890 - val_loss: 11.2938 - val_mean_absolute_percentage_error: 11.2938\n",
            "Epoch 45/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.6761 - mean_absolute_percentage_error: 8.6761 - val_loss: 12.0318 - val_mean_absolute_percentage_error: 12.0318\n",
            "Epoch 46/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.8141 - mean_absolute_percentage_error: 8.8141 - val_loss: 10.7379 - val_mean_absolute_percentage_error: 10.7379\n",
            "Epoch 47/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.7849 - mean_absolute_percentage_error: 8.7849 - val_loss: 11.1431 - val_mean_absolute_percentage_error: 11.1431\n",
            "Epoch 48/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.5026 - mean_absolute_percentage_error: 8.5026 - val_loss: 11.1763 - val_mean_absolute_percentage_error: 11.1763\n",
            "Epoch 49/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.5004 - mean_absolute_percentage_error: 8.5004 - val_loss: 11.5217 - val_mean_absolute_percentage_error: 11.5217\n",
            "Epoch 50/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.4735 - mean_absolute_percentage_error: 8.4735 - val_loss: 11.7506 - val_mean_absolute_percentage_error: 11.7506\n",
            "Epoch 51/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.4083 - mean_absolute_percentage_error: 8.4083 - val_loss: 11.9040 - val_mean_absolute_percentage_error: 11.9040\n",
            "Epoch 52/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.7743 - mean_absolute_percentage_error: 8.7743 - val_loss: 11.3090 - val_mean_absolute_percentage_error: 11.3090\n",
            "Epoch 53/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.6452 - mean_absolute_percentage_error: 8.6452 - val_loss: 11.0755 - val_mean_absolute_percentage_error: 11.0755\n",
            "Epoch 54/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.4539 - mean_absolute_percentage_error: 8.4539 - val_loss: 11.8015 - val_mean_absolute_percentage_error: 11.8015\n",
            "Epoch 55/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.2759 - mean_absolute_percentage_error: 8.2759 - val_loss: 11.1695 - val_mean_absolute_percentage_error: 11.1695\n",
            "Epoch 56/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.2066 - mean_absolute_percentage_error: 8.2066 - val_loss: 11.2666 - val_mean_absolute_percentage_error: 11.2666\n",
            "Epoch 57/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.2580 - mean_absolute_percentage_error: 8.2580 - val_loss: 10.9181 - val_mean_absolute_percentage_error: 10.9181\n",
            "Epoch 58/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.1671 - mean_absolute_percentage_error: 8.1671 - val_loss: 10.9283 - val_mean_absolute_percentage_error: 10.9283\n",
            "Epoch 59/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.2388 - mean_absolute_percentage_error: 8.2388 - val_loss: 11.1687 - val_mean_absolute_percentage_error: 11.1687\n",
            "Epoch 60/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.1938 - mean_absolute_percentage_error: 8.1938 - val_loss: 11.3032 - val_mean_absolute_percentage_error: 11.3032\n",
            "Epoch 61/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.0296 - mean_absolute_percentage_error: 8.0296 - val_loss: 11.2749 - val_mean_absolute_percentage_error: 11.2749\n",
            "Epoch 62/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.0794 - mean_absolute_percentage_error: 8.0794 - val_loss: 11.4062 - val_mean_absolute_percentage_error: 11.4062\n",
            "Epoch 63/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.1241 - mean_absolute_percentage_error: 8.1241 - val_loss: 11.5016 - val_mean_absolute_percentage_error: 11.5016\n",
            "Epoch 64/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.9227 - mean_absolute_percentage_error: 7.9227 - val_loss: 10.7217 - val_mean_absolute_percentage_error: 10.7217\n",
            "Epoch 65/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8.0503 - mean_absolute_percentage_error: 8.0503 - val_loss: 11.3486 - val_mean_absolute_percentage_error: 11.3486\n",
            "Epoch 66/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.7554 - mean_absolute_percentage_error: 7.7554 - val_loss: 10.9019 - val_mean_absolute_percentage_error: 10.9019\n",
            "Epoch 67/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.7583 - mean_absolute_percentage_error: 7.7583 - val_loss: 11.1606 - val_mean_absolute_percentage_error: 11.1606\n",
            "Epoch 68/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.8552 - mean_absolute_percentage_error: 7.8552 - val_loss: 11.6299 - val_mean_absolute_percentage_error: 11.6299\n",
            "Epoch 69/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.9141 - mean_absolute_percentage_error: 7.9141 - val_loss: 11.3381 - val_mean_absolute_percentage_error: 11.3381\n",
            "Epoch 70/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.6218 - mean_absolute_percentage_error: 7.6218 - val_loss: 10.9496 - val_mean_absolute_percentage_error: 10.9496\n",
            "Epoch 71/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.9930 - mean_absolute_percentage_error: 7.9930 - val_loss: 10.7609 - val_mean_absolute_percentage_error: 10.7609\n",
            "Epoch 72/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.9267 - mean_absolute_percentage_error: 7.9267 - val_loss: 10.3420 - val_mean_absolute_percentage_error: 10.3420\n",
            "Epoch 73/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.6968 - mean_absolute_percentage_error: 7.6968 - val_loss: 11.5070 - val_mean_absolute_percentage_error: 11.5070\n",
            "Epoch 74/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.1025 - mean_absolute_percentage_error: 8.1025 - val_loss: 11.0799 - val_mean_absolute_percentage_error: 11.0799\n",
            "Epoch 75/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.8166 - mean_absolute_percentage_error: 7.8166 - val_loss: 10.8057 - val_mean_absolute_percentage_error: 10.8057\n",
            "Epoch 76/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 7.7512 - mean_absolute_percentage_error: 7.7512 - val_loss: 11.6926 - val_mean_absolute_percentage_error: 11.6926\n",
            "Epoch 77/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.7809 - mean_absolute_percentage_error: 7.7809 - val_loss: 10.7519 - val_mean_absolute_percentage_error: 10.7519\n",
            "Epoch 78/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.7509 - mean_absolute_percentage_error: 7.7509 - val_loss: 10.7411 - val_mean_absolute_percentage_error: 10.7411\n",
            "Epoch 79/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.8024 - mean_absolute_percentage_error: 7.8024 - val_loss: 10.6485 - val_mean_absolute_percentage_error: 10.6485\n",
            "Epoch 80/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.4792 - mean_absolute_percentage_error: 7.4792 - val_loss: 11.1860 - val_mean_absolute_percentage_error: 11.1860\n",
            "Epoch 81/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.2842 - mean_absolute_percentage_error: 7.2842 - val_loss: 10.9100 - val_mean_absolute_percentage_error: 10.9100\n",
            "Epoch 82/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.3297 - mean_absolute_percentage_error: 7.3297 - val_loss: 10.6347 - val_mean_absolute_percentage_error: 10.6347\n",
            "Epoch 83/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.1886 - mean_absolute_percentage_error: 7.1886 - val_loss: 10.8782 - val_mean_absolute_percentage_error: 10.8782\n",
            "Epoch 84/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.3733 - mean_absolute_percentage_error: 7.3733 - val_loss: 10.5388 - val_mean_absolute_percentage_error: 10.5388\n",
            "Epoch 85/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.3225 - mean_absolute_percentage_error: 7.3225 - val_loss: 10.8427 - val_mean_absolute_percentage_error: 10.8427\n",
            "Epoch 86/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.3677 - mean_absolute_percentage_error: 7.3677 - val_loss: 11.0406 - val_mean_absolute_percentage_error: 11.0406\n",
            "Epoch 87/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.2949 - mean_absolute_percentage_error: 7.2949 - val_loss: 10.6030 - val_mean_absolute_percentage_error: 10.6030\n",
            "Epoch 88/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.0844 - mean_absolute_percentage_error: 7.0844 - val_loss: 10.8021 - val_mean_absolute_percentage_error: 10.8021\n",
            "Epoch 89/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.1727 - mean_absolute_percentage_error: 7.1727 - val_loss: 10.5137 - val_mean_absolute_percentage_error: 10.5137\n",
            "Epoch 90/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.1214 - mean_absolute_percentage_error: 7.1214 - val_loss: 10.9526 - val_mean_absolute_percentage_error: 10.9526\n",
            "Epoch 91/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.0364 - mean_absolute_percentage_error: 7.0364 - val_loss: 11.1684 - val_mean_absolute_percentage_error: 11.1684\n",
            "Epoch 92/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.0483 - mean_absolute_percentage_error: 7.0483 - val_loss: 10.8650 - val_mean_absolute_percentage_error: 10.8650\n",
            "Epoch 93/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 7.3487 - mean_absolute_percentage_error: 7.3487 - val_loss: 11.2267 - val_mean_absolute_percentage_error: 11.2267\n",
            "Epoch 94/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.3801 - mean_absolute_percentage_error: 7.3801 - val_loss: 11.0149 - val_mean_absolute_percentage_error: 11.0149\n",
            "Epoch 95/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.2012 - mean_absolute_percentage_error: 7.2012 - val_loss: 11.1242 - val_mean_absolute_percentage_error: 11.1242\n",
            "Epoch 96/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.9149 - mean_absolute_percentage_error: 6.9149 - val_loss: 11.0701 - val_mean_absolute_percentage_error: 11.0701\n",
            "Epoch 97/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.9732 - mean_absolute_percentage_error: 6.9732 - val_loss: 11.1769 - val_mean_absolute_percentage_error: 11.1769\n",
            "Epoch 98/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.8582 - mean_absolute_percentage_error: 6.8582 - val_loss: 10.7061 - val_mean_absolute_percentage_error: 10.7061\n",
            "Epoch 99/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.8661 - mean_absolute_percentage_error: 6.8661 - val_loss: 10.6808 - val_mean_absolute_percentage_error: 10.6808\n",
            "Epoch 100/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8668 - mean_absolute_percentage_error: 6.8668 - val_loss: 10.6783 - val_mean_absolute_percentage_error: 10.6783\n",
            "Epoch 101/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.9107 - mean_absolute_percentage_error: 6.9107 - val_loss: 10.6708 - val_mean_absolute_percentage_error: 10.6708\n",
            "Epoch 102/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.2094 - mean_absolute_percentage_error: 7.2094 - val_loss: 10.7330 - val_mean_absolute_percentage_error: 10.7330\n",
            "Epoch 103/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.0870 - mean_absolute_percentage_error: 7.0870 - val_loss: 10.6659 - val_mean_absolute_percentage_error: 10.6659\n",
            "Epoch 104/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.1234 - mean_absolute_percentage_error: 7.1234 - val_loss: 11.1979 - val_mean_absolute_percentage_error: 11.1979\n",
            "Epoch 105/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9481 - mean_absolute_percentage_error: 6.9481 - val_loss: 10.5651 - val_mean_absolute_percentage_error: 10.5651\n",
            "Epoch 106/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.8841 - mean_absolute_percentage_error: 6.8841 - val_loss: 10.4242 - val_mean_absolute_percentage_error: 10.4242\n",
            "Epoch 107/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8378 - mean_absolute_percentage_error: 6.8378 - val_loss: 10.4757 - val_mean_absolute_percentage_error: 10.4757\n",
            "Epoch 108/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7453 - mean_absolute_percentage_error: 6.7453 - val_loss: 10.0988 - val_mean_absolute_percentage_error: 10.0988\n",
            "Epoch 109/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7697 - mean_absolute_percentage_error: 6.7697 - val_loss: 10.7432 - val_mean_absolute_percentage_error: 10.7432\n",
            "Epoch 110/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8764 - mean_absolute_percentage_error: 6.8764 - val_loss: 10.6711 - val_mean_absolute_percentage_error: 10.6711\n",
            "Epoch 111/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9015 - mean_absolute_percentage_error: 6.9015 - val_loss: 10.3054 - val_mean_absolute_percentage_error: 10.3054\n",
            "Epoch 112/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7802 - mean_absolute_percentage_error: 6.7802 - val_loss: 10.1682 - val_mean_absolute_percentage_error: 10.1682\n",
            "Epoch 113/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5977 - mean_absolute_percentage_error: 6.5977 - val_loss: 10.6376 - val_mean_absolute_percentage_error: 10.6376\n",
            "Epoch 114/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9266 - mean_absolute_percentage_error: 6.9266 - val_loss: 9.6592 - val_mean_absolute_percentage_error: 9.6592\n",
            "Epoch 115/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7165 - mean_absolute_percentage_error: 6.7165 - val_loss: 10.4725 - val_mean_absolute_percentage_error: 10.4725\n",
            "Epoch 116/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.5413 - mean_absolute_percentage_error: 6.5413 - val_loss: 10.3966 - val_mean_absolute_percentage_error: 10.3966\n",
            "Epoch 117/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.6811 - mean_absolute_percentage_error: 6.6811 - val_loss: 9.9922 - val_mean_absolute_percentage_error: 9.9922\n",
            "Epoch 118/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.4173 - mean_absolute_percentage_error: 6.4173 - val_loss: 10.5022 - val_mean_absolute_percentage_error: 10.5022\n",
            "Epoch 119/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.4374 - mean_absolute_percentage_error: 6.4374 - val_loss: 10.1653 - val_mean_absolute_percentage_error: 10.1653\n",
            "Epoch 120/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.3493 - mean_absolute_percentage_error: 6.3493 - val_loss: 10.8229 - val_mean_absolute_percentage_error: 10.8229\n",
            "Epoch 121/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.7237 - mean_absolute_percentage_error: 6.7237 - val_loss: 10.9127 - val_mean_absolute_percentage_error: 10.9127\n",
            "Epoch 122/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.6499 - mean_absolute_percentage_error: 6.6499 - val_loss: 10.3272 - val_mean_absolute_percentage_error: 10.3272\n",
            "Epoch 123/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.5005 - mean_absolute_percentage_error: 6.5005 - val_loss: 10.1442 - val_mean_absolute_percentage_error: 10.1442\n",
            "Epoch 124/250\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.3849 - mean_absolute_percentage_error: 6.3849 - val_loss: 10.0252 - val_mean_absolute_percentage_error: 10.0252\n",
            "Epoch 125/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.3537 - mean_absolute_percentage_error: 6.3537 - val_loss: 10.1098 - val_mean_absolute_percentage_error: 10.1098\n",
            "Epoch 126/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.1905 - mean_absolute_percentage_error: 6.1905 - val_loss: 10.0364 - val_mean_absolute_percentage_error: 10.0364\n",
            "Epoch 127/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.4949 - mean_absolute_percentage_error: 6.4949 - val_loss: 10.2046 - val_mean_absolute_percentage_error: 10.2046\n",
            "Epoch 128/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5442 - mean_absolute_percentage_error: 6.5442 - val_loss: 10.3999 - val_mean_absolute_percentage_error: 10.3999\n",
            "Epoch 129/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.5171 - mean_absolute_percentage_error: 6.5171 - val_loss: 10.5897 - val_mean_absolute_percentage_error: 10.5897\n",
            "Epoch 130/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.4249 - mean_absolute_percentage_error: 6.4249 - val_loss: 9.8497 - val_mean_absolute_percentage_error: 9.8497\n",
            "Epoch 131/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.2784 - mean_absolute_percentage_error: 6.2784 - val_loss: 10.0199 - val_mean_absolute_percentage_error: 10.0199\n",
            "Epoch 132/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.3450 - mean_absolute_percentage_error: 6.3450 - val_loss: 9.9689 - val_mean_absolute_percentage_error: 9.9689\n",
            "Epoch 133/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5572 - mean_absolute_percentage_error: 6.5572 - val_loss: 9.9914 - val_mean_absolute_percentage_error: 9.9914\n",
            "Epoch 134/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.2522 - mean_absolute_percentage_error: 6.2522 - val_loss: 10.0268 - val_mean_absolute_percentage_error: 10.0268\n",
            "Epoch 135/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.2908 - mean_absolute_percentage_error: 6.2908 - val_loss: 10.0738 - val_mean_absolute_percentage_error: 10.0738\n",
            "Epoch 136/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.2737 - mean_absolute_percentage_error: 6.2737 - val_loss: 10.1430 - val_mean_absolute_percentage_error: 10.1430\n",
            "Epoch 137/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0867 - mean_absolute_percentage_error: 6.0867 - val_loss: 9.6282 - val_mean_absolute_percentage_error: 9.6282\n",
            "Epoch 138/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.1310 - mean_absolute_percentage_error: 6.1310 - val_loss: 9.9706 - val_mean_absolute_percentage_error: 9.9706\n",
            "Epoch 139/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.1849 - mean_absolute_percentage_error: 6.1849 - val_loss: 10.3870 - val_mean_absolute_percentage_error: 10.3870\n",
            "Epoch 140/250\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 6.2222 - mean_absolute_percentage_error: 6.2222 - val_loss: 10.2582 - val_mean_absolute_percentage_error: 10.2582\n",
            "Epoch 141/250\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 6.2419 - mean_absolute_percentage_error: 6.2419 - val_loss: 10.2686 - val_mean_absolute_percentage_error: 10.2686\n",
            "Epoch 142/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 6.3213 - mean_absolute_percentage_error: 6.3213 - val_loss: 10.4534 - val_mean_absolute_percentage_error: 10.4534\n",
            "Epoch 143/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0561 - mean_absolute_percentage_error: 6.0561 - val_loss: 9.8287 - val_mean_absolute_percentage_error: 9.8287\n",
            "Epoch 144/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0471 - mean_absolute_percentage_error: 6.0471 - val_loss: 10.0306 - val_mean_absolute_percentage_error: 10.0306\n",
            "Epoch 145/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0174 - mean_absolute_percentage_error: 6.0174 - val_loss: 10.0663 - val_mean_absolute_percentage_error: 10.0663\n",
            "Epoch 146/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.0342 - mean_absolute_percentage_error: 6.0342 - val_loss: 10.2203 - val_mean_absolute_percentage_error: 10.2203\n",
            "Epoch 147/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.0596 - mean_absolute_percentage_error: 6.0596 - val_loss: 10.0312 - val_mean_absolute_percentage_error: 10.0312\n",
            "Epoch 148/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.2786 - mean_absolute_percentage_error: 6.2786 - val_loss: 10.7206 - val_mean_absolute_percentage_error: 10.7206\n",
            "Epoch 149/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.3638 - mean_absolute_percentage_error: 6.3638 - val_loss: 10.0611 - val_mean_absolute_percentage_error: 10.0611\n",
            "Epoch 150/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.1720 - mean_absolute_percentage_error: 6.1720 - val_loss: 9.7948 - val_mean_absolute_percentage_error: 9.7948\n",
            "Epoch 151/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0233 - mean_absolute_percentage_error: 6.0233 - val_loss: 9.8353 - val_mean_absolute_percentage_error: 9.8353\n",
            "Epoch 152/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8634 - mean_absolute_percentage_error: 5.8634 - val_loss: 10.4178 - val_mean_absolute_percentage_error: 10.4178\n",
            "Epoch 153/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9546 - mean_absolute_percentage_error: 5.9546 - val_loss: 9.8549 - val_mean_absolute_percentage_error: 9.8549\n",
            "Epoch 154/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9322 - mean_absolute_percentage_error: 5.9322 - val_loss: 9.9032 - val_mean_absolute_percentage_error: 9.9032\n",
            "Epoch 155/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7438 - mean_absolute_percentage_error: 5.7438 - val_loss: 9.4783 - val_mean_absolute_percentage_error: 9.4783\n",
            "Epoch 156/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0235 - mean_absolute_percentage_error: 6.0235 - val_loss: 10.1107 - val_mean_absolute_percentage_error: 10.1107\n",
            "Epoch 157/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9686 - mean_absolute_percentage_error: 5.9686 - val_loss: 9.8014 - val_mean_absolute_percentage_error: 9.8014\n",
            "Epoch 158/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8238 - mean_absolute_percentage_error: 5.8238 - val_loss: 9.8038 - val_mean_absolute_percentage_error: 9.8038\n",
            "Epoch 159/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.9012 - mean_absolute_percentage_error: 5.9012 - val_loss: 10.2364 - val_mean_absolute_percentage_error: 10.2364\n",
            "Epoch 160/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.2069 - mean_absolute_percentage_error: 6.2069 - val_loss: 9.7938 - val_mean_absolute_percentage_error: 9.7938\n",
            "Epoch 161/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.8271 - mean_absolute_percentage_error: 5.8271 - val_loss: 9.5415 - val_mean_absolute_percentage_error: 9.5415\n",
            "Epoch 162/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7813 - mean_absolute_percentage_error: 5.7813 - val_loss: 10.0343 - val_mean_absolute_percentage_error: 10.0343\n",
            "Epoch 163/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8950 - mean_absolute_percentage_error: 5.8950 - val_loss: 9.6922 - val_mean_absolute_percentage_error: 9.6922\n",
            "Epoch 164/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8035 - mean_absolute_percentage_error: 5.8035 - val_loss: 9.8008 - val_mean_absolute_percentage_error: 9.8008\n",
            "Epoch 165/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9063 - mean_absolute_percentage_error: 5.9063 - val_loss: 9.6343 - val_mean_absolute_percentage_error: 9.6343\n",
            "Epoch 166/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7451 - mean_absolute_percentage_error: 5.7451 - val_loss: 9.7386 - val_mean_absolute_percentage_error: 9.7386\n",
            "Epoch 167/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7843 - mean_absolute_percentage_error: 5.7843 - val_loss: 9.7736 - val_mean_absolute_percentage_error: 9.7736\n",
            "Epoch 168/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8844 - mean_absolute_percentage_error: 5.8844 - val_loss: 9.6608 - val_mean_absolute_percentage_error: 9.6608\n",
            "Epoch 169/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.6726 - mean_absolute_percentage_error: 5.6726 - val_loss: 9.5874 - val_mean_absolute_percentage_error: 9.5874\n",
            "Epoch 170/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0167 - mean_absolute_percentage_error: 6.0167 - val_loss: 9.4482 - val_mean_absolute_percentage_error: 9.4482\n",
            "Epoch 171/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.5209 - mean_absolute_percentage_error: 5.5209 - val_loss: 9.6290 - val_mean_absolute_percentage_error: 9.6290\n",
            "Epoch 172/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.7290 - mean_absolute_percentage_error: 5.7290 - val_loss: 9.4307 - val_mean_absolute_percentage_error: 9.4307\n",
            "Epoch 173/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8054 - mean_absolute_percentage_error: 5.8054 - val_loss: 9.7573 - val_mean_absolute_percentage_error: 9.7573\n",
            "Epoch 174/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0835 - mean_absolute_percentage_error: 6.0835 - val_loss: 9.8713 - val_mean_absolute_percentage_error: 9.8713\n",
            "Epoch 175/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.6918 - mean_absolute_percentage_error: 5.6918 - val_loss: 9.4447 - val_mean_absolute_percentage_error: 9.4447\n",
            "Epoch 176/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.6181 - mean_absolute_percentage_error: 5.6181 - val_loss: 10.3408 - val_mean_absolute_percentage_error: 10.3408\n",
            "Epoch 177/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7477 - mean_absolute_percentage_error: 5.7477 - val_loss: 9.2525 - val_mean_absolute_percentage_error: 9.2525\n",
            "Epoch 178/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.6367 - mean_absolute_percentage_error: 5.6367 - val_loss: 9.6804 - val_mean_absolute_percentage_error: 9.6804\n",
            "Epoch 179/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.7635 - mean_absolute_percentage_error: 5.7635 - val_loss: 9.8724 - val_mean_absolute_percentage_error: 9.8724\n",
            "Epoch 180/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.6089 - mean_absolute_percentage_error: 5.6089 - val_loss: 9.3376 - val_mean_absolute_percentage_error: 9.3376\n",
            "Epoch 181/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.6497 - mean_absolute_percentage_error: 5.6497 - val_loss: 9.5006 - val_mean_absolute_percentage_error: 9.5006\n",
            "Epoch 182/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.5379 - mean_absolute_percentage_error: 5.5379 - val_loss: 9.5462 - val_mean_absolute_percentage_error: 9.5462\n",
            "Epoch 183/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.3489 - mean_absolute_percentage_error: 5.3489 - val_loss: 9.0952 - val_mean_absolute_percentage_error: 9.0952\n",
            "Epoch 184/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.6511 - mean_absolute_percentage_error: 5.6511 - val_loss: 9.6319 - val_mean_absolute_percentage_error: 9.6319\n",
            "Epoch 185/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.5388 - mean_absolute_percentage_error: 5.5388 - val_loss: 9.6935 - val_mean_absolute_percentage_error: 9.6935\n",
            "Epoch 186/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.3981 - mean_absolute_percentage_error: 5.3981 - val_loss: 9.4456 - val_mean_absolute_percentage_error: 9.4456\n",
            "Epoch 187/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.5935 - mean_absolute_percentage_error: 5.5935 - val_loss: 9.2450 - val_mean_absolute_percentage_error: 9.2450\n",
            "Epoch 188/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.7273 - mean_absolute_percentage_error: 5.7273 - val_loss: 8.9078 - val_mean_absolute_percentage_error: 8.9078\n",
            "Epoch 189/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.6753 - mean_absolute_percentage_error: 5.6753 - val_loss: 9.2549 - val_mean_absolute_percentage_error: 9.2549\n",
            "Epoch 190/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.3972 - mean_absolute_percentage_error: 5.3972 - val_loss: 9.3754 - val_mean_absolute_percentage_error: 9.3754\n",
            "Epoch 191/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.4040 - mean_absolute_percentage_error: 5.4040 - val_loss: 9.3400 - val_mean_absolute_percentage_error: 9.3400\n",
            "Epoch 192/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.4371 - mean_absolute_percentage_error: 5.4371 - val_loss: 9.4309 - val_mean_absolute_percentage_error: 9.4309\n",
            "Epoch 193/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.2995 - mean_absolute_percentage_error: 5.2995 - val_loss: 9.4744 - val_mean_absolute_percentage_error: 9.4744\n",
            "Epoch 194/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.4540 - mean_absolute_percentage_error: 5.4540 - val_loss: 9.1736 - val_mean_absolute_percentage_error: 9.1736\n",
            "Epoch 195/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.4784 - mean_absolute_percentage_error: 5.4784 - val_loss: 9.0940 - val_mean_absolute_percentage_error: 9.0940\n",
            "Epoch 196/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.8345 - mean_absolute_percentage_error: 5.8345 - val_loss: 9.2141 - val_mean_absolute_percentage_error: 9.2141\n",
            "Epoch 197/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.7871 - mean_absolute_percentage_error: 5.7871 - val_loss: 9.4905 - val_mean_absolute_percentage_error: 9.4905\n",
            "Epoch 198/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7420 - mean_absolute_percentage_error: 5.7420 - val_loss: 9.4805 - val_mean_absolute_percentage_error: 9.4805\n",
            "Epoch 199/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.3496 - mean_absolute_percentage_error: 5.3496 - val_loss: 9.0696 - val_mean_absolute_percentage_error: 9.0696\n",
            "Epoch 200/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.6763 - mean_absolute_percentage_error: 5.6763 - val_loss: 9.3508 - val_mean_absolute_percentage_error: 9.3508\n",
            "Epoch 201/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.2495 - mean_absolute_percentage_error: 5.2495 - val_loss: 9.6022 - val_mean_absolute_percentage_error: 9.6022\n",
            "Epoch 202/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.6200 - mean_absolute_percentage_error: 5.6200 - val_loss: 9.3190 - val_mean_absolute_percentage_error: 9.3190\n",
            "Epoch 203/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.3530 - mean_absolute_percentage_error: 5.3530 - val_loss: 9.6204 - val_mean_absolute_percentage_error: 9.6204\n",
            "Epoch 204/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.4917 - mean_absolute_percentage_error: 5.4917 - val_loss: 9.5101 - val_mean_absolute_percentage_error: 9.5101\n",
            "Epoch 205/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.4372 - mean_absolute_percentage_error: 5.4372 - val_loss: 9.5589 - val_mean_absolute_percentage_error: 9.5589\n",
            "Epoch 206/250\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 5.3509 - mean_absolute_percentage_error: 5.3509 - val_loss: 9.3985 - val_mean_absolute_percentage_error: 9.3985\n",
            "Epoch 207/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.4511 - mean_absolute_percentage_error: 5.4511 - val_loss: 8.9864 - val_mean_absolute_percentage_error: 8.9864\n",
            "Epoch 208/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.4035 - mean_absolute_percentage_error: 5.4035 - val_loss: 9.1762 - val_mean_absolute_percentage_error: 9.1762\n",
            "Epoch 209/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.2667 - mean_absolute_percentage_error: 5.2667 - val_loss: 8.7825 - val_mean_absolute_percentage_error: 8.7825\n",
            "Epoch 210/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.2447 - mean_absolute_percentage_error: 5.2447 - val_loss: 8.9720 - val_mean_absolute_percentage_error: 8.9720\n",
            "Epoch 211/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.1032 - mean_absolute_percentage_error: 5.1032 - val_loss: 9.1437 - val_mean_absolute_percentage_error: 9.1437\n",
            "Epoch 212/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.3401 - mean_absolute_percentage_error: 5.3401 - val_loss: 9.0925 - val_mean_absolute_percentage_error: 9.0925\n",
            "Epoch 213/250\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.0323 - mean_absolute_percentage_error: 5.0323 - val_loss: 9.3004 - val_mean_absolute_percentage_error: 9.3004\n",
            "Epoch 214/250\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.0641 - mean_absolute_percentage_error: 5.0641 - val_loss: 9.3030 - val_mean_absolute_percentage_error: 9.3030\n",
            "Epoch 215/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.0504 - mean_absolute_percentage_error: 5.0504 - val_loss: 9.2193 - val_mean_absolute_percentage_error: 9.2193\n",
            "Epoch 216/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.0067 - mean_absolute_percentage_error: 5.0067 - val_loss: 9.1602 - val_mean_absolute_percentage_error: 9.1602\n",
            "Epoch 217/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.2591 - mean_absolute_percentage_error: 5.2591 - val_loss: 8.9750 - val_mean_absolute_percentage_error: 8.9750\n",
            "Epoch 218/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.9830 - mean_absolute_percentage_error: 4.9830 - val_loss: 9.1565 - val_mean_absolute_percentage_error: 9.1565\n",
            "Epoch 219/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.9574 - mean_absolute_percentage_error: 4.9574 - val_loss: 9.1120 - val_mean_absolute_percentage_error: 9.1120\n",
            "Epoch 220/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.9770 - mean_absolute_percentage_error: 4.9770 - val_loss: 9.2746 - val_mean_absolute_percentage_error: 9.2746\n",
            "Epoch 221/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.1946 - mean_absolute_percentage_error: 5.1946 - val_loss: 9.2069 - val_mean_absolute_percentage_error: 9.2069\n",
            "Epoch 222/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9879 - mean_absolute_percentage_error: 4.9879 - val_loss: 9.5341 - val_mean_absolute_percentage_error: 9.5341\n",
            "Epoch 223/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.4138 - mean_absolute_percentage_error: 5.4138 - val_loss: 9.3328 - val_mean_absolute_percentage_error: 9.3328\n",
            "Epoch 224/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.2196 - mean_absolute_percentage_error: 5.2196 - val_loss: 9.3250 - val_mean_absolute_percentage_error: 9.3250\n",
            "Epoch 225/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.9369 - mean_absolute_percentage_error: 4.9369 - val_loss: 9.2587 - val_mean_absolute_percentage_error: 9.2587\n",
            "Epoch 226/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.3228 - mean_absolute_percentage_error: 5.3228 - val_loss: 9.0328 - val_mean_absolute_percentage_error: 9.0328\n",
            "Epoch 227/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9926 - mean_absolute_percentage_error: 4.9926 - val_loss: 8.9597 - val_mean_absolute_percentage_error: 8.9597\n",
            "Epoch 228/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.0659 - mean_absolute_percentage_error: 5.0659 - val_loss: 8.8153 - val_mean_absolute_percentage_error: 8.8153\n",
            "Epoch 229/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.8052 - mean_absolute_percentage_error: 4.8052 - val_loss: 8.8769 - val_mean_absolute_percentage_error: 8.8769\n",
            "Epoch 230/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.7236 - mean_absolute_percentage_error: 4.7236 - val_loss: 8.9716 - val_mean_absolute_percentage_error: 8.9716\n",
            "Epoch 231/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.8776 - mean_absolute_percentage_error: 4.8776 - val_loss: 8.8714 - val_mean_absolute_percentage_error: 8.8714\n",
            "Epoch 232/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.8031 - mean_absolute_percentage_error: 4.8031 - val_loss: 8.9185 - val_mean_absolute_percentage_error: 8.9185\n",
            "Epoch 233/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.6338 - mean_absolute_percentage_error: 4.6338 - val_loss: 9.3232 - val_mean_absolute_percentage_error: 9.3232\n",
            "Epoch 234/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9708 - mean_absolute_percentage_error: 4.9708 - val_loss: 9.5026 - val_mean_absolute_percentage_error: 9.5026\n",
            "Epoch 235/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.1260 - mean_absolute_percentage_error: 5.1260 - val_loss: 8.7773 - val_mean_absolute_percentage_error: 8.7773\n",
            "Epoch 236/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9778 - mean_absolute_percentage_error: 4.9778 - val_loss: 9.4322 - val_mean_absolute_percentage_error: 9.4322\n",
            "Epoch 237/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4476 - mean_absolute_percentage_error: 5.4476 - val_loss: 9.6037 - val_mean_absolute_percentage_error: 9.6037\n",
            "Epoch 238/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.3423 - mean_absolute_percentage_error: 5.3423 - val_loss: 9.1560 - val_mean_absolute_percentage_error: 9.1560\n",
            "Epoch 239/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9352 - mean_absolute_percentage_error: 4.9352 - val_loss: 8.9116 - val_mean_absolute_percentage_error: 8.9116\n",
            "Epoch 240/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9877 - mean_absolute_percentage_error: 4.9877 - val_loss: 8.8043 - val_mean_absolute_percentage_error: 8.8043\n",
            "Epoch 241/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.7135 - mean_absolute_percentage_error: 4.7135 - val_loss: 8.7636 - val_mean_absolute_percentage_error: 8.7636\n",
            "Epoch 242/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.6731 - mean_absolute_percentage_error: 4.6731 - val_loss: 8.9180 - val_mean_absolute_percentage_error: 8.9180\n",
            "Epoch 243/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.7500 - mean_absolute_percentage_error: 4.7500 - val_loss: 9.3145 - val_mean_absolute_percentage_error: 9.3145\n",
            "Epoch 244/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.8622 - mean_absolute_percentage_error: 4.8622 - val_loss: 8.9408 - val_mean_absolute_percentage_error: 8.9408\n",
            "Epoch 245/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.9079 - mean_absolute_percentage_error: 4.9079 - val_loss: 8.8962 - val_mean_absolute_percentage_error: 8.8962\n",
            "Epoch 246/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.8342 - mean_absolute_percentage_error: 4.8342 - val_loss: 9.1097 - val_mean_absolute_percentage_error: 9.1097\n",
            "Epoch 247/250\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.8976 - mean_absolute_percentage_error: 4.8976 - val_loss: 8.9989 - val_mean_absolute_percentage_error: 8.9989\n",
            "Epoch 248/250\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.6655 - mean_absolute_percentage_error: 4.6655 - val_loss: 9.0430 - val_mean_absolute_percentage_error: 9.0430\n",
            "Epoch 249/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.6324 - mean_absolute_percentage_error: 4.6324 - val_loss: 8.9233 - val_mean_absolute_percentage_error: 8.9233\n",
            "Epoch 250/250\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.5452 - mean_absolute_percentage_error: 4.5452 - val_loss: 9.4812 - val_mean_absolute_percentage_error: 9.4812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1fec292370>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RDBtUuYjuFh"
      },
      "source": [
        "# **Upload this Day 5 Colab Notebook to your Github repository under \"Day 5\" folder. Also add your *Reflection* on today's learning in README.md**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mupD9JvzD1BU"
      },
      "source": [
        "#Fun Fact\n",
        "\n",
        "Google Translate is getting better all the time, but it's still not perfect. Translate a sentence into another language and back into English, and you might get a hilarious surprise. That's what Malinda Kathleen Reese got when she reverse Google Translated the lyrics to \"Let It Go\" from Disney's Frozen into Chinese, Macedonian, French, Polish, Creole, Tamil and others. It doesn't come out as utter gibberish, but as a slightly off version with a slightly different message from the original. Which makes it even funnier. Plus, Malinda can really sing.\n",
        "\n",
        "Link to video: https://www.youtube.com/watch?v=2bVAoVlFYf0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgg0bvRjS9un"
      },
      "source": [
        "Sources:\n",
        "\n",
        "https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23\n",
        "\n",
        "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)"
      ]
    }
  ]
}